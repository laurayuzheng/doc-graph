<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Ageophysics%20AND%20all%3Amachine%20AND%20all%3Alearning%26id_list%3D%26start%3D0%26max_results%3D100" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:geophysics AND all:machine AND all:learning&amp;id_list=&amp;start=0&amp;max_results=100</title>
  <id>http://arxiv.org/api/k5COJkK+gBYDObRj2SHa1EJ6v8Q</id>
  <updated>2019-07-16T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">119</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">100</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/1902.04621v1</id>
    <updated>2019-02-12T20:24:49Z</updated>
    <published>2019-02-12T20:24:49Z</published>
    <title>Deep Learning for Scientific Inference from Geophysical Data: The
  Madden-Julian Oscillation as a Test Case</title>
    <summary>  Deep learning can recognize complex geophysical phenomena by inferring which
variables are important for their identification and understanding their
spatial characteristics.
  We use a particular mode of multi-scale tropical atmospheric variability, the
Madden-Julian oscillation (MJO), to study the capabilities of deep learning, a
form of artificial intelligence and machine learning, in identifying spatial
geophysical phenomena. The MJO is characterized by its spatial and temporal
evolution of cloud patterns, and an extensive body of literature has examined
its defining characteristics. By applying a convolutional neural network (CNN),
a type of deep learning model, to the task of identifying the state of the MJO,
we show that deep learning can correctly identify geophysical phenomena by
"learning" the variables and spatial patterns important to their evolution. In
a broader sense, these findings suggest that deep learning models are
interpretable and viable for scientific inference in geoscientific
applications.
</summary>
    <author>
      <name>Benjamin A. Toms</name>
    </author>
    <author>
      <name>Karthik Kashinath</name>
    </author>
    <author>
      <name> Prabhat</name>
    </author>
    <author>
      <name>Da Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This manuscript has been submitted for review at the American
  Geophysical Union journal Geophysical Research Letters. Please contact the
  corresponding author, Benjamin A. Toms, for the supplementary material</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.04621v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.04621v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.09856v1</id>
    <updated>2018-08-29T14:43:12Z</updated>
    <published>2018-08-29T14:43:12Z</published>
    <title>Application of Machine Learning in Rock Facies Classification with
  Physics-Motivated Feature Augmentation</title>
    <summary>  With recent progress in algorithms and the availability of massive amounts of
computation power, application of machine learning techniques is becoming a hot
topic in the oil and gas industry. One of the most promising aspects to apply
machine learning to the upstream field is the rock facies classification in
reservoir characterization, which is crucial in determining the net pay
thickness of reservoirs, thus a definitive factor in drilling decision making
process. For complex machine learning tasks like facies classification, feature
engineering is often critical. This paper shows the inclusion of
physics-motivated feature interaction in feature augmentation can further
improve the capability of machine learning in rock facies classification. We
demonstrate this approach with the SEG 2016 machine learning contest dataset
and the top winning algorithms. The improvement is roboust and can be $\sim5\%$
better than current existing best F-1 score, where F-1 is an evaluation metric
used to quantify average prediction accuracy.
</summary>
    <author>
      <name>Jie Chen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Corresponding author</arxiv:affiliation>
    </author>
    <author>
      <name>Yu Zeng</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Corresponding author</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1808.09856v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.09856v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.04708v1</id>
    <updated>2017-11-13T17:16:38Z</updated>
    <published>2017-11-13T17:16:38Z</published>
    <title>Machine Learning for the Geosciences: Challenges and Opportunities</title>
    <summary>  Geosciences is a field of great societal relevance that requires solutions to
several urgent problems facing our humanity and the planet. As geosciences
enters the era of big data, machine learning (ML) -- that has been widely
successful in commercial domains -- offers immense potential to contribute to
problems in geosciences. However, problems in geosciences have several unique
challenges that are seldom found in traditional applications, requiring novel
problem formulations and methodologies in machine learning. This article
introduces researchers in the machine learning (ML) community to these
challenges offered by geoscience problems and the opportunities that exist for
advancing both machine learning and geosciences. We first highlight typical
sources of geoscience data and describe their properties that make it
challenging to use traditional machine learning techniques. We then describe
some of the common categories of geoscience problems where machine learning can
play a role, and discuss some of the existing efforts and promising directions
for methodological development in machine learning. We conclude by discussing
some of the emerging research themes in machine learning that are applicable
across all problems in the geosciences, and the importance of a deep
collaboration between machine learning and geosciences for synergistic
advancements in both disciplines.
</summary>
    <author>
      <name>Anuj Karpatne</name>
    </author>
    <author>
      <name>Imme Ebert-Uphoff</name>
    </author>
    <author>
      <name>Sai Ravela</name>
    </author>
    <author>
      <name>Hassan Ali Babaie</name>
    </author>
    <author>
      <name>Vipin Kumar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Under review at IEEE Transactions on Knowledge and Data Engineering</arxiv:comment>
    <link href="http://arxiv.org/abs/1711.04708v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.04708v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.12856v1</id>
    <updated>2018-10-30T16:55:37Z</updated>
    <published>2018-10-30T16:55:37Z</published>
    <title>Discovering state-parameter mappings in subsurface models using
  generative adversarial networks</title>
    <summary>  A fundamental problem in geophysical modeling is related to the
identification and approximation of causal structures among physical processes.
However, resolving the bidirectional mappings between physical parameters and
model state variables (i.e., solving the forward and inverse problems) is
challenging, especially when parameter dimensionality is high. Deep learning
has opened a new door toward knowledge representation and complex pattern
identification. In particular, the recently introduced generative adversarial
networks (GANs) hold strong promises in learning cross-domain mappings for
image translation. This study presents a state-parameter identification GAN
(SPID-GAN) for simultaneously learning bidirectional mappings between a
high-dimensional parameter space and the corresponding model state space.
SPID-GAN is demonstrated using a series of representative problems from
subsurface flow modeling. Results show that SPID-GAN achieves satisfactory
performance in identifying the bidirectional state-parameter mappings,
providing a new deep-learning-based, knowledge representation paradigm for a
wide array of complex geophysical problems.
</summary>
    <author>
      <name>Alexander Y. Sun</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1029/2018GL080404</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1029/2018GL080404" rel="related"/>
    <link href="http://arxiv.org/abs/1810.12856v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.12856v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.08431v4</id>
    <updated>2017-09-06T19:31:51Z</updated>
    <published>2017-01-29T21:18:22Z</published>
    <title>Source localization in an ocean waveguide using supervised machine
  learning</title>
    <summary>  Source localization in ocean acoustics is posed as a machine learning problem
in which data-driven methods learn source ranges directly from observed
acoustic data. The pressure received by a vertical linear array is preprocessed
by constructing a normalized sample covariance matrix (SCM) and used as the
input. Three machine learning methods (feed-forward neural networks (FNN),
support vector machines (SVM) and random forests (RF)) are investigated in this
paper, with focus on the FNN. The range estimation problem is solved both as a
classification problem and as a regression problem by these three machine
learning algorithms. The results of range estimation for the Noise09 experiment
are compared for FNN, SVM, RF and conventional matched-field processing and
demonstrate the potential of machine learning for underwater source
localization..
</summary>
    <author>
      <name>Haiqiang Niu</name>
    </author>
    <author>
      <name>Emma Reeves</name>
    </author>
    <author>
      <name>Peter Gerstoft</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1121/1.5000165</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1121/1.5000165" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to The Journal of the Acoustical Society of America</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Journal of the Acoustical Society of America 142, 1176 (2017)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1701.08431v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.08431v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.06528v1</id>
    <updated>2019-05-16T04:48:28Z</updated>
    <published>2019-05-16T04:48:28Z</published>
    <title>Structure Label Prediction Using Similarity-Based Retrieval and
  Weakly-Supervised Label Mapping</title>
    <summary>  Recently, there has been significant interest in various supervised machine
learning techniques that can help reduce the time and effort consumed by manual
interpretation workflows. However, most successful supervised machine learning
algorithms require huge amounts of annotated training data. Obtaining these
labels for large seismic volumes is a very time-consuming and laborious task.
We address this problem by presenting a weakly-supervised approach for
predicting the labels of various seismic structures. By having an interpreter
select a very small number of exemplar images for every class of subsurface
structures, we use a novel similarity-based retrieval technique to extract
thousands of images that contain similar subsurface structures from the seismic
volume. By assuming that similar images belong to the same class, we obtain
thousands of image-level labels for these images; we validate this assumption
in our results section. We then introduce a novel weakly-supervised algorithm
for mapping these rough image-level labels into more accurate pixel-level
labels that localize the different subsurface structures within the image. This
approach dramatically simplifies the process of obtaining labeled data for
training supervised machine learning algorithms on seismic interpretation
tasks. Using our method we generate thousands of automatically-labeled images
from the Netherlands Offshore F3 block with reasonably accurate pixel-level
labels. We believe this work will allow for more advances in machine
learning-enabled seismic interpretation.
</summary>
    <author>
      <name>Yazeed Alaudah</name>
    </author>
    <author>
      <name>Motaz Alfarraj</name>
    </author>
    <author>
      <name>Ghassan AlRegib</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1190/geo2018-0028.1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1190/geo2018-0028.1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at SEG Geophysics Journal in Dec 2018</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">GEOPHYSICS 2019 84:1, V67-V79</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1905.06528v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.06528v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.03278v1</id>
    <updated>2019-07-07T12:56:02Z</updated>
    <published>2019-07-07T12:56:02Z</published>
    <title>Stacked autoencoders based machine learning for noise reduction and
  signal reconstruction in geophysical data</title>
    <summary>  Autoencoders are neural network formulations where the input and output of
the network are identical and the goal is to identify the hidden representation
in the provided datasets. Generally, autoencoders project the data nonlinearly
onto a lower dimensional hidden space, where the important features get
highlighted and interpretation of the data becomes easier. Recent studies have
shown that even in the presence of noise in the input data, autoencoders can be
trained to reconstruct the noisefree component of the data from the
reduced-dimensional hidden space.
  In this paper, we explore the application of autoencoders within the scope of
denoising geophysical datasets using a data-driven methodology. The autoencoder
formulation is discussed, and a stacked variant of deep autoencoders is
proposed. The proposed method involves locally training the weights first using
basic autoencoders, each comprising a single hidden layer. Using these
initialized weights as starting points in the optimization model, the full
autoencoder network is then trained in the second step. The applicability of
denoising autoencoders has been demonstrated on a basic mathematical example
and several geophysical examples. For all the cases, autoencoders are found to
significantly reduce the noise in the input data.
</summary>
    <author>
      <name>Debjani Bhowick</name>
    </author>
    <author>
      <name>Deepak K. Gupta</name>
    </author>
    <author>
      <name>Saumen Maiti</name>
    </author>
    <author>
      <name>Uma Shankar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.03278v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.03278v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.11157v1</id>
    <updated>2019-03-26T21:20:46Z</updated>
    <published>2019-03-26T21:20:46Z</published>
    <title>Machine Learning Reveals the State of Intermittent Frictional Dynamics
  in a Sheared Granular Fault</title>
    <summary>  Seismogenic plate boundaries are presumed to behave in a similar manner to a
densely packed granular medium, where fault and blocks systems rapidly
rearrange the distribution of forces within themselves, as particles do in
slowly sheared granular systems. We use machine learning and show that
statistical features of velocity signals from individual particles in a
simulated sheared granular fault contain information regarding the
instantaneous global state of intermittent frictional stick-slip dynamics. We
demonstrate that combining features built from the signals of more particles
can improve the accuracy of the global model, and discuss the physical basis
behind decrease in error. We show that the statistical features such as median
and higher moments of the signals that represent the particle displacement in
the direction of shearing are among the best predictive features. Our work
provides novel insights into the applications of machine learning in studying
frictional processes that take place in geophysical systems.
</summary>
    <author>
      <name>C. X. Ren</name>
    </author>
    <author>
      <name>O. Dorostkar</name>
    </author>
    <author>
      <name>B. Rouet-Leduc</name>
    </author>
    <author>
      <name>C. Hulbert</name>
    </author>
    <author>
      <name>D. Strebel</name>
    </author>
    <author>
      <name>R. A. Guyer</name>
    </author>
    <author>
      <name>P. A. Johnson</name>
    </author>
    <author>
      <name>J. Carmeliet</name>
    </author>
    <link href="http://arxiv.org/abs/1903.11157v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.11157v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.10758v1</id>
    <updated>2019-01-30T10:42:39Z</updated>
    <published>2019-01-30T10:42:39Z</published>
    <title>Ensemble-based kernel learning for a class of data assimilation problems
  with imperfect forward simulators</title>
    <summary>  Simulator imperfection, often known as model error, is ubiquitous in
practical data assimilation problems. Despite the enormous efforts dedicated to
addressing this problem, properly handling simulator imperfection in data
assimilation remains to be a challenging task. In this work, we propose an
approach to dealing with simulator imperfection from a point of view of
functional approximation that can be implemented through a certain machine
learning method, such as kernel-based learning adopted in the current work. To
this end, we start from considering a class of supervised learning problems,
and then identify similarities between supervised learning and variational data
assimilation. These similarities found the basis for us to develop an
ensemble-based learning framework to tackle supervised learning problems, while
achieving various advantages of ensemble-based methods over the variational
ones. After establishing the ensemble-based learning framework, we proceed to
investigate the integration of ensemble-based learning into an ensemble-based
data assimilation framework to handle simulator imperfection. In the course of
our investigations, we also develop a strategy to tackle the issue of
multi-modality in supervised-learning problems, and transfer this strategy to
data assimilation problems to help improve assimilation performance. For
demonstration, we apply the ensemble-based learning framework and the
integrated, ensemble-based data assimilation framework to a supervised learning
problem and a data assimilation problem with an imperfect forward simulator,
respectively. The experiment results indicate that both frameworks achieve good
performance in relevant case studies, and that functional approximation through
machine learning may serve as a viable way to account for simulator
imperfection in data assimilation problems.
</summary>
    <author>
      <name>Xiaodong Luo</name>
    </author>
    <link href="http://arxiv.org/abs/1901.10758v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.10758v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.09721v1</id>
    <updated>2017-10-26T14:09:15Z</updated>
    <published>2017-10-26T14:09:15Z</published>
    <title>Topological characteristics of oil and gas reservoirs and their
  applications</title>
    <summary>  We demonstrate applications of topological characteristics of oil and gas
reservoirs considered as three-dimensional bodies to geological modeling.
</summary>
    <author>
      <name>V. A. Baikov</name>
    </author>
    <author>
      <name>R. R. Gilmanov</name>
    </author>
    <author>
      <name>I. A. Taimanov</name>
    </author>
    <author>
      <name>A. A. Yakovlev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Towards Integrative Machine Learning and Knowledge Extraction,
  182-193, Lecture Notes in Comput. Sci., 10344, Lecture Notes in Artificial
  Intelligence, Springer, Cham, 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1710.09721v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.09721v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.00770v1</id>
    <updated>2019-03-26T13:12:14Z</updated>
    <published>2019-03-26T13:12:14Z</published>
    <title>Netherlands Dataset: A New Public Dataset for Machine Learning in
  Seismic Interpretation</title>
    <summary>  Machine learning and, more specifically, deep learning algorithms have seen
remarkable growth in their popularity and usefulness in the last years. This is
arguably due to three main factors: powerful computers, new techniques to train
deeper networks and larger datasets. Although the first two are readily
available in modern computers and ML libraries, the last one remains a
challenge for many domains. It is a fact that big data is a reality in almost
all fields nowadays, and geosciences are not an exception. However, to achieve
the success of general-purpose applications such as ImageNet - for which there
are +14 million labeled images for 1000 target classes - we not only need more
data, we need more high-quality labeled data. When it comes to the Oil&amp;Gas
industry, confidentiality issues hamper even more the sharing of datasets. In
this work, we present the Netherlands interpretation dataset, a contribution to
the development of machine learning in seismic interpretation. The Netherlands
F3 dataset acquisition was carried out in the North Sea, Netherlands offshore.
The data is publicly available and contains pos-stack data, 8 horizons and well
logs of 4 wells. For the purposes of our machine learning tasks, the original
dataset was reinterpreted, generating 9 horizons separating different seismic
facies intervals. The interpreted horizons were used to generate approximatelly
190,000 labeled images for inlines and crosslines. Finally, we present two deep
learning applications in which the proposed dataset was employed and produced
compelling results.
</summary>
    <author>
      <name>Reinaldo Mozart Silva</name>
    </author>
    <author>
      <name>Lais Baroni</name>
    </author>
    <author>
      <name>Rodrigo S. Ferreira</name>
    </author>
    <author>
      <name>Daniel Civitarese</name>
    </author>
    <author>
      <name>Daniela Szwarcman</name>
    </author>
    <author>
      <name>Emilio Vital Brazil</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.00770v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.00770v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.06688v1</id>
    <updated>2018-09-07T05:14:37Z</updated>
    <published>2018-09-07T05:14:37Z</published>
    <title>Geology prediction based on operation data of TBM: comparison between
  deep neural network and statistical learning methods</title>
    <summary>  Tunnel boring machine (TBM) is a complex engineering system widely used for
tunnel construction. In view of the complicated construction environments, it
is necessary to predict geology conditions prior to excavation. In recent
years, massive operation data of TBM has been recorded, and mining these data
can provide important references and useful information for designers and
operators of TBM. In this work, a geology prediction approach is proposed based
on deep neural network and operation data. It can provide relatively accurate
geology prediction results ahead of the tunnel face compared with the other
prediction models based on statistical learning methods. The application case
study on a tunnel in China shows that the proposed approach can accurately
estimate the geological conditions prior to excavation, especially for the
short range ahead of training data. This work can be regarded as a good
complement to the geophysical prospecting approach during the construction of
tunnels, and also highlights the applicability and potential of deep neural
networks for other data mining tasks of TBMs.
</summary>
    <author>
      <name>Maolin Shi</name>
    </author>
    <author>
      <name>Xueguan Song</name>
    </author>
    <author>
      <name>Wei Sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1809.06688v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.06688v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.06267v1</id>
    <updated>2019-02-17T14:52:02Z</updated>
    <published>2019-02-17T14:52:02Z</published>
    <title>Deep-learning inversion: a next generation seismic velocity-model
  building method</title>
    <summary>  Seismic velocity is one of the most important parameters used in seismic
exploration. Accurate velocity models are key prerequisites for reverse-time
migration and other high-resolution seismic imaging techniques. Such velocity
information has traditionally been derived by tomography or full-waveform
inversion (FWI), which are time consuming and computationally expensive, and
they rely heavily on human interaction and quality control. We investigate a
novel method based on the supervised deep fully convolutional neural network
(FCN) for velocity-model building (VMB) directly from raw seismograms. Unlike
the conventional inversion method based on physical models, the supervised
deep-learning methods are based on big-data training rather than
prior-knowledge assumptions. During the training stage, the network establishes
a nonlinear projection from the multi-shot seismic data to the corresponding
velocity models. During the prediction stage, the trained network can be used
to estimate the velocity models from the new input seismic data. One key
characteristic of the deep-learning method is that it can automatically extract
multi-layer useful features without the need for human-curated activities and
initial velocity setup. The data-driven method usually requires more time
during the training stage, and actual predictions take less time, with only
seconds needed. Therefore, the computational time of geophysical inversions,
including real-time inversions, can be dramatically reduced once a good
generalized network is built. By using numerical experiments on synthetic
models, the promising performances of our proposed method are shown in
comparison with conventional FWI even when the input data are in more realistic
scenarios. Discussions on the deep-learning methods, training dataset, lack of
low frequencies, and advantages and disadvantages of the new method are also
provided.
</summary>
    <author>
      <name>Fangshu Yang</name>
    </author>
    <author>
      <name>Jianwei Ma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">62 pages, 23 figures, 5 tables, revised version (Geophysics)</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.06267v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.06267v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="86A15" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.10247v1</id>
    <updated>2018-12-26T07:00:23Z</updated>
    <published>2018-12-26T07:00:23Z</published>
    <title>Deep learning electromagnetic inversion with convolutional neural
  networks</title>
    <summary>  Geophysical inversion attempts to estimate the distribution of physical
properties in the Earth's interior from observations collected at or above the
surface. Inverse problems are commonly posed as least-squares optimization
problems in high-dimensional parameter spaces. Existing approaches are largely
based on deterministic gradient-based methods, which are limited by
nonlinearity and nonuniqueness of the inverse problem. Probabilistic inversion
methods, despite their great potential in uncertainty quantification, still
remain a formidable computational task. In this paper, I explore the potential
of deep learning methods for electromagnetic inversion. This approach does not
require calculation of the gradient and provides results instantaneously. Deep
neural networks based on fully convolutional architecture are trained on large
synthetic datasets obtained by full 3-D simulations. The performance of the
method is demonstrated on models of strong practical relevance representing an
onshore controlled source electromagnetic CO2 monitoring scenario. The
pre-trained networks can reliably estimate the position and lateral dimensions
of the anomalies, as well as their resistivity properties. Several fully
convolutional network architectures are compared in terms of their accuracy,
generalization, and cost of training. Examples with different survey geometry
and noise levels confirm the feasibility of the deep learning inversion,
opening the possibility to estimate the subsurface resistivity distribution in
real time.
</summary>
    <author>
      <name>Vladimir Puzyrev</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1093/gji/ggz204</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1093/gji/ggz204" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.10247v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.10247v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.08655v1</id>
    <updated>2016-11-26T04:19:54Z</updated>
    <published>2016-11-26T04:19:54Z</published>
    <title>A Deep Neural Network to identify foreshocks in real time</title>
    <summary>  Foreshock events provide valuable insight to predict imminent major
earthquakes. However, it is difficult to identify them in real time. In this
paper, I propose an algorithm based on deep learning to instantaneously
classify a seismic waveform as a foreshock, mainshock or an aftershock event
achieving a high accuracy of 99% in classification. As a result, this is by far
the most reliable method to predict major earthquakes that are preceded by
foreshocks. In addition, I discuss methods to create an earthquake dataset that
is compatible with deep networks.
</summary>
    <author>
      <name>K. Vikraman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper on earthquake prediction based on deep learning approach. 6
  figures, two tables and 4 pages in total</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.08655v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.08655v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.06375v1</id>
    <updated>2017-01-23T13:20:05Z</updated>
    <published>2017-01-23T13:20:05Z</published>
    <title>Combining machine learning techniques, microanalyses and large
  geochemical datasets for tephrochronological studies in complex volcanic
  areas: new age constraints for the Pleistocene magmatism of Central Italy</title>
    <summary>  Characterization, correlation and provenance determination of tephra samples
in sedimentary sections (tephrochronological studies) are powerful tools for
establishing ages of depositional events, volcanic eruptions, and tephra
dispersion. Despite the large literature and the advancements in this research
field, the univocal attribution of tephra deposits to specific volcanic sources
remains too often elusive. In this contribution, we test the application of a
machine learning technique named Support Vector Machine to attempt shedding new
light upon tephra deposits related to one of the most complex and debated
volcanic regions on Earth: the Pliocene-Pleistocene magmatism in Italy. The
machine learning algorithm was trained using one of the most comprehensive
global petrological databases (GEOROC); 17 chemical elements including major
and selected trace elements were chosen as input parameters. We first show the
ability of support vector machines in discriminating among different
Pliocene-Pleistocene volcanic provinces in Italy and then apply the same
methodology to determine the volcanic source of tephra samples occurring in the
Caio outcrop, an Early Pleistocene sedimentary section located in Central
Italy.
</summary>
    <author>
      <name>Maurizio Petrelli</name>
    </author>
    <author>
      <name>Roberto Bizzarri</name>
    </author>
    <author>
      <name>Daniele Morgavi</name>
    </author>
    <author>
      <name>Angela Baldanza</name>
    </author>
    <author>
      <name>Diego Perugini</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.quageo.2016.12.003</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.quageo.2016.12.003" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to be published in Quaternary Geochronology</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.06375v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.06375v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="86-04" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.04464v3</id>
    <updated>2017-07-13T01:04:40Z</updated>
    <published>2016-06-14T17:18:06Z</published>
    <title>Sequential geophysical and flow inversion to characterize fracture
  networks in subsurface systems</title>
    <summary>  Subsurface applications including geothermal, geological carbon
sequestration, oil and gas, etc., typically involve maximizing either the
extraction of energy or the storage of fluids. Characterizing the subsurface is
extremely complex due to heterogeneity and anisotropy. Due to this complexity,
there are uncertainties in the subsurface parameters, which need to be
estimated from multiple diverse as well as fragmented data streams. In this
paper, we present a non-intrusive sequential inversion framework, for
integrating data from geophysical and flow sources to constraint subsurface
Discrete Fracture Networks (DFN). In this approach, we first estimate bounds on
the statistics for the DFN fracture orientations using microseismic data. These
bounds are estimated through a combination of a focal mechanism (physics-based
approach) and clustering analysis (statistical approach) of seismic data. Then,
the fracture lengths are constrained based on the flow data. The efficacy of
this multi-physics based sequential inversion is demonstrated through a
representative synthetic example.
</summary>
    <author>
      <name>M. K. Mudunuru</name>
    </author>
    <author>
      <name>S. Karra</name>
    </author>
    <author>
      <name>N. Makedonska</name>
    </author>
    <author>
      <name>T. Chen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/sam.11356</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/sam.11356" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.04464v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.04464v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1803.00222v2</id>
    <updated>2018-04-25T23:45:59Z</updated>
    <published>2018-03-01T05:50:45Z</published>
    <title>Extreme learning machine for reduced order modeling of turbulent
  geophysical flows</title>
    <summary>  We investigate the application of artificial neural networks to stabilize
proper orthogonal decomposition based reduced order models for quasi-stationary
geophysical turbulent flows. An extreme learning machine concept is introduced
for computing an eddy-viscosity closure dynamically to incorporate the effects
of the truncated modes. We consider a four-gyre wind-driven ocean circulation
problem as our prototype setting to assess the performance of the proposed
data-driven approach. Our framework provides a significant reduction in
computational time and effectively retains the dynamics of the full-order model
during the forward simulation period beyond the training data set. Furthermore,
we show that the method is robust for larger choices of time steps and can be
used as an efficient and reliable tool for long time integration of general
circulation models.
</summary>
    <author>
      <name>Omer San</name>
    </author>
    <author>
      <name>Romit Maulik</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.97.042322</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.97.042322" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E 97, 042322 (2018)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1803.00222v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1803.00222v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.00291v1</id>
    <updated>2018-05-01T12:40:16Z</updated>
    <published>2018-05-01T12:40:16Z</published>
    <title>Deep Autoassociative Neural Networks for Noise Reduction in Seismic data</title>
    <summary>  Machine learning is currently a trending topic in various science and
engineering disciplines, and the field of geophysics is no exception. With the
advent of powerful computers, it is now possible to train the machine to learn
complex patterns in the data, which may not be easily realized using the
traditional methods. Among the various machine learning methods, the artificial
neural networks (ANNs) have received enormous attention. A variant of ANNs,
autoassociative neural network (autoNN) tries to learn the reconstruction of
input itself using backpropagation. In an autoNN, the input and output are the
same, and an approximation to the identity mapping is obtained in a nonlinear
setting. AutoNNs have primarily been used to extract sparse internal
representations of any input and reduce its dimensionality. In this paper, we
explore the potential of autoNNs in reducing random noise in geophysical data.
In this paper, the first results of this study are presented. The synthetic
mathematical example demonstrates the concept of autoNN. For the test seismic
data, it is observed that autoNN can significantly remove the vertical time-
and frequency-local noise, however, the resolution of the output signal is
compromised to a certain extent. Future work includes testing larger examples
with several different types of noise, and using deep-stacked-autoNNs to
further reduce the noise, ensuring minimal compromise with the resolution of
the signal.
</summary>
    <author>
      <name>Debjani Bhowmick</name>
    </author>
    <author>
      <name>Deepak K. Gupta</name>
    </author>
    <author>
      <name>Saumen Maiti</name>
    </author>
    <author>
      <name>Uma Shankar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages; Accepted at 80th EAGE Annual Conference &amp; Exhibition 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1805.00291v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.00291v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.00037v3</id>
    <updated>2017-11-27T23:00:55Z</updated>
    <published>2017-08-31T18:45:40Z</published>
    <title>Earth System Modeling 2.0: A Blueprint for Models That Learn From
  Observations and Targeted High-Resolution Simulations</title>
    <summary>  Climate projections continue to be marred by large uncertainties, which
originate in processes that need to be parameterized, such as clouds,
convection, and ecosystems. But rapid progress is now within reach. New
computational tools and methods from data assimilation and machine learning
make it possible to integrate global observations and local high-resolution
simulations in an Earth system model (ESM) that systematically learns from
both. Here we propose a blueprint for such an ESM. We outline how
parameterization schemes can learn from global observations and targeted
high-resolution simulations, for example, of clouds and convection, through
matching low-order statistics between ESMs, observations, and high-resolution
simulations. We illustrate learning algorithms for ESMs with a simple dynamical
system that shares characteristics of the climate system; and we discuss the
opportunities the proposed framework presents and the challenges that remain to
realize it.
</summary>
    <author>
      <name>Tapio Schneider</name>
    </author>
    <author>
      <name>Shiwei Lan</name>
    </author>
    <author>
      <name>Andrew Stuart</name>
    </author>
    <author>
      <name>João Teixeira</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/2017GL076101</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/2017GL076101" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Geophysical Research Letters 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1709.00037v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.00037v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.11718v3</id>
    <updated>2018-12-06T04:31:08Z</updated>
    <published>2018-05-29T21:36:05Z</published>
    <title>Random mesh projectors for inverse problems</title>
    <summary>  We propose a new learning-based approach to solve ill-posed inverse problems
in imaging. We address the case where ground truth training samples are rare
and the problem is severely ill-posed - both because of the underlying physics
and because we can only get few measurements. This setting is common in
geophysical imaging and remote sensing. We show that in this case the common
approach to directly learn the mapping from the measured data to the
reconstruction becomes unstable. Instead, we propose to first learn an ensemble
of simpler mappings from the data to projections of the unknown image into
random piecewise-constant subspaces. We then combine the projections to form a
final reconstruction by solving a deconvolution-like problem. We show
experimentally that the proposed method is more robust to measurement noise and
corruptions not seen during training than a directly learned inverse.
</summary>
    <author>
      <name>Sidharth Gupta</name>
    </author>
    <author>
      <name>Konik Kothari</name>
    </author>
    <author>
      <name>Maarten V. de Hoop</name>
    </author>
    <author>
      <name>Ivan Dokmanić</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">S. Gupta and K. Kothari contributed equally</arxiv:comment>
    <link href="http://arxiv.org/abs/1805.11718v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.11718v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.07367v1</id>
    <updated>2018-12-09T16:32:40Z</updated>
    <published>2018-12-09T16:32:40Z</published>
    <title>Deep Learning Approach in Automatic Iceberg - Ship Detection with SAR
  Remote Sensing Data</title>
    <summary>  Deep Learning is gaining traction with geophysics community to understand
subsurface structures, such as fault detection or salt body in seismic data.
This study describes using deep learning method for iceberg or ship recognition
with synthetic aperture radar (SAR) data. Drifting icebergs pose a potential
threat to activities offshore around the Arctic, including for both ship
navigation and oil rigs. Advancement of satellite imagery using
weather-independent cross-polarized radar has enabled us to monitor and
delineate icebergs and ships, however a human component is needed to classify
the images. Here we present Transfer Learning, a convolutional neural network
(CNN) designed to work with a limited training data and features, while
demonstrating its effectiveness in this problem. Key aspect of the approach is
data augmentation and stacking of multiple outputs, resulted in a significant
boost in accuracy (logarithmic score of 0.1463). This algorithm has been tested
through participation at the Statoil/C-Core Kaggle competition.
</summary>
    <author>
      <name>Cheng Zhan</name>
    </author>
    <author>
      <name>Licheng Zhang</name>
    </author>
    <author>
      <name>Zhenzhen Zhong</name>
    </author>
    <author>
      <name>Sher Didi-Ooi</name>
    </author>
    <author>
      <name>Youzuo Lin</name>
    </author>
    <author>
      <name>Yunxi Zhang</name>
    </author>
    <author>
      <name>Shujiao Huang</name>
    </author>
    <author>
      <name>Changchun Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1812.07367v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.07367v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1803.00758v2</id>
    <updated>2018-03-14T19:21:22Z</updated>
    <published>2018-03-02T08:41:58Z</published>
    <title>Driving Digital Rock towards Machine Learning: predicting permeability
  with Gradient Boosting and Deep Neural Networks</title>
    <summary>  We present a research study aimed at testing of applicability of machine
learning techniques for prediction of permeability of digitized rock samples.
We prepare a training set containing 3D images of sandstone samples imaged with
X-ray microtomography and corresponding permeability values simulated with Pore
Network approach. We also use Minkowski functionals and Deep Learning-based
descriptors of 3D images and 2D slices as input features for predictive model
training and prediction. We compare predictive power of various feature sets
and methods. The later include Gradient Boosting and various architectures of
Deep Neural Networks (DNN). The results demonstrate applicability of machine
learning for image-based permeability prediction and open a new area of Digital
Rock research.
</summary>
    <author>
      <name>Oleg Sudakov</name>
    </author>
    <author>
      <name>Evgeny Burnaev</name>
    </author>
    <author>
      <name>Dmitry Koroteev</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cageo.2019.02.002</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cageo.2019.02.002" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1803.00758v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1803.00758v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.01101v1</id>
    <updated>2018-11-24T05:01:13Z</updated>
    <published>2018-11-24T05:01:13Z</published>
    <title>Automatic Seismic Salt Interpretation with Deep Convolutional Neural
  Networks</title>
    <summary>  One of the most crucial tasks in seismic reflection imaging is to identify
the salt bodies with high precision. Traditionally, this is accomplished by
visually picking the salt/sediment boundaries, which requires a great amount of
manual work and may introduce systematic bias. With recent progress of deep
learning algorithm and growing computational power, a great deal of efforts
have been made to replace human effort with machine power in salt body
interpretation. Currently, the method of Convolutional neural networks (CNN) is
revolutionizing the computer vision field and has been a hot topic in the image
analysis. In this paper, the benefits of CNN-based classification are
demonstrated by using a state-of-art network structure U-Net, along with the
residual learning framework ResNet, to delineate salt body with high precision.
Network adjustments, including the Exponential Linear Units (ELU) activation
function, the Lov\'{a}sz-Softmax loss function, and stratified $K$-fold
cross-validation, have been deployed to further improve the prediction
accuracy. The preliminary result using SEG Advanced Modeling (SEAM) data shows
good agreement between the predicted salt body and manually interpreted salt
body, especially in areas with weak reflections. This indicates the great
potential of applying CNN for salt-related interpretations.
</summary>
    <author>
      <name>Yu Zeng</name>
    </author>
    <author>
      <name>Kebei Jiang</name>
    </author>
    <author>
      <name>Jie Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.01101v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.01101v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.01429v1</id>
    <updated>2018-11-21T11:39:30Z</updated>
    <published>2018-11-21T11:39:30Z</published>
    <title>Automatic salt deposits segmentation: A deep learning approach</title>
    <summary>  One of the most important applications of seismic reflection is the
hydrocarbon exploration which is closely related to salt deposits analysis.
This problem is very important even nowadays due to it's non-linear nature.
Taking into account the recent developments in deep learning networks TGS-NOPEC
Geophysical Company hosted the Kaggle competition for salt deposits
segmentation problem in seismic image data. In this paper, we demonstrate the
great performance of several novel deep learning techniques merged into a
single neural network which achieved the 27th place (top 1%) in the mentioned
competition. Using a U-Net with ResNeXt-50 encoder pre-trained on ImageNet as
our base architecture, we implemented Spatial-Channel Squeeze &amp; Excitation,
Lovasz loss, CoordConv and Hypercolumn methods. The source code for our
solution is made publicly available at
https://github.com/K-Mike/Automatic-salt-deposits-segmentation.
</summary>
    <author>
      <name>Mikhail Karchevskiy</name>
    </author>
    <author>
      <name>Insaf Ashrapov</name>
    </author>
    <author>
      <name>Leonid Kozinkin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.01429v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.01429v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.05114v2</id>
    <updated>2019-01-28T22:39:04Z</updated>
    <published>2018-06-12T16:37:53Z</published>
    <title>Earthquake Detection in 1-D Time Series Data with Feature Selection and
  Dictionary Learning</title>
    <summary>  Earthquakes can be detected by matching spatial patterns or phase properties
from 1-D seismic waves. Current earthquake detection methods, such as waveform
correlation and template matching, have difficulty detecting anomalous
earthquakes that are not similar to other earthquakes. In recent years,
machine-learning techniques for earthquake detection have been emerging as a
new active research direction. In this paper, we develop a novel earthquake
detection method based on dictionary learning. Our detection method first
generates rich features via signal processing and statistical methods and
further employs feature selection techniques to choose features that carry the
most significant information. Based on these selected features, we build a
dictionary for classifying earthquake events from non-earthquake events. To
evaluate the performance of our dictionary-based detection methods, we test our
method on a labquake dataset from Penn State University, which contains
3,357,566 time series data points with a 400 MHz sampling rate. 1,000
earthquake events are manually labeled in total, and the length of these
earthquake events varies from 74 to 7151 data points. Through comparison to
other detection methods, we show that our feature selection and dictionary
learning incorporated earthquake detection method achieves an 80.1% prediction
accuracy and outperforms the baseline methods in earthquake detection,
including Template Matching (TM) and Support Vector Machine (SVM).
</summary>
    <author>
      <name>Zheng Zhou</name>
    </author>
    <author>
      <name>Youzuo Lin</name>
    </author>
    <author>
      <name>Zhongping Zhang</name>
    </author>
    <author>
      <name>Yue Wu</name>
    </author>
    <author>
      <name>Paul Johnson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Workshop on Data Mining for Geophysics and Geology, SIAM
  International Conference on Data Mining 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1806.05114v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.05114v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.11614v1</id>
    <updated>2018-10-27T07:39:09Z</updated>
    <published>2018-10-27T07:39:09Z</published>
    <title>Deep learning tutorial for denoising</title>
    <summary>  We herein introduce deep learning to seismic noise attenuation. Compared with
traditional seismic noise attenuation algorithms that depend on signal models
and their corresponding prior assumptions, a deep neural network is trained
based on a large training set, where the inputs are the raw datasets and the
corresponding outputs are the desired clean data. After the completion of
training, the deep learning method achieves adaptive denoising with no
requirements of (i) accurate modeling of the signal and noise, and (ii) optimal
parameters tuning. We call this intelligent denoising. We use a convolutional
neural network as the basic tool for deep learning. The training set is
generated with manually added noise in random and linear noise attenuation, and
with the wave equation in the multiple attenuation. Stochastic gradient descent
is used to solve the optimal parameters for the convolutional neural network.
The runtime of deep learning on a graphics processing unit for denoising has
the same order as the $f-x$ deconvolutional method. Synthetic and field results
show the potential applications of deep learning in the automation of random
noise attenuation with unknown variance, linear noise, and multiples.
</summary>
    <author>
      <name>Siwei Yu</name>
    </author>
    <author>
      <name>Jianwei Ma</name>
    </author>
    <author>
      <name>Wenlong Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">54 pages, 34 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1810.11614v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.11614v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="86A15" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.04104v1</id>
    <updated>2017-10-11T15:08:50Z</updated>
    <published>2017-10-11T15:08:50Z</published>
    <title>A novel prestack sparse azimuthal AVO inversion</title>
    <summary>  In this paper we demonstrate a new algorithm for sparse prestack azimuthal
AVO inversion. A novel Euclidean prior model is developed to at once respect
sparseness in the layered earth and smoothness in the model of reflectivity.
Recognizing that methods of artificial intelligence and Bayesian computation
are finding an every increasing role in augmenting the process of
interpretation and analysis of geophysical data, we derive a generalized
matrix-variate model of reflectivity in terms of orthogonal basis functions,
subject to sparse constraints. This supports a direct application of machine
learning methods, in a way that can be mapped back onto the physical principles
known to govern reflection seismology. As a demonstration we present an
application of these methods to the Marcellus shale. Attributes extracted using
the azimuthal inversion are clustered using an unsupervised learning algorithm.
Interpretation of the clusters is performed in the context of the Ruger model
of azimuthal AVO.
</summary>
    <author>
      <name>B. G. Lasscock</name>
    </author>
    <author>
      <name>T. A. Sansal</name>
    </author>
    <link href="http://arxiv.org/abs/1710.04104v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.04104v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.05774v1</id>
    <updated>2017-02-19T17:57:10Z</updated>
    <published>2017-02-19T17:57:10Z</published>
    <title>Machine Learning Predicts Laboratory Earthquakes</title>
    <summary>  Forecasting fault failure is a fundamental but elusive goal in earthquake
science. Here we show that by listening to the acoustic signal emitted by a
laboratory fault, machine learning can predict the time remaining before it
fails with great accuracy. These predictions are based solely on the
instantaneous physical characteristics of the acoustical signal, and do not
make use of its history. Surprisingly, machine learning identifies a signal
emitted from the fault zone previously thought to be low-amplitude noise that
enables failure forecasting throughout the laboratory quake cycle. We
hypothesize that applying this approach to continuous seismic data may lead to
significant advances in identifying currently unknown signals, in providing new
insights into fault physics, and in placing bounds on fault failure times.
</summary>
    <author>
      <name>Bertrand Rouet-Leduc</name>
    </author>
    <author>
      <name>Claudia Hulbert</name>
    </author>
    <author>
      <name>Nicholas Lubbers</name>
    </author>
    <author>
      <name>Kipton Barros</name>
    </author>
    <author>
      <name>Colin Humphreys</name>
    </author>
    <author>
      <name>Paul A. Johnson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/2017GL074677</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/2017GL074677" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.05774v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.05774v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.11539v1</id>
    <updated>2018-10-26T21:44:47Z</updated>
    <published>2018-10-26T21:44:47Z</published>
    <title>Earthquake catalog-based machine learning identification of laboratory
  fault states and the effects of magnitude of completeness</title>
    <summary>  Machine learning regression can predict macroscopic fault properties such as
shear stress, friction, and time to failure using continuous records of fault
zone acoustic emissions. Here we show that a similar approach is successful
using event catalogs derived from the continuous data. Our methods are
applicable to catalogs of arbitrary scale and magnitude of completeness. We
investigate how machine learning regression from an event catalog of laboratory
earthquakes performs as a function of the catalog magnitude of completeness. We
find that strong model performance requires a sufficiently low magnitude of
completeness, and below this magnitude of completeness model performance
saturates.
</summary>
    <author>
      <name>Nicholas Lubbers</name>
    </author>
    <author>
      <name>David C. Bolton</name>
    </author>
    <author>
      <name>Jamaludin Mohd-Yusof</name>
    </author>
    <author>
      <name>Chris Marone</name>
    </author>
    <author>
      <name>Kipton Barros</name>
    </author>
    <author>
      <name>Paul A. Johnson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1029/2018GL079712</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1029/2018GL079712" rel="related"/>
    <link href="http://arxiv.org/abs/1810.11539v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.11539v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.08623v2</id>
    <updated>2019-02-01T22:09:00Z</updated>
    <published>2019-01-24T19:44:30Z</published>
    <title>Petrophysical Property Estimation from Seismic Data Using Recurrent
  Neural Networks</title>
    <summary>  Reservoir characterization involves the estimation petrophysical properties
from well-log data and seismic data. Estimating such properties is a
challenging task due to the non-linearity and heterogeneity of the subsurface.
Various attempts have been made to estimate petrophysical properties using
machine learning techniques such as feed-forward neural networks and support
vector regression (SVR). Recent advances in machine learning have shown
promising results for recurrent neural networks (RNN) in modeling complex
sequential data such as videos and speech signals. In this work, we propose an
algorithm for property estimation from seismic data using recurrent neural
networks. An applications of the proposed workflow to estimate density and
p-wave impedance using seismic data shows promising results compared to
feed-forward neural networks.
</summary>
    <author>
      <name>Motaz Alfarraj</name>
    </author>
    <author>
      <name>Ghassan AlRegib</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in SEG Technical Program Expanded Abstracts 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.08623v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.08623v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.03137v1</id>
    <updated>2019-07-06T15:22:42Z</updated>
    <published>2019-07-06T15:22:42Z</published>
    <title>Precision annealing Monte Carlo methods for statistical data
  assimilation and machine learning</title>
    <summary>  In statistical data assimilation (SDA) and supervised machine learning (ML),
we wish to transfer information from observations to a model of the processes
underlying those observations. For SDA, the model consists of a set of
differential equations that describe the dynamics of a physical system. For ML,
the model is usually constructed using other strategies. In this paper, we
develop a systematic formulation based on Monte Carlo sampling to achieve such
information transfer. Following the derivation of an appropriate target
distribution, we present the formulation based on the standard
Metropolis-Hasting (MH) procedure and the Hamiltonian Monte Carlo (HMC) method
for performing the high dimensional integrals that appear. To the extensive
literature on MH and HMC, we add (1) an annealing method using a hyperparameter
that governs the precision of the model to identify and explore the highest
probability regions of phase space dominating those integrals, and (2) a
strategy for initializing the state space search. The efficacy of the proposed
formulation is demonstrated using a nonlinear dynamical model with chaotic
solutions widely used in geophysics.
</summary>
    <author>
      <name>Zheng Fang</name>
    </author>
    <author>
      <name>Adrian S. Wong</name>
    </author>
    <author>
      <name>Kangbo Hao</name>
    </author>
    <author>
      <name>Alexander J. A. Ty</name>
    </author>
    <author>
      <name>Henry D. I. Abarbanel</name>
    </author>
    <link href="http://arxiv.org/abs/1907.03137v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.03137v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.10379v2</id>
    <updated>2019-04-17T21:06:12Z</updated>
    <published>2019-02-27T08:16:50Z</published>
    <title>Can learning from natural image denoising be used for seismic data
  interpolation?</title>
    <summary>  We propose a convolutional neural network (CNN) denoising based method for
seismic data interpolation. It provides a simple and efficient way to break
though the lack problem of geophysical training labels that are often required
by deep learning methods. The new method consists of two steps: (1) Train a set
of CNN denoisers from natural image clean-noisy pairs to learn denoising; (2)
Integrate the trained CNN denoisers into project onto convex set (POCS)
framework to perform seismic data interpolation. The method alleviates the
demanding of seismic big data with similar features as applications of
end-to-end deep learning on seismic data interpolation. Additionally, the
proposed method is flexible for many cases of traces missing because missing
cases are not involved in the training step, and thus it is of plug-and-play
nature. These indicate the high generalizability of our approach and the
reduction of the need of the problem-specific training. Primary results on
synthetic and field data show promising interpolation performances of the
presented CNN-POCS method in terms of signal-to-noise ratio, de-aliasing and
weak-feature reconstruction, in comparison with traditional $f$-$x$ prediction
filtering and curvelet transform based POCS methods.
</summary>
    <author>
      <name>Hao Zhang</name>
    </author>
    <author>
      <name>Xiuyan Yang</name>
    </author>
    <author>
      <name>Jianwei Ma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 7 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.10379v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.10379v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.10108v1</id>
    <updated>2017-06-30T10:37:50Z</updated>
    <published>2017-06-30T10:37:50Z</published>
    <title>Solving petrological problems through machine learning: the study case
  of tectonic discrimination using geochemical and isotopic data</title>
    <summary>  Machine learning methods are evaluated to study the intriguing and debated
topic of discrimination among different tectonic environments using geochemical
and isotopic data. Volcanic rocks characterized by a whole geochemical
signature of major elements (SiO2, TiO2, Al2O3, Fe2O3T, CaO, MgO, Na2O, K2O),
selected trace elements (Sr, Ba, Rb, Zr, Nb, La, Ce, Nd, Hf, Sm, Gd, Y, Yb, Lu,
Ta, Th) and isotopes (206Pb/204Pb, 207Pb/204Pb, 208Pb/204Pb, 87Sr/86Sr and
143Nd/144Nd) have been extracted from open-access and comprehensive
petrological databases (i.e. PetDB and GEOROC). The obtained dataset has been
analyzed using support vector machines, a set of supervised machine learning
methods, which are considered particularly powerful in classification problems.
Results from the application of the machine learning methods show that the
combined use of major, trace elements and isotopes allow associating the
geochemical composition of rocks to the relative tectonic setting with high
classification scores (93%, on average). The lowest scores are recorded from
volcanic rocks deriving from back-arc basins (65%). All the other tectonic
settings display higher classification scores, with oceanic islands reaching
values up to 99%. Results of this study could have a significant impact in
other petrological studies potentially opening new perspectives for
petrologists and geochemists. Other examples of applications include the
development of more robust geo-thermometers and geo-barometers and the
recognition of volcanic sources for tephra layers in tephro-chronological
studies.
</summary>
    <author>
      <name>Maurizio Petrelli</name>
    </author>
    <author>
      <name>Diego Perugini</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00410-016-1292-2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00410-016-1292-2" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Contributions to Mineralogy and Petrology - Volume 171, Issue 10,
  1 October 2016, Article number 81</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1706.10108v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.10108v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.10535v1</id>
    <updated>2018-10-24T23:21:55Z</updated>
    <published>2018-10-24T23:21:55Z</published>
    <title>Meta-modeling game for deriving theoretical-consistent,
  micro-structural-based traction-separation laws via deep reinforcement
  learning</title>
    <summary>  This paper presents a new meta-modeling framework to employ deep
reinforcement learning (DRL) to generate mechanical constitutive models for
interfaces. The constitutive models are conceptualized as information flow in
directed graphs. The process of writing constitutive models are simplified as a
sequence of forming graph edges with the goal of maximizing the model score (a
function of accuracy, robustness and forward prediction quality). Thus
meta-modeling can be formulated as a Markov decision process with well-defined
states, actions, rules, objective functions, and rewards. By using neural
networks to estimate policies and state values, the computer agent is able to
efficiently self-improve the constitutive model it generated through
self-playing, in the same way AlphaGo Zero (the algorithm that outplayed the
world champion in the game of Go)improves its gameplay. Our numerical examples
show that this automated meta-modeling framework not only produces models which
outperform existing cohesive models on benchmark traction-separation data but
is also capable of detecting hidden mechanisms among micro-structural features
and incorporating them in constitutive models to improve the forward prediction
accuracy, which are difficult tasks to do manually.
</summary>
    <author>
      <name>Kun Wang</name>
    </author>
    <author>
      <name>WaiChing Sun</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cma.2018.11.026</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cma.2018.11.026" rel="related"/>
    <link href="http://arxiv.org/abs/1810.10535v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.10535v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.02254v1</id>
    <updated>2019-04-03T22:14:08Z</updated>
    <published>2019-04-03T22:14:08Z</published>
    <title>Including Physics in Deep Learning -- An example from 4D seismic
  pressure saturation inversion</title>
    <summary>  Geoscience data often have to rely on strong priors in the face of
uncertainty. Additionally, we often try to detect or model anomalous sparse
data that can appear as an outlier in machine learning models. These are
classic examples of imbalanced learning. Approaching these problems can benefit
from including prior information from physics models or transforming data to a
beneficial domain. We show an example of including physical information in the
architecture of a neural network as prior information. We go on to present
noise injection at training time to successfully transfer the network from
synthetic data to field data.
</summary>
    <author>
      <name>Jesper Sören Dramsch</name>
    </author>
    <author>
      <name>Gustavo Corte</name>
    </author>
    <author>
      <name>Hamed Amini</name>
    </author>
    <author>
      <name>Colin MacBeth</name>
    </author>
    <author>
      <name>Mikael Lüthje</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3997/2214-4609.201901967</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3997/2214-4609.201901967" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 figures, workshop, extended abstract, EAGE 2019 Workshop
  Programme, European Association of Geoscientists and Engineers</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.02254v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.02254v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.07659v2</id>
    <updated>2019-04-10T07:09:35Z</updated>
    <published>2019-01-12T19:04:58Z</published>
    <title>A Machine Learning Benchmark for Facies Classification</title>
    <summary>  The recent interest in using deep learning for seismic interpretation tasks,
such as facies classification, has been facing a significant obstacle, namely
the absence of large publicly available annotated datasets for training and
testing models. As a result, researchers have often resorted to annotating
their own training and testing data. However, different researchers may
annotate different classes, or use different train and test splits. In
addition, it is common for papers that apply machine learning for facies
classification to not contain quantitative results, and rather rely solely on
visual inspection of the results. All of these practices have lead to
subjective results and have greatly hindered the ability to compare different
machine learning models against each other and understand the advantages and
disadvantages of each approach.
  To address these issues, we open-source a fully-annotated 3D geological model
of the Netherlands F3 Block. This model is based on the study of the 3D seismic
data in addition to 26 well logs, and is grounded on the careful study of the
geology of the region. Furthermore, we propose two baseline models for facies
classification based on a deconvolution network architecture and make their
codes publicly available. Finally, we propose a scheme for evaluating different
models on this dataset, and we share the results of our baseline models. In
addition to making the dataset and the code publicly available, this work helps
advance research in this area by creating an objective benchmark for comparing
the results of different machine learning approaches for facies classification.
</summary>
    <author>
      <name>Yazeed Alaudah</name>
    </author>
    <author>
      <name>Patrycja Michalowicz</name>
    </author>
    <author>
      <name>Motaz Alfarraj</name>
    </author>
    <author>
      <name>Ghassan AlRegib</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to the SEG Interpretation journal</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.07659v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.07659v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.05508v1</id>
    <updated>2019-05-14T10:41:53Z</updated>
    <published>2019-05-14T10:41:53Z</published>
    <title>Seismic Bayesian evidential learning: Estimation and uncertainty
  quantification of sub-resolution reservoir properties</title>
    <summary>  We present a framework that enables estimation of low-dimensional
sub-resolution reservoir properties directly from seismic data, without
requiring the solution of a high dimensional seismic inverse problem. Our
workflow is based on the Bayesian evidential learning approach and exploits
learning the direct relation between seismic data and reservoir properties to
efficiently estimate reservoir properties. The theoretical framework we develop
allows incorporation of non-linear statistical models for seismic estimation
problems. Uncertainty quantification is performed with Approximate Bayesian
Computation. With the help of a synthetic example of estimation of reservoir
net-to-gross and average fluid saturations in sub-resolution thin-sand
reservoir, several nuances are foregrounded regarding the applicability of
unsupervised and supervised learning methods for seismic estimation problems.
Finally, we demonstrate the efficacy of our approach by estimating posterior
uncertainty of reservoir net-to-gross in sub-resolution thin-sand reservoir
from an offshore delta dataset using 3D pre-stack seismic data.
</summary>
    <author>
      <name>Anshuman Pradhan</name>
    </author>
    <author>
      <name>Tapan Mukerji</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Computational Geosciences</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.05508v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.05508v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.12060v1</id>
    <updated>2019-03-21T19:10:14Z</updated>
    <published>2019-03-21T19:10:14Z</published>
    <title>Penobscot Dataset: Fostering Machine Learning Development for Seismic
  Interpretation</title>
    <summary>  We have seen in the past years the flourishing of machine and deep learning
algorithms in several applications such as image classification and
segmentation, object detection and recognition, among many others. This was
only possible, in part, because datasets like ImageNet -- with +14 million
labeled images -- were created and made publicly available, providing
researches with a common ground to compare their advances and extend the
state-of-the-art. Although we have seen an increasing interest in machine
learning in geosciences as well, we will only be able to achieve a significant
impact in our community if we collaborate to build such a common basis. This is
even more difficult when it comes to the Oil&amp;Gas industry, in which
confidentiality and commercial interests often hinder the sharing of datasets
with others. In this letter, we present the Penobscot interpretation dataset,
our contribution to the development of machine learning in geosciences, more
specifically in seismic interpretation. The Penobscot 3D seismic dataset was
acquired in the Scotian shelf, offshore Nova Scotia, Canada. The data is
publicly available and comprises pre- and pos-stack data, 5 horizons and well
logs of 2 wells. However, for the dataset to be of practical use for our tasks,
we had to reinterpret the seismic, generating 7 horizons separating different
seismic facies intervals. The interpreted horizons were used to generated
+100,000 labeled images for inlines and crosslines. To demonstrate the utility
of our dataset, results of two experiments are presented.
</summary>
    <author>
      <name>Lais Baroni</name>
    </author>
    <author>
      <name>Reinaldo Mozart Silva</name>
    </author>
    <author>
      <name>Rodrigo S. Ferreira</name>
    </author>
    <author>
      <name>Daniel Civitarese</name>
    </author>
    <author>
      <name>Daniela Szwarcman</name>
    </author>
    <author>
      <name>Emilio Vital Brazil</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.12060v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.12060v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.06250v1</id>
    <updated>2019-06-14T15:31:59Z</updated>
    <published>2019-06-14T15:31:59Z</published>
    <title>Machine Learning Approach to Earthquake Rupture Dynamics</title>
    <summary>  Simulating dynamic rupture propagation is challenging due to the
uncertainties involved in the underlying physics of fault slip, stress
conditions, and frictional properties of the fault. A trial and error approach
is often used to determine the unknown parameters describing rupture, but
running many simulations usually requires human review to determine how to
adjust parameter values and is thus not very efficient. To reduce the
computational cost and improve our ability to determine reasonable stress and
friction parameters, we take advantage of the machine learning approach. We
develop two models for earthquake rupture propagation using the artificial
neural network (ANN) and the random forest (RF) algorithms to predict if a
rupture can break a geometric heterogeneity on a fault. We train the models
using a database of 1600 dynamic rupture simulations computed numerically.
Fault geometry, stress conditions, and friction parameters vary in each
simulation. We cross-validate and test the predictive power of the models using
an additional 400 simulated ruptures, respectively. Both RF and ANN models
predict rupture propagation with more than 81% accuracy, and model parameters
can be used to infer the underlying factors most important for rupture
propagation. Both of the models are computationally efficient such that the 400
testings require a fraction of a second, leading to potential applications of
dynamic rupture that have previously not been possible due to the computational
demands of physics-based rupture simulations.
</summary>
    <author>
      <name>Sabber Ahamed</name>
    </author>
    <author>
      <name>Eric G. Daub</name>
    </author>
    <link href="http://arxiv.org/abs/1906.06250v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.06250v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1804.08697v1</id>
    <updated>2018-04-23T20:03:46Z</updated>
    <published>2018-04-23T20:03:46Z</published>
    <title>Simultaneous shot inversion for nonuniform geometries using fast data
  interpolation</title>
    <summary>  Stochastic optimization is key to efficient inversion in PDE-constrained
optimization. Using 'simultaneous shots', or random superposition of source
terms, works very well in simple acquisition geometries where all sources see
all receivers, but this rarely occurs in practice. We develop an approach that
interpolates data to an ideal acquisition geometry while solving the inverse
problem using simultaneous shots. The approach is formulated as a joint inverse
problem, combining ideas from low-rank interpolation with full-waveform
inversion. Results using synthetic experiments illustrate the flexibility and
efficiency of the approach.
</summary>
    <author>
      <name>Michelle Liu</name>
    </author>
    <author>
      <name>Rajiv Kumar</name>
    </author>
    <author>
      <name>Eldad Haber</name>
    </author>
    <author>
      <name>Aleksandr Aravkin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1804.08697v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1804.08697v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65K05, 65K10, 86-08" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.06689v1</id>
    <updated>2018-05-17T10:37:50Z</updated>
    <published>2018-05-17T10:37:50Z</published>
    <title>Breaking Cascadia's Silence: Machine Learning Reveals the Constant
  Chatter of the Megathrust</title>
    <summary>  Tectonic faults slip in various manners, ranging from ordinary earthquakes to
slow slip events to aseismic fault creep. The frequent occurrence of slow
earthquakes and their sensitivity to stress make them a promising probe of the
neighboring locked zone where megaquakes take place. This relationship,
however, remains poorly understood. We show that the Cascadia megathrust is
continuously broadcasting a tremor-like signal that precisely informs of fault
displacement rate throughout the slow slip cycle. We posit that this signal
provides indirect, real-time access to physical properties of the megathrust
and may ultimately reveal a connection between slow slip and megaquakes.
</summary>
    <author>
      <name>Bertrand Rouet-Leduc</name>
    </author>
    <author>
      <name>Claudia Hulbert</name>
    </author>
    <author>
      <name>Paul A. Johnson</name>
    </author>
    <link href="http://arxiv.org/abs/1805.06689v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.06689v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.01750v1</id>
    <updated>2017-06-06T13:27:28Z</updated>
    <published>2017-06-06T13:27:28Z</published>
    <title>Multi-View Kernels for Low-Dimensional Modeling of Seismic Events</title>
    <summary>  The problem of learning from seismic recordings has been studied for years.
There is a growing interest in developing automatic mechanisms for identifying
the properties of a seismic event. One main motivation is the ability have a
reliable identification of man-made explosions. The availability of multiple
high-dimensional observations has increased the use of machine learning
techniques in a variety of fields. In this work, we propose to use a
kernel-fusion based dimensionality reduction framework for generating
meaningful seismic representations from raw data. The proposed method is tested
on 2023 events that were recorded in Israel and in Jordan. The method achieves
promising results in classification of event type as well as in estimating the
location of the event. The proposed fusion and dimensionality reduction tools
may be applied to other types of geophysical data.
</summary>
    <author>
      <name>Ofir Lindenbaum</name>
    </author>
    <author>
      <name>Yuri Bregman</name>
    </author>
    <author>
      <name>Neta Rabin</name>
    </author>
    <author>
      <name>Amir Averbuch</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TGRS.2018.2797537</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TGRS.2018.2797537" rel="related"/>
    <link href="http://arxiv.org/abs/1706.01750v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.01750v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.05141v2</id>
    <updated>2018-02-15T03:16:08Z</updated>
    <published>2018-02-14T15:03:09Z</published>
    <title>Deep Learning and Data Assimilation for Real-Time Production Prediction
  in Natural Gas Wells</title>
    <summary>  The prediction of the gas production from mature gas wells, due to their
complex end-of-life behavior, is challenging and crucial for operational
decision making. In this paper, we apply a modified deep LSTM model for
prediction of the gas flow rates in mature gas wells, including the
uncertainties in input parameters. Additionally, due to changes in the system
in time and in order to increase the accuracy and robustness of the prediction,
the Ensemble Kalman Filter (EnKF) is used to update the flow rate predictions
based on new observations. The developed approach was tested on the data from
two mature gas production wells in which their production is highly dynamic and
suffering from salt deposition. The results show that the flow predictions
using the EnKF updated model leads to better Jeffreys' J-divergences than the
predictions without the EnKF model updating scheme.
</summary>
    <author>
      <name>Kelvin Loh</name>
    </author>
    <author>
      <name>Pejman Shoeibi Omrani</name>
    </author>
    <author>
      <name>Ruud van der Linden</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Reduced length preprint submitted to IJCAI 2018 for review</arxiv:comment>
    <link href="http://arxiv.org/abs/1802.05141v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.05141v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.00511v1</id>
    <updated>2018-11-28T09:55:53Z</updated>
    <published>2018-11-28T09:55:53Z</published>
    <title>Ensemble model aggregation using a computationally lightweight
  machine-learning model to forecast ocean waves</title>
    <summary>  This study investigated an approach to improve the accuracy of
computationally lightweight surrogate models by updating forecasts based on
historical accuracy relative to sparse observation data. Using a lightweight,
ocean-wave forecasting model, we created a large number of model ensembles,
with perturbed inputs, for a two-year study period. Forecasts were aggregated
using a machine-learning algorithm that combined forecasts from multiple,
independent models into a single 'best-estimate' prediction of the true state,
based on historical performance relative to observations. The framework was
applied to a case-study site in Monterey Bay, California.
A~learning-aggregation technique used historical observations and model
forecasts to calculate a weight for each ensemble member. Weighted ensemble
predictions were compared to measured wave conditions to evaluate performance
against present state-of-the-art. Finally, we discuss how this framework, which
integrates ensemble aggregations and surrogate models, can be used to improve
forecasting systems and scientific process studies.
</summary>
    <author>
      <name>Fearghal O'Donncha</name>
    </author>
    <author>
      <name>Yushan Zhang</name>
    </author>
    <author>
      <name>Bei Chen</name>
    </author>
    <author>
      <name>Scott c. James</name>
    </author>
    <link href="http://arxiv.org/abs/1812.00511v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.00511v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.01094v1</id>
    <updated>2018-07-03T11:43:13Z</updated>
    <published>2018-07-03T11:43:13Z</published>
    <title>Recovering gaps in the gamma-ray logging method</title>
    <summary>  The gamma-ray logging method is one of the mandatory well logging methods for
geophysical exploration of wells. However, during the conduct of such a study,
the sensor, for one reason or another, may stop recording observations in the
well. If a small number of values are missing, you can restore these values
using standard methods to fill in gaps like in time series. If data miss a
large number of values, observations usually are made again, which leads to
additional financial costs. This work proposes an alternative solution, in the
form of filling missed observations in data with the help of machine learning
methods. The main idea of this method is to construct a simple two- layer
neural network that is trained on data from the well, and then synthesise the
missing values based on the trained neural network. This work evaluates the
effectiveness of the proposed method, and gives reasons for the appropriateness
of using different methods of filling gaps, depending on the number of missed
values.
</summary>
    <author>
      <name>N. S. Churikov</name>
    </author>
    <author>
      <name>N. G. Grafeeva</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures, SGEM conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1807.01094v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.01094v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.05194v2</id>
    <updated>2016-11-04T02:04:52Z</updated>
    <published>2015-11-16T21:50:48Z</published>
    <title>Sparse-promoting Full Waveform Inversion based on Online Orthonormal
  Dictionary Learning</title>
    <summary>  Full waveform inversion (FWI) delivers high-resolution images of the
subsurface by minimizing iteratively the misfit between the recorded and
calculated seismic data. It has been attacked successfully with the
Gauss-Newton method and sparsity promoting regularization based on fixed
multiscale transforms that permit significant subsampling of the seismic data
when the model perturbation at each FWI data-fitting iteration can be
represented with sparse coefficients. Rather than using analytical transforms
with predefined dictionaries to achieve sparse representation, we introduce an
adaptive transform called the Sparse Orthonormal Transform (SOT) whose
dictionary is learned from many small training patches taken from the model
perturbations in previous iterations. The patch-based dictionary is constrained
to be orthonormal and trained with an online approach to provide the best
sparse representation of the complex features and variations of the entire
model perturbation. The complexity of the training method is proportional to
the cube of the number of samples in one small patch. By incorporating both
compressive subsampling and the adaptive SOT-based representation into the
Gauss-Newton least-squares problem for each FWI iteration, the model
perturbation can be recovered after an l1-norm sparsity constraint is applied
on the SOT coefficients. Numerical experiments on synthetic models demonstrate
that the SOT-based sparsity promoting regularization can provide robust FWI
results with reduced computation.
</summary>
    <author>
      <name>Lingchen Zhu</name>
    </author>
    <author>
      <name>Entao Liu</name>
    </author>
    <author>
      <name>James H. McClellan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has already been accepted by Geophysics</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.05194v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.05194v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.07328v1</id>
    <updated>2017-09-21T13:53:42Z</updated>
    <published>2017-09-21T13:53:42Z</published>
    <title>Stochastic parameterization identification using ensemble Kalman
  filtering combined with expectation-maximization and Newton-Raphson maximum
  likelihood methods</title>
    <summary>  For modelling geophysical systems, large-scale processes are described
through a set of coarse-grained dynamical equations while small-scale processes
are represented via parameterizations. This work proposes a method for
identifying the best possible stochastic parameterization from noisy data.
State-the-art sequential estimation methods such as Kalman and particle filters
do not achieve this goal succesfully because both suffer from the collapse of
the parameter posterior distribution. To overcome this intrinsic limitation, we
propose two statistical learning methods. They are based on the combination of
two methodologies: the maximization of the likelihood via
Expectation-Maximization (EM) and Newton-Raphson (NR) algorithms which are
mainly applied in the statistic and machine learning communities, and the
ensemble Kalman filter (EnKF). The methods are derived using a Bayesian
approach for a hidden Markov model. They are applied to infer deterministic and
stochastic physical parameters from noisy observations in coarse-grained
dynamical models. Numerical experiments are conducted using the Lorenz-96
dynamical system with one and two scales as a proof-of-concept. The imperfect
coarse-grained model is modelled through a one-scale Lorenz-96 system in which
a stochastic parameterization is incorpored to represent the small-scale
dynamics. The algorithms are able to identify an optimal stochastic
parameterization with a good accuracy under moderate observational noise. The
proposed EnKF-EM and EnKF-NR are promising statistical learning methods for
developing stochastic parameterizations in high-dimensional geophysical models.
</summary>
    <author>
      <name>Manuel Pulido</name>
    </author>
    <author>
      <name>Pierre Tandeo</name>
    </author>
    <author>
      <name>Marc Bocquet</name>
    </author>
    <author>
      <name>Alberto Carrassi</name>
    </author>
    <author>
      <name>Magdalena Lucini</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/16000870.2018.1442099</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/16000870.2018.1442099" rel="related"/>
    <link href="http://arxiv.org/abs/1709.07328v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.07328v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.04840v3</id>
    <updated>2017-03-15T22:51:17Z</updated>
    <published>2016-09-15T20:11:50Z</published>
    <title>Dictionary learning of sound speed profiles</title>
    <summary>  To provide constraints on their inversion, ocean sound speed profiles (SSPs)
often are modeled using empirical orthogonal functions (EOFs). However, this
regularization, which uses the leading order EOFs with a minimum-energy
constraint on their coefficients, often yields low resolution SSP estimates. In
this paper, it is shown that dictionary learning, a form of unsupervised
machine learning, can improve SSP resolution by generating a dictionary of
shape functions for sparse processing (e.g. compressive sensing) that optimally
compress SSPs; both minimizing the reconstruction error and the number of
coefficients. These learned dictionaries (LDs) are not constrained to be
orthogonal and thus, fit the given signals such that each signal example is
approximated using few LD entries. Here, LDs describing SSP observations from
the HF-97 experiment and the South China Sea are generated using the K-SVD
algorithm. These LDs better explain SSP variability and require fewer
coefficients than EOFs, describing much of the variability with one
coefficient. Thus, LDs improve the resolution of SSP estimates with negligible
computational burden.
</summary>
    <author>
      <name>Michael Bianco</name>
    </author>
    <author>
      <name>Peter Gerstoft</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1121/1.4977926</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1121/1.4977926" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in the Journal of the Acoustical Society of America</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J Acoust. Soc. Am. 141(3), 1749-1758, March 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1609.04840v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.04840v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.08655v1</id>
    <updated>2018-12-12T03:56:20Z</updated>
    <published>2018-12-12T03:56:20Z</published>
    <title>Surrogate-assisted Bayesian inversion for landscape and basin evolution
  models</title>
    <summary>  The complex and computationally expensive features of the forward landscape
and sedimentary basin evolution models pose a major challenge in the
development of efficient inference and optimization methods. Bayesian inference
provides a methodology for estimation and uncertainty quantification of free
model parameters. In our previous work, parallel tempering Bayeslands was
developed as a framework for parameter estimation and uncertainty
quantification for the landscape and basin evolution modelling software
Badlands. Parallel tempering Bayeslands features high-performance computing
with dozens of processing cores running in parallel to enhance computational
efficiency. Although parallel computing is used, the procedure remains
computationally challenging since thousands of samples need to be drawn and
evaluated. In large-scale landscape and basin evolution problems, a single
model evaluation can take from several minutes to hours, and in certain cases,
even days. Surrogate-assisted optimization has been with successfully applied
to a number of engineering problems. This motivates its use in optimisation and
inference methods suited for complex models in geology and geophysics.
Surrogates can speed up parallel tempering Bayeslands by developing
computationally inexpensive surrogates to mimic expensive models. In this
paper, we present an application of surrogate-assisted parallel tempering where
that surrogate mimics a landscape evolution model including erosion, sediment
transport and deposition, by estimating the likelihood function that is given
by the model. We employ a machine learning model as a surrogate that learns
from the samples generated by the parallel tempering algorithm. The results
show that the methodology is effective in lowering the overall computational
cost significantly while retaining the quality of solutions.
</summary>
    <author>
      <name>Rohitash Chandra</name>
    </author>
    <author>
      <name>Danial Azam</name>
    </author>
    <author>
      <name>Arpit Kapoor</name>
    </author>
    <author>
      <name>R. Dietmar Müller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Under review. arXiv admin note: text overlap with arXiv:1811.08687</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.08655v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.08655v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.12321v1</id>
    <updated>2019-05-29T10:47:42Z</updated>
    <published>2019-05-29T10:47:42Z</published>
    <title>Complex-valued neural networks for machine learning on non-stationary
  physical data</title>
    <summary>  Deep learning has become an area of interest in most scientific areas,
including physical sciences. Modern networks apply real-valued transformations
on the data. Particularly, convolutions in convolutional neural networks
discard phase information entirely. Many deterministic signals, such as seismic
data or electrical signals, contain significant information in the phase of the
signal. We explore complex-valued deep convolutional networks to leverage
non-linear feature maps. Seismic data commonly has a lowcut filter applied, to
attenuate noise from ocean waves and similar long wavelength contributions.
Discarding the phase information leads to low-frequency aliasing analogous to
the Nyquist-Shannon theorem for high frequencies. In non-stationary data, the
phase content can stabilize training and improve the generalizability of neural
networks. While it has been shown that phase content can be restored in deep
neural networks, we show how including phase information in feature maps
improves both training and inference from deterministic physical data.
Furthermore, we show that the reduction of parameters in a complex network
results in training on a smaller dataset without overfitting, in comparison to
a real-valued network with the same performance.
</summary>
    <author>
      <name>Jesper Sören Dramsch</name>
    </author>
    <author>
      <name>Mikael Lüthje</name>
    </author>
    <author>
      <name>Anders Nymark Christensen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages total, 8 pages, 2 pages references, conference paper, 9
  figures, 28 networks</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.12321v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.12321v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.04170v1</id>
    <updated>2017-03-12T20:30:56Z</updated>
    <published>2017-03-12T20:30:56Z</published>
    <title>Leak Event Identification in Water Systems Using High Order CRF</title>
    <summary>  Today, detection of anomalous events in civil infrastructures (e.g. water
pipe breaks and leaks) is time consuming and often takes hours or days. Pipe
breakage as one of the most frequent types of failure of water networks often
causes community disruptions ranging from temporary interruptions in services
to extended loss of business and relocation of residents. In this project, we
design and implement a two-phase approach for leak event identification, which
leverages dynamic data from multiple information sources including IoT sensing
data (pressure values and/or flow rates), geophysical data (water systems), and
human inputs (tweets posted on Twitter). In the approach, a high order
Conditional Random Field (CRF) is constructed that enforces predictions based
on IoT observations consistent with human inputs to improve the performance of
event identifications.
  Considering the physical water network as a graph, a CRF model is built and
learned by the Structured Support Vector Machine (SSVM) using node features
such as water pressure and flow rate. After that, we built the high order CRF
system by enforcing twitter leakage detection information. An optimal inference
algorithm is proposed for the adapted high order CRF model. Experimental
results show the effectiveness of our system.
</summary>
    <author>
      <name>Qing Han</name>
    </author>
    <author>
      <name>Wentao Zhu</name>
    </author>
    <author>
      <name>Yang Shi</name>
    </author>
    <link href="http://arxiv.org/abs/1703.04170v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.04170v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.05094v1</id>
    <updated>2017-08-16T22:08:25Z</updated>
    <published>2017-08-16T22:08:25Z</published>
    <title>An Ensemble Quadratic Echo State Network for Nonlinear Spatio-Temporal
  Forecasting</title>
    <summary>  Spatio-temporal data and processes are prevalent across a wide variety of
scientific disciplines. These processes are often characterized by nonlinear
time dynamics that include interactions across multiple scales of spatial and
temporal variability. The data sets associated with many of these processes are
increasing in size due to advances in automated data measurement, management,
and numerical simulator output. Non- linear spatio-temporal models have only
recently seen interest in statistics, but there are many classes of such models
in the engineering and geophysical sciences. Tradi- tionally, these models are
more heuristic than those that have been presented in the statistics
literature, but are often intuitive and quite efficient computationally. We
show here that with fairly simple, but important, enhancements, the echo state
net- work (ESN) machine learning approach can be used to generate long-lead
forecasts of nonlinear spatio-temporal processes, with reasonable uncertainty
quantification, and at only a fraction of the computational expense of a
traditional parametric nonlinear spatio-temporal models.
</summary>
    <author>
      <name>Patrick L. McDermott</name>
    </author>
    <author>
      <name>Christopher K. Wikle</name>
    </author>
    <link href="http://arxiv.org/abs/1708.05094v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.05094v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.07806v1</id>
    <updated>2018-01-23T23:06:06Z</updated>
    <published>2018-01-23T23:06:06Z</published>
    <title>Estimating the Physical State of a Laboratory Slow Slipping Fault from
  Seismic Signals</title>
    <summary>  Over the last two decades, strain and GPS measurements have shown that slow
slip on earthquake faults is a widespread phenomenon. Slow slip is also
inferred from correlated small amplitude seismic signals known as nonvolcanic
tremor and low frequency earthquakes (LFEs). Slow slip has been reproduced in
laboratory and simulation studies, however the fundamental physics of these
phenomena and their relationship to dynamic earthquake rupture remains poorly
understood. Here we show that, in a laboratory setting, continuous seismic
waves are imprinted with fundamental signatures of the fault's physical state.
Using machine learning on continuous seismic waves, we can infer several bulk
characteristics of the fault (friction, shear displacement, gouge thickness),
at any time during the slow slip cycle. This analysis also allows us to infer
many properties of the future behavior of the fault, including the time
remaining before the next slow slip event. Our work suggests that by applying
machine learning approaches to continuous seismic data, new insight into the
physics of slow slip could be obtained in Earth.
</summary>
    <author>
      <name>Claudia Hulbert</name>
    </author>
    <author>
      <name>Bertrand Rouet-Leduc</name>
    </author>
    <author>
      <name>Christopher X. Ren</name>
    </author>
    <author>
      <name>Jacques Riviere</name>
    </author>
    <author>
      <name>David C. Bolton</name>
    </author>
    <author>
      <name>Chris Marone</name>
    </author>
    <author>
      <name>Paul A. Johnson</name>
    </author>
    <link href="http://arxiv.org/abs/1801.07806v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.07806v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.00144v1</id>
    <updated>2018-06-01T00:10:04Z</updated>
    <published>2018-06-01T00:10:04Z</published>
    <title>Sea surface temperature prediction and reconstruction using patch-level
  neural network representations</title>
    <summary>  The forecasting and reconstruction of ocean and atmosphere dynamics from
satellite observation time series are key challenges. While model-driven
representations remain the classic approaches, data-driven representations
become more and more appealing to benefit from available large-scale
observation and simulation datasets. In this work we investigate the relevance
of recently introduced bilinear residual neural network representations, which
mimic numerical integration schemes such as Runge-Kutta, for the forecasting
and assimilation of geophysical fields from satellite-derived remote sensing
data. As a case-study, we consider satellite-derived Sea Surface Temperature
time series off South Africa, which involves intense and complex upper ocean
dynamics. Our numerical experiments demonstrate that the proposed patch-level
neural-network-based representations outperform other data-driven models,
including analog schemes, both in terms of forecasting and missing data
interpolation performance with a relative gain up to 50\% for highly dynamic
areas.
</summary>
    <author>
      <name>Said Ouala</name>
    </author>
    <author>
      <name>Cedric Herzet</name>
    </author>
    <author>
      <name>Ronan Fablet</name>
    </author>
    <link href="http://arxiv.org/abs/1806.00144v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.00144v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.04846v3</id>
    <updated>2019-03-30T13:57:12Z</updated>
    <published>2019-01-15T14:29:04Z</published>
    <title>Soil Texture Classification with 1D Convolutional Neural Networks based
  on Hyperspectral Data</title>
    <summary>  Soil texture is important for many environmental processes. In this paper, we
study the classification of soil texture based on hyperspectral data. We
develop and implement three 1-dimensional (1D) convolutional neural networks
(CNN): the LucasCNN, the LucasResNet which contains an identity block as
residual network, and the LucasCoordConv with an additional coordinates layer.
Furthermore, we modify two existing 1D CNN approaches for the presented
classification task. The code of all five CNN approaches is available on GitHub
(Riese, 2019). We evaluate the performance of the CNN approaches and compare
them to a random forest classifier. Thereby, we rely on the freely available
LUCAS topsoil dataset. The CNN approach with the least depth turns out to be
the best performing classifier. The LucasCoordConv achieves the best
performance regarding the average accuracy. In future work, we can further
enhance the introduced LucasCNN, LucasResNet and LucasCoordConv and include
additional variables of the rich LUCAS dataset.
</summary>
    <author>
      <name>Felix M. Riese</name>
    </author>
    <author>
      <name>Sina Keller</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5194/isprs-annals-IV-2-W5-615-2019</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5194/isprs-annals-IV-2-W5-615-2019" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to the ISPRS Geospatial Week 2019 in Enschede (NL)</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.04846v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.04846v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.07859v1</id>
    <updated>2019-05-20T03:34:47Z</updated>
    <published>2019-05-20T03:34:47Z</published>
    <title>Artificial Neural Network Surrogate Modeling of Oil Reservoir: a Case
  Study</title>
    <summary>  We develop a data-driven model, introducing recent advances in machine
learning to reservoir simulation. We use a conventional reservoir modeling tool
to generate training set and a special ensemble of artificial neural networks
(ANNs) to build a predictive model. The ANN-based model allows to reproduce the
time dependence of fluids and pressure distribution within the computational
cells of the reservoir model. We compare the performance of the ANN-based model
with conventional reservoir modeling and illustrate that ANN-based model (1) is
able to capture all the output parameters of the conventional model with very
high accuracy and (2) demonstrate much higher computational performance. We
finally elaborate on further options for research and developments within the
area of reservoir modeling.
</summary>
    <author>
      <name>Oleg Sudakov</name>
    </author>
    <author>
      <name>Dmitri Koroteev</name>
    </author>
    <author>
      <name>Boris Belozerov</name>
    </author>
    <author>
      <name>Evgeny Burnaev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">16th International Symposium on Neural Networks, ISNN 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1905.07859v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.07859v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.04507v1</id>
    <updated>2019-06-11T11:56:47Z</updated>
    <published>2019-06-11T11:56:47Z</published>
    <title>Approximate Variational Inference Based on a Finite Sample of Gaussian
  Latent Variables</title>
    <summary>  Variational methods are employed in situations where exact Bayesian inference
becomes intractable due to the difficulty in performing certain integrals.
Typically, variational methods postulate a tractable posterior and formulate a
lower bound on the desired integral to be approximated, e.g. marginal
likelihood. The lower bound is then optimised with respect to its free
parameters, the so called variational parameters. However, this is not always
possible as for certain integrals it is very challenging (or tedious) to come
up with a suitable lower bound. Here we propose a simple scheme that overcomes
some of the awkward cases where the usual variational treatment becomes
difficult. The scheme relies on a rewriting of the lower bound on the model
log-likelihood. We demonstrate the proposed scheme on a number of synthetic and
real examples, as well as on a real geophysical model for which the standard
variational approaches are inapplicable.
</summary>
    <author>
      <name>Nikolaos Gianniotis</name>
    </author>
    <author>
      <name>Christoph Schnörr</name>
    </author>
    <author>
      <name>Christian Molkenthin</name>
    </author>
    <author>
      <name>Sanjay Singh Bora</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10044-015-0496-9</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10044-015-0496-9" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">published in Pattern Analysis and Applications</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Pattern Anal Applic (2016) 19: 475</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.04507v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.04507v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.03467v1</id>
    <updated>2019-01-11T03:24:55Z</updated>
    <published>2019-01-11T03:24:55Z</published>
    <title>Reliable Real-time Seismic Signal/Noise Discrimination with Machine
  Learning</title>
    <summary>  In Earthquake Early Warning (EEW), every sufficiently impulsive signal is
potentially the first evidence for an unfolding large earthquake. More often
than not, however, impulsive signals are mere nuisance signals. One of the most
fundamental - and difficult - tasks in EEW is to rapidly and reliably
discriminate real local earthquake signals from all other signals. This
discrimination is necessarily based on very little information, typically a few
seconds worth of seismic waveforms from a small number of stations. As a
result, current EEW systems struggle to avoid discrimination errors, and suffer
from false and missed alerts. In this study we show how modern machine learning
classifiers can strongly improve real-time signal/noise discrimination. We
develop and compare a series of non-linear classifiers with variable
architecture depths, including fully connected, convolutional (CNN) and
recurrent neural networks, and a model that combines a generative adversarial
network with a random forest (GAN+RF). We train all classifiers on the same
data set, which includes 374k local earthquake records (M3.0-9.1) and 946k
impulsive noise signals. We find that all classifiers outperform existing
simple linear classifiers, and that complex models trained directly on the raw
signals yield the greatest degree of improvement. Using 3s long waveform
snippets, the CNN and the GAN+RF classifiers both reach 99.5% precision and
99.3% recall on an independent validation data set. Most misclassifications
stem from impulsive teleseismic records, and from incorrectly labeled records
in the data set. Our results suggest that machine learning classifiers can
strongly improve the reliability and speed of EEW alerts.
</summary>
    <author>
      <name>Men-Andrin Meier</name>
    </author>
    <author>
      <name>Zachary E. Ross</name>
    </author>
    <author>
      <name>Anshul Ramachandran</name>
    </author>
    <author>
      <name>Ashwin Balakrishna</name>
    </author>
    <author>
      <name>Suraj Nair</name>
    </author>
    <author>
      <name>Peter Kundzicz</name>
    </author>
    <author>
      <name>Zefeng Li</name>
    </author>
    <author>
      <name>Jennifer Andrews</name>
    </author>
    <author>
      <name>Egill Hauksson</name>
    </author>
    <author>
      <name>Yisong Yue</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1029/2018JB016661</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1029/2018JB016661" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Geophysical Research: Solid Earth, 124 (2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1901.03467v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.03467v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.11019v2</id>
    <updated>2019-05-30T13:03:30Z</updated>
    <published>2018-06-28T14:56:39Z</published>
    <title>Integration of LiDAR and multispectral images for exposure and
  earthquake vulnerability estimation. Application in Lorca, Spain</title>
    <summary>  We present a procedure for assessing the urban exposure and seismic
vulnerability that integrates LiDAR data with aerial and satellite images. It
comprises three phases: first, we segment the satellite image to divide the
study area into different urban patterns. Second, we extract building
footprints and attributes that represent the type of building of each urban
pattern. Finally, we assign the seismic vulnerability to each building using
different machine-learning techniques: Decision trees, SVM, logistic regression
and Bayesian networks. We apply the procedure to 826 buildings in the city of
Lorca (SE Spain), where we count on a vulnerability database that we use as
ground truth for the validation of results. The outcomes show that the machine
learning techniques have similar performance, yielding vulnerability
classification results with an accuracy of 77% - 80% (F1-Score). The procedure
is scalable and can be replicated in different areas. It is especially
interesting as a complement to conventional data gathering approaches for
disaster risk applications in areas where field surveys need to be restricted
to certain areas, dates or budget. Keywords LiDAR, satellite image, orthophoto,
image segmentation, machine learning, earthquake vulnerability.
</summary>
    <author>
      <name>Yolanda Torres</name>
    </author>
    <author>
      <name>Jose Juan Arranz</name>
    </author>
    <author>
      <name>Jorge M. Gaspar-Escribano</name>
    </author>
    <author>
      <name>Azadeh Haghi</name>
    </author>
    <author>
      <name>Sandra Martinez-Cuevas</name>
    </author>
    <author>
      <name>Belen Benito</name>
    </author>
    <author>
      <name>Juan Carlos Ojeda</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jag.2019.05.015</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jag.2019.05.015" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">I.J. of Applied Earth Observation and Geoinformation, 81, 161-175
  (2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1806.11019v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.11019v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.10936v1</id>
    <updated>2019-04-24T17:21:13Z</updated>
    <published>2019-04-24T17:21:13Z</published>
    <title>Seismic Inversion by Newtonian Machine Learning</title>
    <summary>  We present a wave-equation inversion method that inverts skeletonized data
for the subsurface velocity model. The skeletonized representation of the
seismic traces consists of the low-rank latent-space variables predicted by a
well-trained autoencoder neural network. The input to the autoencoder is the
recorded common shot gathers, and the implicit function theorem is used to
determine the perturbation of the skeletonized data with respect to the
velocity perturbation. The final velocity model is the one that best predicts
the observed latent-space parameters. Empirical results suggest that the
cycle-skipping problem is largely mitigated compared to the conventional full
waveform inversion (FWI) method by replacing the waveform differences by those
of the latent-space parameters. The advantage of this method over other
skeletonized data methods is that no manual picking of important features is
required because the skeletal data are automatically selected by the
autoencoder. The most significant contribution of this paper is that it
provides a general framework for using solutions to the governing PDE to invert
skeletal data generated by any type of a neural network. The governing equation
can be that for gravity, seismic waves, electromagnetic fields, and magnetic
fields. The input data can be the records from different types of data and
their skeletal features, as long as the model parameters are sensitive to their
perturbations. The skeletal data can be the latent space variables of an
autoencoder, a variational autoencoder, or a feature map from a convolutional
neural network (CNN), or principal component analysis (PCA) features. In other
words, we have combined the best features of Newtonian physics and the pattern
matching capabilities of machine learning to invert seismic data by Newtonian
machine learning.
</summary>
    <author>
      <name>Yuqing Chen</name>
    </author>
    <author>
      <name>Gerard T. Schuster</name>
    </author>
    <link href="http://arxiv.org/abs/1904.10936v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.10936v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.02962v2</id>
    <updated>2018-12-17T02:26:29Z</updated>
    <published>2017-04-10T17:36:59Z</published>
    <title>The Stability of the First Neumann Laplacian Eigenfunction Under Domain
  Deformations and Applications</title>
    <summary>  The robustness of manifold learning methods is often predicated on the
stability of the Neumann Laplacian eigenfunctions under deformations of the
assumed underlying domain. Indeed, many manifold learning methods are based on
approximating the Neumann Laplacian eigenfunctions on a manifold that is
assumed to underlie data, which is viewed through a source of distortion. In
this paper, we study the stability of the first Neumann Laplacian eigenfunction
with respect to deformations of a domain by a diffeomorphism. In particular, we
are interested in the stability of the first eigenfunction on tall thin domains
where, intuitively, the first Neumann Laplacian eigenfunction should only
depend on the length along the domain. We prove a rigorous version of this
statement and apply it to a machine learning problem in geophysical
interpretation.
</summary>
    <author>
      <name>Nicholas F. Marshall</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.02962v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.02962v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="35P99, 35Q86" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.06611v3</id>
    <updated>2017-09-11T18:38:40Z</updated>
    <published>2017-07-20T17:06:47Z</published>
    <title>Prolongation of SMAP to Spatio-temporally Seamless Coverage of
  Continental US Using a Deep Learning Neural Network</title>
    <summary>  The Soil Moisture Active Passive (SMAP) mission has delivered valuable
sensing of surface soil moisture since 2015. However, it has a short time span
and irregular revisit schedule. Utilizing a state-of-the-art time-series deep
learning neural network, Long Short-Term Memory (LSTM), we created a system
that predicts SMAP level-3 soil moisture data with atmospheric forcing,
model-simulated moisture, and static physiographic attributes as inputs. The
system removes most of the bias with model simulations and improves predicted
moisture climatology, achieving small test root-mean-squared error (&lt;0.035) and
high correlation coefficient &gt;0.87 for over 75\% of Continental United States,
including the forested Southeast. As the first application of LSTM in
hydrology, we show the proposed network avoids overfitting and is robust for
both temporal and spatial extrapolation tests. LSTM generalizes well across
regions with distinct climates and physiography. With high fidelity to SMAP,
LSTM shows great potential for hindcasting, data assimilation, and weather
forecasting.
</summary>
    <author>
      <name>Kuai Fang</name>
    </author>
    <author>
      <name>Chaopeng Shen</name>
    </author>
    <author>
      <name>Daniel Kifer</name>
    </author>
    <author>
      <name>Xiao Yang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/2017GL075619</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/2017GL075619" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Geophysical Research Letters, 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1707.06611v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.06611v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.05912v2</id>
    <updated>2018-02-06T08:57:21Z</updated>
    <published>2017-09-18T13:26:25Z</published>
    <title>Estimating regional ground-level PM2.5 directly from satellite
  top-of-atmosphere reflectance using deep learning</title>
    <summary>  Almost all remote sensing atmospheric PM2.5 estimation methods need satellite
aerosol optical depth (AOD) products, which are often retrieved from
top-of-atmosphere (TOA) reflectance via an atmospheric radiative transfer
model. Then, is it possible to estimate ground-level PM2.5 directly from
satellite TOA reflectance without a physical model? In this study, this
challenging work are achieved based on a machine learning model. Specifically,
we establish the relationship between PM2.5, satellite TOA reflectance,
observation angles, and meteorological factors in a deep learning architecture
(denoted as Ref-PM modeling). Taking the Wuhan Urban Agglomeration (WUA) as a
case study, the results demonstrate that compared with the AOD-PM modeling, the
Ref-PM modeling obtains a competitive performance, with out-of-sample
cross-validated R2 and RMSE values of 0.87 and 9.89 ug/m3 respectively. Also,
the TOA-reflectance-derived PM2.5 have a finer resolution and larger spatial
coverage than the AOD-derived PM2.5. This work updates the traditional
cognition of remote sensing PM2.5 estimation and has the potential to promote
the application in atmospheric environmental monitoring.
</summary>
    <author>
      <name>Huanfeng Shen</name>
    </author>
    <author>
      <name>Tongwen Li</name>
    </author>
    <author>
      <name>Qiangqiang Yuan</name>
    </author>
    <author>
      <name>Liangpei Zhang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1029/2018JD028759</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1029/2018JD028759" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper is under review</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of geophysical research: Atmosphere (2018)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1709.05912v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.05912v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.05799v1</id>
    <updated>2017-11-15T20:50:08Z</updated>
    <published>2017-11-15T20:50:08Z</published>
    <title>ORBIT: Ordering Based Information Transfer Across Space and Time for
  Global Surface Water Monitoring</title>
    <summary>  Many earth science applications require data at both high spatial and
temporal resolution for effective monitoring of various ecosystem resources.
Due to practical limitations in sensor design, there is often a trade-off in
different resolutions of spatio-temporal datasets and hence a single sensor
alone cannot provide the required information. Various data fusion methods have
been proposed in the literature that mainly rely on individual timesteps when
both datasets are available to learn a mapping between features values at
different resolutions using local relationships between pixels. Earth
observation data is often plagued with spatially and temporally correlated
noise, outliers and missing data due to atmospheric disturbances which pose a
challenge in learning the mapping from a local neighborhood at individual
timesteps. In this paper, we aim to exploit time-independent global
relationships between pixels for robust transfer of information across
different scales. Specifically, we propose a new framework, ORBIT (Ordering
Based Information Transfer) that uses relative ordering constraint among pixels
to transfer information across both time and scales. The effectiveness of the
framework is demonstrated for global surface water monitoring using both
synthetic and real-world datasets.
</summary>
    <author>
      <name>Ankush Khandelwal</name>
    </author>
    <author>
      <name>Anuj Karpatne</name>
    </author>
    <author>
      <name>Vipin Kumar</name>
    </author>
    <link href="http://arxiv.org/abs/1711.05799v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.05799v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1712.08655v3</id>
    <updated>2018-05-16T04:09:57Z</updated>
    <published>2017-12-16T02:28:40Z</published>
    <title>Travel time tomography with adaptive dictionaries</title>
    <summary>  We develop a 2D travel time tomography method which regularizes the inversion
by modeling groups of slowness pixels from discrete slowness maps, called
patches, as sparse linear combinations of atoms from a dictionary. We propose
to use dictionary learning during the inversion to adapt dictionaries to
specific slowness maps. This patch regularization, called the local model, is
integrated into the overall slowness map, called the global model. The local
model considers small-scale variations using a sparsity constraint and the
global model considers larger-scale features constrained using $\ell_2$
regularization. This strategy in a locally-sparse travel time tomography (LST)
approach enables simultaneous modeling of smooth and discontinuous slowness
features. This is in contrast to conventional tomography methods, which
constrain models to be exclusively smooth or discontinuous. We develop a
$\textit{maximum a posteriori}$ formulation for LST and exploit the sparsity of
slowness patches using dictionary learning. The LST approach compares favorably
with smoothness and total variation regularization methods on densely, but
irregularly sampled synthetic slowness maps.
</summary>
    <author>
      <name>Michael Bianco</name>
    </author>
    <author>
      <name>Peter Gerstoft</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to IEEE Transactions on Computational Imaging (1st
  revision)</arxiv:comment>
    <link href="http://arxiv.org/abs/1712.08655v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1712.08655v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.00496v1</id>
    <updated>2019-06-30T23:24:24Z</updated>
    <published>2019-06-30T23:24:24Z</published>
    <title>Directivity Modes of Earthquake Populations with Unsupervised Learning</title>
    <summary>  We present a novel approach for resolving modes of rupture directivity in
large populations of earthquakes. A seismic spectral decomposition technique is
used to first produce relative measurements of radiated energy for earthquakes
in a spatially-compact cluster. The azimuthal distribution of energy for each
earthquake is then assumed to result from one of several distinct modes of
rupture propagation. Rather than fitting a kinematic rupture model to determine
the most likely mode of rupture propagation, we instead treat the modes as
latent variables and learn them with a Gaussian mixture model. The mixture
model simultaneously determines the number of events that best identify with
each mode. The technique is demonstrated on four datasets in California with
several thousand earthquakes. We show that the datasets naturally decompose
into distinct rupture propagation modes that correspond to different rupture
directions, and the fault plane is unambiguously identified for all cases. We
find that these small earthquakes exhibit unilateral ruptures 53-74% of the
time on average. The results provide important observational constraints on the
physics of earthquakes and faults.
</summary>
    <author>
      <name>Zachary E. Ross</name>
    </author>
    <author>
      <name>Daniel T. Trugman</name>
    </author>
    <author>
      <name>Kamyar Azizzadenesheli</name>
    </author>
    <author>
      <name>Anima Anandkumar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.00496v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.00496v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.00500v1</id>
    <updated>2019-06-30T23:55:58Z</updated>
    <published>2019-06-30T23:55:58Z</published>
    <title>Learning Argo Profiles by using the Signature Method</title>
    <summary>  A profile from the Argo ocean observing array is a sequence of
three-dimensional vectors composed of pressure, salinity, and temperature,
appearing as a continuous curve in three-dimensional space.The shape of such
curve is faithfully represented by a path signature, a collection of all the
iterated integrals. Moreover, the product of two terms of the signature of a
path can be expressed as a sum of higher order terms. Thanks to this algebraic
property,a nonlinear function of profile shape can always be represented by a
weighted linear combination of the iterated integrals,which makes easy to
perform machine learning of a complicated function of the profile shape. In
this study, we perform a supervised learning of existing Argo data with quality
control flags using the signature method, and demonstrate the prediction skill
by cross-validation. This technique should be a key to realizing an automatic
quality control of the Argo profile data.
</summary>
    <author>
      <name>Nozomi Sugiura</name>
    </author>
    <author>
      <name>Shigeki Hosoda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages. 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.00500v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.00500v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.01497v1</id>
    <updated>2019-07-02T17:02:53Z</updated>
    <published>2019-07-02T17:02:53Z</published>
    <title>Seismic data denoising and deblending using deep learning</title>
    <summary>  An important step of seismic data processing is removing noise, including
interference due to simultaneous and blended sources, from the recorded data.
Traditional methods are time-consuming to apply as they often require manual
choosing of parameters to obtain good results. We use deep learning, with a
U-net model incorporating a ResNet architecture pretrained on ImageNet and
further trained on synthetic seismic data, to perform this task. The method is
applied to common offset gathers, with adjacent offset gathers of the gather
being denoised provided as additional input channels. Here we show that this
approach leads to a method that removes noise from several datasets recorded in
different parts of the world with moderate success. We find that providing
three adjacent offset gathers on either side of the gather being denoised is
most effective. As this method does not require parameters to be chosen, it is
more automated than traditional methods.
</summary>
    <author>
      <name>Alan Richardson</name>
    </author>
    <author>
      <name>Caelen Feller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.01497v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.01497v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.05306v1</id>
    <updated>2019-01-14T03:43:42Z</updated>
    <published>2019-01-14T03:43:42Z</published>
    <title>Learning to Label Seismic Structures with Deconvolution Networks and
  Weak Labels</title>
    <summary>  Recently, there has been increasing interest in using deep learning
techniques for various seismic interpretation tasks. However, unlike shallow
machine learning models, deep learning models are often far more complex and
can have hundreds of millions of free parameters. This not only means that
large amounts of computational resources are needed to train these models, but
more critically, they require vast amounts of labeled training data as well. In
this work, we show how automatically-generated weak labels can be effectively
used to overcome this problem and train powerful deep learning models for
labeling seismic structures in large seismic volumes. To achieve this, we
automatically generate thousands of weak labels and use them to train a
deconvolutional network for labeling fault, salt dome, and chaotic regions
within the Netherlands F3 block. Furthermore, we show how modifying the loss
function to take into account the weak training labels helps reduce false
positives in the labeling results. The benefit of this work is that it enables
the effective training and deployment of deep learning models to various
seismic interpretation tasks without requiring any manual labeling effort. We
show excellent results on the Netherlands F3 block, and show how our model
outperforms other baseline models.
</summary>
    <author>
      <name>Yazeed Alaudah</name>
    </author>
    <author>
      <name>Shan Gao</name>
    </author>
    <author>
      <name>Ghassan AlRegib</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1190/segam2018-2997865.1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1190/segam2018-2997865.1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in the proceedings of the Society of Exploration
  Geophysicists' 2018 Annual Meeting</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SEG Technical Program Expanded Abstracts 2018: pp. 2121-2125</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1901.05306v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.05306v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.04103v2</id>
    <updated>2017-04-08T06:39:31Z</updated>
    <published>2016-09-14T01:01:29Z</published>
    <title>A Machine Learning Nowcasting Method based on Real-time Reanalysis Data</title>
    <summary>  Despite marked progress over the past several decades, convective storm
nowcasting remains a challenge because most nowcasting systems are based on
linear extrapolation of radar reflectivity without much consideration for other
meteorological fields. The variational Doppler radar analysis system (VDRAS) is
an advanced convective-scale analysis system capable of providing analysis of
3-D wind, temperature, and humidity by assimilating Doppler radar observations.
Although potentially useful, it is still an open question as to how to use
these fields to improve nowcasting. In this study, we present results from our
first attempt at developing a Support Vector Machine (SVM) Box-based nOWcasting
(SBOW) method under the machine learning framework using VDRAS analysis data.
The key design points of SBOW are as follows: 1) The study domain is divided
into many position-fixed small boxes and the nowcasting problem is transformed
into one question, i.e., will a radar echo &gt; 35 dBZ appear in a box in 30
minutes? 2) Box-based temporal and spatial features, which include time trends
and surrounding environmental information, are elaborately constructed, and 3)
The box-based constructed features are used to first train the SVM classifier,
and then the trained classifier is used to make predictions. Compared with
complicated and expensive expert systems, the above design of SBOW allows the
system to be small, compact, straightforward, and easy to maintain and expand
at low cost. The experimental results show that, although no complicated
tracking algorithm is used, SBOW can predict the storm movement trend and storm
growth with reasonable skill.
</summary>
    <author>
      <name>Lei Han</name>
    </author>
    <author>
      <name>Juanzhen Sun</name>
    </author>
    <author>
      <name>Wei Zhang</name>
    </author>
    <author>
      <name>Yuanyuan Xiu</name>
    </author>
    <author>
      <name>Hailei Feng</name>
    </author>
    <author>
      <name>Yinjing Lin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/2016JD025783</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/2016JD025783" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 11 figures, submitted to Journal of Geophysical Research:
  Atmospheres</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Geophys. Res. Atmos., 122, (2017)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1609.04103v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.04103v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1712.09016v2</id>
    <updated>2018-04-04T06:33:58Z</updated>
    <published>2017-12-25T06:51:34Z</published>
    <title>Geochemical discrimination and characteristics of magmatic tectonic
  settings; a machine learning-based approach</title>
    <summary>  Geochemically discriminating between magmatism in different tectonic settings
remains a fundamental part of understanding the processes of magma generation
within the Earth's mantle. Here, we present an approach where machine-learning
(ML) methods are used for quantitative tectonic discrimination and feature
selection using global geochemical datasets containing data for volcanic rocks
generated in eight different tectonic settings. This study uses support vector
machine, random forest, and sparse multinomial regression (SMR) approaches. All
these ML methods with data for 20 elements and 5 isotopic ratios allowed the
successful geochemical discrimination between igneous rocks formed in eight
different tectonic settings with a discriminant ratio better than 83% for all
settings barring oceanic plateaus and back-arc basins. SMR is a particularly
powerful and interpretable ML method because it quantitatively identifies
geochemical signatures that characterize the tectonic settings of interest and
the characteristics of each sample as a probability of the membership of the
sample for each setting. We also present the most representative basalt
composition for each tectonic setting. The new data provide reference points
for future geochemical discussions. Our results indicate that at least 17
elements and isotopic ratios are required to characterize each tectonic
setting, suggesting that geochemical tectonic discrimination cannot be achieved
using only a small number of elemental compositions and/or isotopic ratios. The
results show that volcanic rocks formed in different tectonic settings have
unique geochemical signatures, indicating that both volcanic rock geochemistry
and magma generation processes are closely connected to the tectonic setting.
</summary>
    <author>
      <name>Kenta Ueki</name>
    </author>
    <author>
      <name>Hideitsu Hino</name>
    </author>
    <author>
      <name>Tatsu Kuwatani</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1029/2017GC007401</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1029/2017GC007401" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1712.09016v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1712.09016v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.02401v1</id>
    <updated>2019-06-06T03:52:12Z</updated>
    <published>2019-06-06T03:52:12Z</published>
    <title>Learning to regularize with a variational autoencoder for hydrologic
  inverse analysis</title>
    <summary>  Inverse problems often involve matching observational data using a physical
model that takes a large number of parameters as input. These problems tend to
be under-constrained and require regularization to impose additional structure
on the solution in parameter space. A central difficulty in regularization is
turning a complex conceptual model of this additional structure into a
functional mathematical form to be used in the inverse analysis. In this work
we propose a method of regularization involving a machine learning technique
known as a variational autoencoder (VAE). The VAE is trained to map a
low-dimensional set of latent variables with a simple structure to the
high-dimensional parameter space that has a complex structure. We train a VAE
on unconditioned realizations of the parameters for a hydrological inverse
problem. These unconditioned realizations neither rely on the observational
data used to perform the inverse analysis nor require any forward runs of the
physical model, thus making the computational cost of generating the training
data minimal. The central benefit of this approach is that regularization is
then performed on the latent variables from the VAE, which can be regularized
simply. A second benefit of this approach is that the VAE reduces the number of
variables in the optimization problem, thus making gradient-based optimization
more computationally efficient when adjoint methods are unavailable. After
performing regularization and optimization on the latent variables, the VAE
then decodes the problem back to the original parameter space. Our approach
constitutes a novel framework for regularization and optimization, readily
applicable to a wide range of inverse problems. We call the approach RegAE.
</summary>
    <author>
      <name>Daniel O'Malley</name>
    </author>
    <author>
      <name>John K. Golden</name>
    </author>
    <author>
      <name>Velimir V. Vesselinov</name>
    </author>
    <link href="http://arxiv.org/abs/1906.02401v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.02401v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.08884v2</id>
    <updated>2017-03-13T17:23:58Z</updated>
    <published>2017-01-31T01:25:21Z</published>
    <title>Enabling large-scale viscoelastic calculations via neural network
  acceleration</title>
    <summary>  One of the most significant challenges involved in efforts to understand the
effects of repeated earthquake cycle activity are the computational costs of
large-scale viscoelastic earthquake cycle models. Computationally intensive
viscoelastic codes must be evaluated thousands of times and locations, and as a
result, studies tend to adopt a few fixed rheological structures and model
geometries, and examine the predicted time-dependent deformation over short
(&lt;10 yr) time periods at a given depth after a large earthquake. Training a
deep neural network to learn a computationally efficient representation of
viscoelastic solutions, at any time, location, and for a large range of
rheological structures, allows these calculations to be done quickly and
reliably, with high spatial and temporal resolution. We demonstrate that this
machine learning approach accelerates viscoelastic calculations by more than
50,000%. This magnitude of acceleration will enable the modeling of
geometrically complex faults over thousands of earthquake cycles across wider
ranges of model parameters and at larger spatial and temporal scales than have
been previously possible.
</summary>
    <author>
      <name>Phoebe R. DeVries</name>
    </author>
    <author>
      <name>T. Ben Thompson</name>
    </author>
    <author>
      <name>Brendan J. Meade</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/2017GL072716</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/2017GL072716" rel="related"/>
    <link href="http://arxiv.org/abs/1701.08884v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.08884v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1712.02854v1</id>
    <updated>2017-12-07T20:21:01Z</updated>
    <published>2017-12-07T20:21:01Z</published>
    <title>Stochastic reconstruction of an oolitic limestone by generative
  adversarial networks</title>
    <summary>  Stochastic image reconstruction is a key part of modern digital rock physics
and materials analysis that aims to create numerous representative samples of
material micro-structures for upscaling, numerical computation of effective
properties and uncertainty quantification. We present a method of
three-dimensional stochastic image reconstruction based on generative
adversarial neural networks (GANs). GANs represent a framework of unsupervised
learning methods that require no a priori inference of the probability
distribution associated with the training data. Using a fully convolutional
neural network allows fast sampling of large volumetric images.We apply a GAN
based workflow of network training and image generation to an oolitic Ketton
limestone micro-CT dataset. Minkowski functionals, effective permeability as
well as velocity distributions of simulated flow within the acquired images are
compared with the synthetic reconstructions generated by the deep neural
network. While our results show that GANs allow a fast and accurate
reconstruction of the evaluated image dataset, we address a number of open
questions and challenges involved in the evaluation of generative network-based
methods.
</summary>
    <author>
      <name>Lukas Mosser</name>
    </author>
    <author>
      <name>Olivier Dubrule</name>
    </author>
    <author>
      <name>Martin J. Blunt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1712.02854v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1712.02854v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.09866v4</id>
    <updated>2018-01-30T01:40:56Z</updated>
    <published>2017-05-27T21:12:23Z</published>
    <title>Machine learning for graph-based representations of three-dimensional
  discrete fracture networks</title>
    <summary>  Structural and topological information play a key role in modeling flow and
transport through fractured rock in the subsurface. Discrete fracture network
(DFN) computational suites such as dfnWorks are designed to simulate flow and
transport in such porous media. Flow and transport calculations reveal that a
small backbone of fractures exists, where most flow and transport occurs.
Restricting the flowing fracture network to this backbone provides a
significant reduction in the network's effective size. However, the particle
tracking simulations needed to determine the reduction are computationally
intensive. Such methods may be impractical for large systems or for robust
uncertainty quantification of fracture networks, where thousands of forward
simulations are needed to bound system behavior.
  In this paper, we develop an alternative network reduction approach to
characterizing transport in DFNs, by combining graph theoretical and machine
learning methods. We consider a graph representation where nodes signify
fractures and edges denote their intersections. Using random forest and support
vector machines, we rapidly identify a subnetwork that captures the flow
patterns of the full DFN, based primarily on node centrality features in the
graph. Our supervised learning techniques train on particle-tracking backbone
paths found by dfnWorks, but run in negligible time compared to those
simulations. We find that our predictions can reduce the network to
approximately 20% of its original size, while still generating breakthrough
curves consistent with those of the original network.
</summary>
    <author>
      <name>Manuel Valera</name>
    </author>
    <author>
      <name>Zhengyang Guo</name>
    </author>
    <author>
      <name>Priscilla Kelly</name>
    </author>
    <author>
      <name>Sean Matz</name>
    </author>
    <author>
      <name>Vito Adrian Cantu</name>
    </author>
    <author>
      <name>Allon G. Percus</name>
    </author>
    <author>
      <name>Jeffrey D. Hyman</name>
    </author>
    <author>
      <name>Gowri Srinivasan</name>
    </author>
    <author>
      <name>Hari S. Viswanathan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10596-018-9720-1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10596-018-9720-1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Geosciences (2018)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Geosciences 22, 695-710 (2018)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1705.09866v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.09866v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.01488v1</id>
    <updated>2018-10-01T15:47:34Z</updated>
    <published>2018-10-01T15:47:34Z</published>
    <title>Using Machine Learning to Discern Eruption in Noisy Environments: A Case
  Study using CO2-driven Cold-Water Geyser in Chimayo, New Mexico</title>
    <summary>  We present an approach based on machine learning (ML) to distinguish eruption
and precursory signals of Chimay\'{o} geyser (New Mexico, USA) under noisy
environments. This geyser can be considered as a natural analog of
$\mathrm{CO}_2$ intrusion into shallow water aquifers. By studying this geyser,
we can understand upwelling of $\mathrm{CO}_2$-rich fluids from depth, which
has relevance to leak monitoring in a $\mathrm{CO}_2$ sequestration project. ML
methods such as Random Forests (RF) are known to be robust multi-class
classifiers and perform well under unfavorable noisy conditions. However, the
extent of the RF method's accuracy is poorly understood for this
$\mathrm{CO}_2$-driven geysering application. The current study aims to
quantify the performance of RF-classifiers to discern the geyser state. Towards
this goal, we first present the data collected from the seismometer that is
installed near the Chimay\'{o} geyser. The seismic signals collected at this
site contain different types of noises such as daily temperature variations,
seasonal trends, animal movement near the geyser, and human activity. First, we
filter the signals from these noises by combining the Butterworth-Highpass
filter and an Autoregressive method in a multi-level fashion. We show that by
combining these filtering techniques, in a hierarchical fashion, leads to
reduction in the noise in the seismic data without removing the precursors and
eruption event signals. We then use RF on the filtered data to classify the
state of geyser into three classes -- remnant noise, precursor, and eruption
states. We show that the classification accuracy using RF on the filtered data
is greater than 90\%.These aspects make the proposed ML framework attractive
for event discrimination and signal enhancement under noisy conditions, with
strong potential for application to monitoring leaks in $\mathrm{CO}_2$
sequestration.
</summary>
    <author>
      <name>B. Yuan</name>
    </author>
    <author>
      <name>Y. J. Tan</name>
    </author>
    <author>
      <name>M. K. Mudunuru</name>
    </author>
    <author>
      <name>O. E. Marcillo</name>
    </author>
    <author>
      <name>A. A. Delorey</name>
    </author>
    <author>
      <name>P. M. Roberts</name>
    </author>
    <author>
      <name>J. D. Webster</name>
    </author>
    <author>
      <name>C. N. L. Gammans</name>
    </author>
    <author>
      <name>S. Karra</name>
    </author>
    <author>
      <name>G. D. Guthrie</name>
    </author>
    <author>
      <name>P. A. Johnson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages,7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1810.01488v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.01488v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.01933v1</id>
    <updated>2019-01-31T16:28:16Z</updated>
    <published>2019-01-31T16:28:16Z</published>
    <title>Combining Physically-Based Modeling and Deep Learning for Fusing GRACE
  Satellite Data: Can We Learn from Mismatch?</title>
    <summary>  Global hydrological and land surface models are increasingly used for
tracking terrestrial total water storage (TWS) dynamics, but the utility of
existing models is hampered by conceptual and/or data uncertainties related to
various underrepresented and unrepresented processes, such as groundwater
storage. The gravity recovery and climate experiment (GRACE) satellite mission
provided a valuable independent data source for tracking TWS at regional and
continental scales. Strong interests exist in fusing GRACE data into global
hydrological models to improve their predictive performance. Here we develop
and apply deep convolutional neural network (CNN) models to learn the
spatiotemporal patterns of mismatch between TWS anomalies (TWSA) derived from
GRACE and those simulated by NOAH, a widely used land surface model. Once
trained, our CNN models can be used to correct the NOAH simulated TWSA without
requiring GRACE data, potentially filling the data gap between GRACE and its
follow-on mission, GRACE-FO. Our methodology is demonstrated over India, which
has experienced significant groundwater depletion in recent decades that is
nevertheless not being captured by the NOAH model. Results show that the CNN
models significantly improve the match with GRACE TWSA, achieving a
country-average correlation coefficient of 0.94 and Nash-Sutcliff efficient of
0.87, or 14\% and 52\% improvement respectively over the original NOAH TWSA. At
the local scale, the learned mismatch pattern correlates well with the observed
in situ groundwater storage anomaly data for most parts of India, suggesting
that deep learning models effectively compensate for the missing groundwater
component in NOAH for this study region.
</summary>
    <author>
      <name>Alexander Y. Sun</name>
    </author>
    <author>
      <name>Bridget R. Scanlon</name>
    </author>
    <author>
      <name>Zizhan Zhang</name>
    </author>
    <author>
      <name>David Walling</name>
    </author>
    <author>
      <name>Soumendra N. Bhanja</name>
    </author>
    <author>
      <name>Abhijit Mukherjee</name>
    </author>
    <author>
      <name>Zhi Zhong</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1029/2018WR023333</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1029/2018WR023333" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Water Resources Research, 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1902.01933v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.01933v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.07943v2</id>
    <updated>2017-11-29T04:15:26Z</updated>
    <published>2017-09-12T08:00:46Z</published>
    <title>Cascaded Region-based Densely Connected Network for Event Detection: A
  Seismic Application</title>
    <summary>  Automatic event detection from time series signals has wide applications,
such as abnormal event detection in video surveillance and event detection in
geophysical data. Traditional detection methods detect events primarily by the
use of similarity and correlation in data. Those methods can be inefficient and
yield low accuracy. In recent years, because of the significantly increased
computational power, machine learning techniques have revolutionized many
science and engineering domains. In this study, we apply a deep-learning-based
method to the detection of events from time series seismic signals. However, a
direct adaptation of the similar ideas from 2D object detection to our problem
faces two challenges. The first challenge is that the duration of earthquake
event varies significantly; The other is that the proposals generated are
temporally correlated. To address these challenges, we propose a novel cascaded
region-based convolutional neural network to capture earthquake events in
different sizes, while incorporating contextual information to enrich features
for each individual proposal. To achieve a better generalization performance,
we use densely connected blocks as the backbone of our network. Because of the
fact that some positive events are not correctly annotated, we further
formulate the detection problem as a learning-from-noise problem. To verify the
performance of our detection methods, we employ our methods to seismic data
generated from a bi-axial "earthquake machine" located at Rock Mechanics
Laboratory, and we acquire labels with the help of experts. Through our
numerical tests, we show that our novel detection techniques yield high
accuracy. Therefore, our novel deep-learning-based detection methods can
potentially be powerful tools for locating events from time series data in
various applications.
</summary>
    <author>
      <name>Yue Wu</name>
    </author>
    <author>
      <name>Youzuo Lin</name>
    </author>
    <author>
      <name>Zheng Zhou</name>
    </author>
    <author>
      <name>David Chas Bolton</name>
    </author>
    <author>
      <name>Ji Liu</name>
    </author>
    <author>
      <name>Paul Johnson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TGRS.2018.2852302</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TGRS.2018.2852302" rel="related"/>
    <link href="http://arxiv.org/abs/1709.07943v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.07943v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.03480v1</id>
    <updated>2018-10-05T16:15:14Z</updated>
    <published>2018-10-05T16:15:14Z</published>
    <title>Text Classification of the Precursory Accelerating Seismicity Corpus:
  Inference on some Theoretical Trends in Earthquake Predictability Research
  from 1988 to 2018</title>
    <summary>  Text analytics based on supervised machine learning classifiers has shown
great promise in a multitude of domains, but has yet to be applied to
Seismology. We test various standard models (Naive Bayes, k-Nearest Neighbors,
Support Vector Machines, and Random Forests) on a seismological corpus of 100
articles related to the topic of precursory accelerating seismicity, spanning
from 1988 to 2010. This corpus was labelled in Mignan (2011) with the precursor
whether explained by critical processes (i.e., cascade triggering) or by other
processes (such as signature of main fault loading). We investigate rather the
classification process can be automatized to help analyze larger corpora in
order to better understand trends in earthquake predictability research. We
find that the Naive Bayes model performs best, in agreement with the machine
learning literature for the case of small datasets, with cross-validation
accuracies of 86% for binary classification. For a refined multiclass
classification ('non-critical process' &lt; 'agnostic' &lt; 'critical process
assumed' &lt; 'critical process demonstrated'), we obtain up to 78% accuracy.
Prediction on a dozen of articles published since 2011 shows however a weak
generalization with a F1-score of 60%, only slightly better than a random
classifier, which can be explained by a change of authorship and use of
different terminologies. Yet, the model shows F1-scores greater than 80% for
the two multiclass extremes ('non-critical process' versus 'critical process
demonstrated') while it falls to random classifier results (around 25%) for
papers labelled 'agnostic' or 'critical process assumed'. Those results are
encouraging in view of the small size of the corpus and of the high degree of
abstraction of the labelling. Domain knowledge engineering remains essential
but can be made transparent by an investigation of Naive Bayes keyword
posterior probabilities.
</summary>
    <author>
      <name>Arnaud Mignan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10950-019-09833-2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10950-019-09833-2" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 3 figures, 7 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Seismology, 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1810.03480v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.03480v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.02241v1</id>
    <updated>2018-01-17T17:06:04Z</updated>
    <published>2018-01-17T17:06:04Z</published>
    <title>Seismic-Net: A Deep Densely Connected Neural Network to Detect Seismic
  Events</title>
    <summary>  One of the risks of large-scale geologic carbon sequestration is the
potential migration of fluids out of the storage formations. Accurate and fast
detection of this fluids migration is not only important but also challenging,
due to the large subsurface uncertainty and complex governing physics.
Traditional leakage detection and monitoring techniques rely on geophysical
observations including seismic. However, the resulting accuracy of these
methods is limited because of indirect information they provide requiring
expert interpretation, therefore yielding in-accurate estimates of leakage
rates and locations. In this work, we develop a novel machine-learning
detection package, named "Seismic-Net", which is based on the deep densely
connected neural network. To validate the performance of our proposed leakage
detection method, we employ our method to a natural analog site at Chimay\'o,
New Mexico. The seismic events in the data sets are generated because of the
eruptions of geysers, which is due to the leakage of $\mathrm{CO}_\mathrm{2}$.
In particular, we demonstrate the efficacy of our Seismic-Net by formulating
our detection problem as an event detection problem with time series data. A
fixed-length window is slid throughout the time series data and we build a deep
densely connected network to classify each window to determine if a geyser
event is included. Through our numerical tests, we show that our model achieves
precision/recall as high as 0.889/0.923. Therefore, our Seismic-Net has a great
potential for detection of $\mathrm{CO}_\mathrm{2}$ leakage.
</summary>
    <author>
      <name>Yue Wu</name>
    </author>
    <author>
      <name>Youzuo Lin</name>
    </author>
    <author>
      <name>Zheng Zhou</name>
    </author>
    <author>
      <name>Andrew Delorey</name>
    </author>
    <link href="http://arxiv.org/abs/1802.02241v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.02241v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.13444v1</id>
    <updated>2018-10-31T17:57:26Z</updated>
    <published>2018-10-31T17:57:26Z</published>
    <title>Model parameter estimation using coherent structure coloring</title>
    <summary>  Lagrangian data assimilation is a complex problem in oceanic and atmospheric
modeling. Tracking drifters in large-scale geophysical flows can involve
uncertainty in drifter location, complex inertial effects, and other factors
which make comparing them to simulated Lagrangian trajectories from numerical
models extremely challenging. Temporal and spatial discretization, factors
necessary in modeling large scale flows, also contribute to separation between
real and simulated drifter trajectories. The chaotic advection inherent in
these turbulent flows tends to separate even closely spaced tracer particles,
making error metrics based solely on drifter displacements unsuitable for
estimating model parameters. We propose to instead use error in the coherent
structure coloring (CSC) field to assess model skill. The CSC field provides a
spatial representation of the underlying coherent patterns in the flow, and we
show that it is a more robust metric for assessing model accuracy. Through the
use of two test cases, one considering spatial uncertainty in particle
initialization, and one examining the influence of stochastic error along a
trajectory and temporal discretization, we show that error in the coherent
structure coloring field can be used to accurately determine single or multiple
simultaneously unknown model parameters, whereas a conventional error metric
based on error in drifter displacement fails. Because the CSC field enhances
the difference in error between correct and incorrect model parameters, error
minima in model parameter sweeps become more distinct. The effectiveness and
robustness of this method for single and multi-parameter estimation in
analytical flows suggests that Lagrangian data assimilation for real oceanic
and atmospheric models would benefit from a similar approach.
</summary>
    <author>
      <name>Kristy L. Schlueter-Kuck</name>
    </author>
    <author>
      <name>John O. Dabiri</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1017/jfm.2018.898</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1017/jfm.2018.898" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in the Journal of Fluid Mechanics</arxiv:comment>
    <link href="http://arxiv.org/abs/1810.13444v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.13444v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.05749v2</id>
    <updated>2019-06-12T12:49:02Z</updated>
    <published>2019-05-14T17:52:52Z</published>
    <title>DeepFlow: History Matching in the Space of Deep Generative Models</title>
    <summary>  The calibration of a reservoir model with observed transient data of fluid
pressures and rates is a key task in obtaining a predictive model of the flow
and transport behaviour of the earth's subsurface. The model calibration task,
commonly referred to as "history matching", can be formalised as an ill-posed
inverse problem where we aim to find the underlying spatial distribution of
petrophysical properties that explain the observed dynamic data. We use a
generative adversarial network pretrained on geostatistical object-based models
to represent the distribution of rock properties for a synthetic model of a
hydrocarbon reservoir. The dynamic behaviour of the reservoir fluids is
modelled using a transient two-phase incompressible Darcy formulation. We
invert for the underlying reservoir properties by first modeling property
distributions using the pre-trained generative model then using the adjoint
equations of the forward problem to perform gradient descent on the latent
variables that control the output of the generative model. In addition to the
dynamic observation data, we include well rock-type constraints by introducing
an additional objective function. Our contribution shows that for a synthetic
test case, we are able to obtain solutions to the inverse problem by optimising
in the latent variable space of a deep generative model, given a set of
transient observations of a non-linear forward problem.
</summary>
    <author>
      <name>Lukas Mosser</name>
    </author>
    <author>
      <name>Olivier Dubrule</name>
    </author>
    <author>
      <name>Martin J. Blunt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 15 figures, fixed typos</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.05749v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.05749v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T10 (Primary) 68T20, 86-08, 86-04, 76T99 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.1; I.6.3; I.5.4; I.2.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.02880v2</id>
    <updated>2019-01-10T20:44:10Z</updated>
    <published>2018-09-08T21:39:29Z</published>
    <title>PhaseLink: A Deep Learning Approach to Seismic Phase Association</title>
    <summary>  Seismic phase association is a fundamental task in seismology that pertains
to linking together phase detections on different sensors that originate from a
common earthquake. It is widely employed to detect earthquakes on permanent and
temporary seismic networks, and underlies most seismicity catalogs produced
around the world. This task can be challenging because the number of sources is
unknown, events frequently overlap in time, or can occur simultaneously in
different parts of a network. We present PhaseLink, a framework based on recent
advances in deep learning for grid-free earthquake phase association. Our
approach learns to link phases together that share a common origin, and is
trained entirely on tens of millions of synthetic sequences of P- and S-wave
arrival times generated using a simple 1D velocity model. Our approach is
simple to implement for any tectonic regime, suitable for real-time processing,
and can naturally incorporate errors in arrival time picks. Rather than tuning
a set of ad hoc hyperparameters to improve performance, PhaseLink can be
improved by simply adding examples of problematic cases to the training
dataset. We demonstrate the state-of-the-art performance of PhaseLink on a
challenging recent sequence from southern California, and synthesized sequences
from Japan designed to test the point at which the method fails. For the
examined datasets, PhaseLink can precisely associate P- and S-picks to events
that are separated by ~12 seconds in origin time. This approach is expected to
improve the resolution of seismicity catalogs, add stability to real-time
seismic monitoring, and streamline automated processing of large seismic
datasets.
</summary>
    <author>
      <name>Zachary E. Ross</name>
    </author>
    <author>
      <name>Yisong Yue</name>
    </author>
    <author>
      <name>Men-Andrin Meier</name>
    </author>
    <author>
      <name>Egill Hauksson</name>
    </author>
    <author>
      <name>Thomas H. Heaton</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1029/2018JB016674</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1029/2018JB016674" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1809.02880v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.02880v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.11092v1</id>
    <updated>2018-12-26T07:35:24Z</updated>
    <published>2018-12-26T07:35:24Z</published>
    <title>Multi-resolution neural networks for tracking seismic horizons from few
  training images</title>
    <summary>  Detecting a specific horizon in seismic images is a valuable tool for
geological interpretation. Because hand-picking the locations of the horizon is
a time-consuming process, automated computational methods were developed
starting three decades ago. Older techniques for such picking include
interpolation of control points however, in recent years neural networks have
been used for this task. Until now, most networks trained on small patches from
larger images. This limits the networks ability to learn from large-scale
geologic structures. Moreover, currently available networks and training
strategies require label patches that have full and continuous annotations,
which are also time-consuming to generate.
  We propose a projected loss-function for training convolutional networks with
a multi-resolution structure, including variants of the U-net. Our networks
learn from a small number of large seismic images without creating patches. The
projected loss-function enables training on labels with just a few annotated
pixels and has no issue with the other unknown label pixels. Training uses all
data without reserving some for validation. Only the labels are split into
training/testing. Contrary to other work on horizon tracking, we train the
network to perform non-linear regression, and not classification. As such, we
propose labels as the convolution of a Gaussian kernel and the known horizon
locations that indicate uncertainty in the labels. The network output is the
probability of the horizon location. We demonstrate the proposed computational
ingredients on two different datasets, for horizon extrapolation and
interpolation. We show that the predictions of our methodology are accurate
even in areas far from known horizon locations because our learning strategy
exploits all data in large seismic images.
</summary>
    <author>
      <name>Bas Peters</name>
    </author>
    <author>
      <name>Justin Granek</name>
    </author>
    <author>
      <name>Eldad Haber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 13 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.11092v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.11092v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T45 (Primary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.0520v1</id>
    <updated>2013-06-05T10:28:33Z</updated>
    <published>2013-06-05T10:28:33Z</published>
    <title>Waveform cross correlation applied to earthquakes in the Atlantic Ocean</title>
    <summary>  We assess the level of cross correlation between P-waves generated by
earthquakes in the Atlantic Ocean and measured by 22 array stations of the
International Monitoring System (IMS). There are 931 events with 6,411 arrivals
in 2011 and 2012. Station TORD was the most sensitive and detected 868 from 931
events. We constructed several 931 by 931 matrices of cross correlation
coefficients (CCs) for individual stations and also for average and cumulative
CCs. These matrices characterize the detection performance of the involved
stations and the IMS. Sixty earthquakes located in the northern hemisphere were
selected as master events for signal detection and building of events
populating a cross correlation Standard Event List (XSEL) for the first halves
of 2009 and 2012. High-quality signals (SNR&gt;5.0) recorded by 10 most sensitive
stations were used as waveform templates. In order to quantitatively estimate
the gain in the completeness and resolution of the XSEL we compared it with the
Reviewed Event Bulletin (REB) of the International Data Centre (IDC) for the
North Atlantic (NA) and with the ISC Bulletin. Machine learning and
classification algorithms were successfully applied to automatically reject
invalid events in the XSEL for 2009.
</summary>
    <author>
      <name>Dmitry Bobrov</name>
    </author>
    <author>
      <name>Ivan Kitov</name>
    </author>
    <author>
      <name>Mikhail Rozhkov</name>
    </author>
    <link href="http://arxiv.org/abs/1307.0520v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.0520v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.00053v2</id>
    <updated>2016-03-10T18:34:41Z</updated>
    <published>2015-05-30T01:17:38Z</published>
    <title>Efficient Bayesian experimentation using an expected information gain
  lower bound</title>
    <summary>  Experimental design is crucial for inference where limitations in the data
collection procedure are present due to cost or other restrictions. Optimal
experimental designs determine parameters that in some appropriate sense make
the data the most informative possible. In a Bayesian setting this is
translated to updating to the best possible posterior. Information theoretic
arguments have led to the formation of the expected information gain as a
design criterion. This can be evaluated mainly by Monte Carlo sampling and
maximized by using stochastic approximation methods, both known for being
computationally expensive tasks. We propose a framework where a lower bound of
the expected information gain is used as an alternative design criterion. In
addition to alleviating the computational burden, this also addresses issues
concerning estimation bias. The problem of permeability inference in a large
contaminated area is used to demonstrate the validity of our approach where we
employ the massively parallel version of the multiphase multicomponent
simulator TOUGH2 to simulate contaminant transport and a Polynomial Chaos
approximation of the forward model that further accelerates the objective
function evaluations. The proposed methodology is demonstrated to a setting
where field measurements are available.
</summary>
    <author>
      <name>Panagiotis Tsilifis</name>
    </author>
    <author>
      <name>Roger G. Ghanem</name>
    </author>
    <author>
      <name>Paris Hajali</name>
    </author>
    <link href="http://arxiv.org/abs/1506.00053v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.00053v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.7407v1</id>
    <updated>2014-05-28T21:42:22Z</updated>
    <published>2014-05-28T21:42:22Z</published>
    <title>Reproducing Kernel Functions: A general framework for Discrete Variable
  Representation</title>
    <summary>  Since its introduction, the Discrete Variable Representation (DVR) basis set
has become an invaluable representation of state vectors and Hermitian
operators in non-relativistic quantum dynamics and spectroscopy calculations.
On the other hand reproducing kernel (positive definite) functions have been
widely employed for a long time to a wide variety of disciplines: detection and
estimation problems in signal processing; data analysis in statistics;
generating observational models in machine learning; solving inverse problems
in geophysics and tomography in general; and in quantum mechanics.
  In this article it was demonstrated that, starting with the axiomatic
definition of DVR provided by Littlejohn [1], it is possible to show that the
space upon which the projection operator, defined in ref [1], projects is a
Reproducing Kernel Hilbert Space (RKHS) whose associated reproducing kernel
function can be used to generate DVR points and their corresponding DVR
functions on any domain manifold (curved or not). It is illustrated how, with
this idea, one may be able to `neatly' address the long-standing challenge of
building multidimensional DVR basis functions defined on curved manifolds.
</summary>
    <author>
      <name>Hamse Mussa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages and 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.7407v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.7407v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.02607v1</id>
    <updated>2016-07-09T13:05:09Z</updated>
    <published>2016-07-09T13:05:09Z</published>
    <title>Data Set From Molisan Regional Seismic Network Events</title>
    <summary>  After the earthquake occurred in Molise (Central Italy) on 31st October 2002
(Ml 5.4, 29 people dead), the local Servizio Regionale per la Protezione Civile
to ensure a better analysis of local seismic data, through a convention with
the Istituto Nazionale di Geofisica e Vulcanologia (INGV), promoted the design
of the Regional Seismic Network (RMSM) and funded its implementation. The 5
stations of RMSM worked since 2007 to 2013 collecting a large amount of seismic
data and giving an important contribution to the study of seismic sources
present in the region and the surrounding territory. This work reports about
the dataset containing all triggers collected by RMSM since July 2007 to March
2009, including actual seismic events; among them, all earthquakes events
recorded in coincidence to Rete Sismica Nazionale Centralizzata (RSNC) of INGV
have been marked with S and P arrival timestamps. Every trigger has been
associated to a spectrogram defined into a recorded time vs. frequency domain.
The main aim of this structured dataset is to be used for further analysis with
data mining and machine learning techniques on image patterns associated to the
waveforms.
</summary>
    <author>
      <name>Giovanni De Gasperis</name>
    </author>
    <author>
      <name>Christian Del Pinto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.02607v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.02607v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.08027v1</id>
    <updated>2017-01-27T12:25:19Z</updated>
    <published>2017-01-27T12:25:19Z</published>
    <title>LocDyn: Robust Distributed Localization for Mobile Underwater Networks</title>
    <summary>  How to self-localize large teams of underwater nodes using only noisy range
measurements? How to do it in a distributed way, and incorporating dynamics
into the problem? How to reject outliers and produce trustworthy position
estimates? The stringent acoustic communication channel and the accuracy needs
of our geophysical survey application demand faster and more accurate
localization methods. We approach dynamic localization as a MAP estimation
problem where the prior encodes dynamics, and we devise a convex relaxation
method that takes advantage of previous estimates at each measurement
acquisition step; The algorithm converges at an optimal rate for first order
methods. LocDyn is distributed: there is no fusion center responsible for
processing acquired data and the same simple computations are performed for
each node. LocDyn is accurate: experiments attest to a smaller positioning
error than a comparable Kalman filter. LocDyn is robust: it rejects outlier
noise, while the comparing methods succumb in terms of positioning error.
</summary>
    <author>
      <name>Cláudia Soares</name>
    </author>
    <author>
      <name>João Gomes</name>
    </author>
    <author>
      <name>Beatriz Ferreira</name>
    </author>
    <author>
      <name>João Paulo Costeira</name>
    </author>
    <link href="http://arxiv.org/abs/1701.08027v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.08027v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.01856v2</id>
    <updated>2017-02-15T21:16:12Z</updated>
    <published>2017-02-07T02:48:34Z</published>
    <title>A multi-channel approach for automatic microseismic event localization
  using RANSAC-based arrival time event clustering(RATEC)</title>
    <summary>  In the presence of background noise and interference, arrival times picked
from a surface microseismic data set usually include a number of false picks
which lead to uncertainty in location estimation. To eliminate false picks and
improve the accuracy of location estimates, we develop a classification
algorithm (RATEC) that clusters picked arrival times into event groups based on
random sampling and fitting moveout curves that approximate hyperbolas. Arrival
times far from the fitted hyperbolas are classified as false picks and removed
from the data set prior to location estimation. Simulations of synthetic data
for a 1-D linear array show that RATEC is robust under different noise
conditions and generally applicable to various types of media. By generalizing
the underlying moveout model, RATEC is extended to the case of a 2-D surface
monitoring array. The effectiveness of event location for the 2-D case is
demonstrated using a data set collected by a 5200-element dense 2-D array
deployed for microearthquake monitoring.
</summary>
    <author>
      <name>Lijun Zhu</name>
    </author>
    <author>
      <name>Entao Liu</name>
    </author>
    <author>
      <name>James H. McClellan</name>
    </author>
    <link href="http://arxiv.org/abs/1702.01856v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.01856v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.00561v1</id>
    <updated>2017-03-02T00:19:12Z</updated>
    <published>2017-03-02T00:19:12Z</published>
    <title>Signal-based Bayesian Seismic Monitoring</title>
    <summary>  Detecting weak seismic events from noisy sensors is a difficult perceptual
task. We formulate this task as Bayesian inference and propose a generative
model of seismic events and signals across a network of spatially distributed
stations. Our system, SIGVISA, is the first to directly model seismic
waveforms, allowing it to incorporate a rich representation of the physics
underlying the signal generation process. We use Gaussian processes over
wavelet parameters to predict detailed waveform fluctuations based on
historical events, while degrading smoothly to simple parametric envelopes in
regions with no historical seismicity. Evaluating on data from the western US,
we recover three times as many events as previous work, and reduce mean
location errors by a factor of four while greatly increasing sensitivity to
low-magnitude events.
</summary>
    <author>
      <name>David A. Moore</name>
    </author>
    <author>
      <name>Stuart J. Russell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appearing at AISTATS 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.00561v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.00561v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.07178v1</id>
    <updated>2017-06-22T06:53:19Z</updated>
    <published>2017-06-22T06:53:19Z</published>
    <title>Shape recognition of volcanic ash by simple convolutional neural network</title>
    <summary>  Shape analyses of tephra grains result in understanding eruption mechanism of
volcanoes. However, we have to define and select parameter set such as
convexity for the precise discrimination of tephra grains. Selection of the
best parameter set for the recognition of tephra shapes is complicated.
Actually, many shape parameters have been suggested. Recently, neural network
has made a great success in the field of machine learning. Convolutional neural
network can recognize the shape of images without human bias and shape
parameters. We applied the simple convolutional neural network developed for
the handwritten digits to the recognition of tephra shapes. The network was
trained by Morphologi tephra images, and it can recognize the tephra shapes
with approximately 90% of accuracy.
</summary>
    <author>
      <name>Daigo Shoji</name>
    </author>
    <author>
      <name>Rina Noguchi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.07178v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.07178v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.01810v2</id>
    <updated>2019-04-09T08:01:07Z</updated>
    <published>2017-08-05T19:07:06Z</published>
    <title>Parametrization and generation of geological models with generative
  adversarial networks</title>
    <summary>  One of the main challenges in the parametrization of geological models is the
ability to capture complex geological structures often observed in the
subsurface. In recent years, generative adversarial networks (GAN) were
proposed as an efficient method for the generation and parametrization of
complex data, showing state-of-the-art performances in challenging computer
vision tasks such as reproducing natural images (handwritten digits, human
faces, etc.). In this work, we study the application of Wasserstein GAN for the
parametrization of geological models. The effectiveness of the method is
assessed for uncertainty propagation tasks using several test cases involving
different permeability patterns and subsurface flow problems. Results show that
GANs are able to generate samples that preserve the multipoint statistical
features of the geological models both visually and quantitatively. The
generated samples reproduce both the geological structures and the flow
statistics of the reference geology.
</summary>
    <author>
      <name>Shing Chan</name>
    </author>
    <author>
      <name>Ahmed H. Elsheikh</name>
    </author>
    <link href="http://arxiv.org/abs/1708.01810v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.01810v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.02756v1</id>
    <updated>2017-10-07T22:59:13Z</updated>
    <published>2017-10-07T22:59:13Z</published>
    <title>A New Spectral Clustering Algorithm</title>
    <summary>  We present a new clustering algorithm that is based on searching for natural
gaps in the components of the lowest energy eigenvectors of the Laplacian of a
graph. In comparing the performance of the proposed method with a set of other
popular methods (KMEANS, spectral-KMEANS, and an agglomerative method) in the
context of the Lancichinetti-Fortunato-Radicchi (LFR) Benchmark for undirected
weighted overlapping networks, we find that the new method outperforms the
other spectral methods considered in certain parameter regimes. Finally, in an
application to climate data involving one of the most important modes of
interannual climate variability, the El Nino Southern Oscillation phenomenon,
we demonstrate the ability of the new algorithm to readily identify different
flavors of the phenomenon.
</summary>
    <author>
      <name>W. R. Casper</name>
    </author>
    <author>
      <name>Balu Nadiga</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1710.02756v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.02756v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1712.01961v3</id>
    <updated>2018-07-10T22:36:57Z</updated>
    <published>2017-12-05T23:03:07Z</published>
    <title>The First Comparison Between Swarm-C Accelerometer-Derived Thermospheric
  Densities and Physical and Empirical Model Estimates</title>
    <summary>  The first systematic comparison between Swarm-C accelerometer-derived
thermospheric density and both empirical and physics-based model results using
multiple model performance metrics is presented. This comparison is performed
at the satellite's high temporal 10-s resolution, which provides a meaningful
evaluation of the models' fidelity for orbit prediction and other space weather
forecasting applications. The comparison against the physical model is
influenced by the specification of the lower atmospheric forcing, the
high-latitude ionospheric plasma convection, and solar activity. Some insights
into the model response to thermosphere-driving mechanisms are obtained through
a machine learning exercise. The results of this analysis show that the
short-timescale variations observed by Swarm-C during periods of high solar and
geomagnetic activity were better captured by the physics-based model than the
empirical models. It is concluded that Swarm-C data agree well with the
climatologies inherent within the models and are, therefore, a useful data set
for further model validation and scientific research.
</summary>
    <author>
      <name>Timothy Kodikara</name>
    </author>
    <author>
      <name>Brett Carter</name>
    </author>
    <author>
      <name>Kefei Zhang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1029/2017JA025118</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1029/2017JA025118" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">https://goo.gl/n4QvU7</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Geophysical Research: Space Physics, 123, 2018</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1712.01961v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1712.01961v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.space-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.03065v3</id>
    <updated>2018-07-05T17:56:39Z</updated>
    <published>2018-02-08T22:41:22Z</published>
    <title>Generating Realistic Geology Conditioned on Physical Measurements with
  Generative Adversarial Networks</title>
    <summary>  An important problem in geostatistics is to build models of the subsurface of
the Earth given physical measurements at sparse spatial locations. Typically,
this is done using spatial interpolation methods or by reproducing patterns
from a reference image. However, these algorithms fail to produce realistic
patterns and do not exhibit the wide range of uncertainty inherent in the
prediction of geology. In this paper, we show how semantic inpainting with
Generative Adversarial Networks can be used to generate varied realizations of
geology which honor physical measurements while matching the expected
geological patterns. In contrast to other algorithms, our method scales well
with the number of data points and mimics a distribution of patterns as opposed
to a single pattern or image. The generated conditional samples are state of
the art.
</summary>
    <author>
      <name>Emilien Dupont</name>
    </author>
    <author>
      <name>Tuanfeng Zhang</name>
    </author>
    <author>
      <name>Peter Tilke</name>
    </author>
    <author>
      <name>Lin Liang</name>
    </author>
    <author>
      <name>William Bailey</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Added ICML workshop info, more specific training details and more
  details on how images are chosen</arxiv:comment>
    <link href="http://arxiv.org/abs/1802.03065v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.03065v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.05622v1</id>
    <updated>2018-02-15T15:34:23Z</updated>
    <published>2018-02-15T15:34:23Z</published>
    <title>Conditioning of three-dimensional generative adversarial networks for
  pore and reservoir-scale models</title>
    <summary>  Geostatistical modeling of petrophysical properties is a key step in modern
integrated oil and gas reservoir studies. Recently, generative adversarial
networks (GAN) have been shown to be a successful method for generating
unconditional simulations of pore- and reservoir-scale models. This
contribution leverages the differentiable nature of neural networks to extend
GANs to the conditional simulation of three-dimensional pore- and
reservoir-scale models. Based on the previous work of Yeh et al. (2016), we use
a content loss to constrain to the conditioning data and a perceptual loss
obtained from the evaluation of the GAN discriminator network. The technique is
tested on the generation of three-dimensional micro-CT images of a Ketton
limestone constrained by two-dimensional cross-sections, and on the simulation
of the Maules Creek alluvial aquifer constrained by one-dimensional sections.
Our results show that GANs represent a powerful method for sampling conditioned
pore and reservoir samples for stochastic reservoir evaluation workflows.
</summary>
    <author>
      <name>Lukas Mosser</name>
    </author>
    <author>
      <name>Olivier Dubrule</name>
    </author>
    <author>
      <name>Martin J. Blunt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1802.05622v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.05622v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1804.05273v3</id>
    <updated>2018-08-07T13:22:06Z</updated>
    <published>2018-04-14T20:51:54Z</published>
    <title>Fusion of hyperspectral and ground penetrating radar to estimate soil
  moisture</title>
    <summary>  In this contribution, we investigate the potential of hyperspectral data
combined with either simulated ground penetrating radar (GPR) or simulated
(sensor-like) soil-moisture data to estimate soil moisture. We propose two
simulation approaches to extend a given multi-sensor dataset which contains
sparse GPR data. In the first approach, simulated GPR data is generated either
by an interpolation along the time axis or by a machine learning model. The
second approach includes the simulation of soil-moisture along the GPR profile.
The soil-moisture estimation is improved significantly by the fusion of
hyperspectral and GPR data. In contrast, the combination of simulated,
sensor-like soil-moisture values and hyperspectral data achieves the worst
regression performance. In conclusion, the estimation of soil moisture with
hyperspectral and GPR data engages further investigations.
</summary>
    <author>
      <name>Felix M. Riese</name>
    </author>
    <author>
      <name>Sina Keller</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/WHISPERS.2018.8747076</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/WHISPERS.2018.8747076" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This work has been accepted to the IEEE WHISPERS 2018 conference. (C)
  2018 IEEE</arxiv:comment>
    <link href="http://arxiv.org/abs/1804.05273v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1804.05273v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.03720v1</id>
    <updated>2018-06-10T20:38:29Z</updated>
    <published>2018-06-10T20:38:29Z</published>
    <title>Stochastic seismic waveform inversion using generative adversarial
  networks as a geological prior</title>
    <summary>  We present an application of deep generative models in the context of
partial-differential equation (PDE) constrained inverse problems. We combine a
generative adversarial network (GAN) representing an a priori model that
creates subsurface geological structures and their petrophysical properties,
with the numerical solution of the PDE governing the propagation of acoustic
waves within the earth's interior. We perform Bayesian inversion using an
approximate Metropolis-adjusted Langevin algorithm (MALA) to sample from the
posterior given seismic observations. Gradients with respect to the model
parameters governing the forward problem are obtained by solving the adjoint of
the acoustic wave equation. Gradients of the mismatch with respect to the
latent variables are obtained by leveraging the differentiable nature of the
deep neural network used to represent the generative model. We show that
approximate MALA sampling allows efficient Bayesian inversion of model
parameters obtained from a prior represented by a deep generative model,
obtaining a diverse set of realizations that reflect the observed seismic
response.
</summary>
    <author>
      <name>Lukas Mosser</name>
    </author>
    <author>
      <name>Olivier Dubrule</name>
    </author>
    <author>
      <name>Martin J. Blunt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1806.03720v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.03720v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
