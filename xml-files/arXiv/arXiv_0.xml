<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Aatmosphere%20AND%20all%3Amachine%20AND%20all%3Alearning%26id_list%3D%26start%3D0%26max_results%3D100" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:atmosphere AND all:machine AND all:learning&amp;id_list=&amp;start=0&amp;max_results=100</title>
  <id>http://arxiv.org/api/cOhjqhjksFsiFHh8lFZ+OW1ibig</id>
  <updated>2019-07-16T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">131</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">100</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/1907.01351v1</id>
    <updated>2019-07-02T13:25:41Z</updated>
    <published>2019-07-02T13:25:41Z</published>
    <title>Online learning as a way to tackle instabilities and biases in neural
  network parameterizations</title>
    <summary>  Over the last couple of years, machine learning parameterizations have
emerged as a potential way to improve the representation of sub-grid processes
in atmospheric models. All previous studies created a training dataset from a
high-resolution simulation, fitted a machine learning algorithms to that
dataset, and then plugged the trained algorithm into an atmospheric model. The
resulting online simulations were frequently plagued by instabilities and
biases. Here, I propose online learning as a way to combat these issues. In
online learning, the pretrained machine learning parameterization, specifically
a neural network, is run in parallel with a high-resolution simulation which is
kept in sync with the neural network-driven atmospheric model through constant
forcing. This enables the neural network to learn from the tendencies that the
high-resolution simulation would produce if it experienced the atmospheric
states the neural network creates. The concept is illustrated using the Lorenz
96 model, where online learning is able to recover the "true"
parameterizations. Then I present detailed algorithms for implementing online
learning in the 3D cloud-resolving model and super-parameterization frameworks.
Finally, I discuss outstanding challenges and issues not solved by this
approach.
</summary>
    <author>
      <name>Stephan Rasp</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">https://github.com/raspstephan/Lorenz-Online</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.01351v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.01351v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.10659v1</id>
    <updated>2019-05-25T19:15:24Z</updated>
    <published>2019-05-25T19:15:24Z</published>
    <title>An Ensemble of Bayesian Neural Networks for Exoplanetary Atmospheric
  Retrieval</title>
    <summary>  Machine learning is now used in many areas of astrophysics, from detecting
exoplanets in Kepler transit signals to removing telescope systematics. Recent
work demonstrated the potential of using machine learning algorithms for
atmospheric retrieval by implementing a random forest to perform retrievals in
seconds that are consistent with the traditional, computationally-expensive
nested-sampling retrieval method. We expand upon their approach by presenting a
new machine learning model, \texttt{plan-net}, based on an ensemble of Bayesian
neural networks that yields more accurate inferences than the random forest for
the same data set of synthetic transmission spectra. We demonstrate that an
ensemble provides greater accuracy and more robust uncertainties than a single
model. In addition to being the first to use Bayesian neural networks for
atmospheric retrieval, we also introduce a new loss function for Bayesian
neural networks that learns correlations between the model outputs.
Importantly, we show that designing machine learning models to explicitly
incorporate domain-specific knowledge both improves performance and provides
additional insight by inferring the covariance of the retrieved atmospheric
parameters. We apply \texttt{plan-net} to the Hubble Space Telescope Wide Field
Camera 3 transmission spectrum for WASP-12b and retrieve an isothermal
temperature and water abundance consistent with the literature. We highlight
that our method is flexible and can be expanded to higher-resolution spectra
and a larger number of atmospheric parameters.
</summary>
    <author>
      <name>Adam D. Cobb</name>
    </author>
    <author>
      <name>Michael D. Himes</name>
    </author>
    <author>
      <name>Frank Soboczenski</name>
    </author>
    <author>
      <name>Simone Zorzan</name>
    </author>
    <author>
      <name>Molly D. O'Beirne</name>
    </author>
    <author>
      <name>Atılım Güneş Baydin</name>
    </author>
    <author>
      <name>Yarin Gal</name>
    </author>
    <author>
      <name>Shawn D. Domagal-Goldman</name>
    </author>
    <author>
      <name>Giada N. Arney</name>
    </author>
    <author>
      <name>Daniel Angerhausen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3847/1538-3881/ab2390</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3847/1538-3881/ab2390" rel="related"/>
    <link href="http://arxiv.org/abs/1905.10659v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.10659v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.03944v1</id>
    <updated>2018-06-11T13:03:46Z</updated>
    <published>2018-06-11T13:03:46Z</published>
    <title>Supervised Machine Learning for Analysing Spectra of Exoplanetary
  Atmospheres</title>
    <summary>  The use of machine learning is becoming ubiquitous in astronomy, but remains
rare in the study of the atmospheres of exoplanets. Given the spectrum of an
exoplanetary atmosphere, a multi-parameter space is swept through in real time
to find the best-fit model. Known as atmospheric retrieval, it is a technique
that originates from the Earth and planetary sciences. Such methods are very
time-consuming and by necessity there is a compromise between physical and
chemical realism versus computational feasibility. Machine learning has
previously been used to determine which molecules to include in the model, but
the retrieval itself was still performed using standard methods. Here, we
report an adaptation of the random forest method of supervised machine
learning, trained on a pre-computed grid of atmospheric models, which retrieves
full posterior distributions of the abundances of molecules and the cloud
opacity. The use of a pre-computed grid allows a large part of the
computational burden to be shifted offline. We demonstrate our technique on a
transmission spectrum of the hot gas-giant exoplanet WASP-12b using a
five-parameter model (temperature, a constant cloud opacity and the volume
mixing ratios or relative abundance by number of water, ammonia and hydrogen
cyanide). We obtain results consistent with the standard nested-sampling
retrieval method. Additionally, we can estimate the sensitivity of the measured
spectrum to constraining the model parameters and we can quantify the
information content of the spectrum. Our method can be straightforwardly
applied using more sophisticated atmospheric models and also to interpreting an
ensemble of spectra without having to retrain the random forest.
</summary>
    <author>
      <name>Pablo Marquez-Neila</name>
    </author>
    <author>
      <name>Chloe Fisher</name>
    </author>
    <author>
      <name>Raphael Sznitman</name>
    </author>
    <author>
      <name>Kevin Heng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 7 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1806.03944v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.03944v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.05912v2</id>
    <updated>2018-02-06T08:57:21Z</updated>
    <published>2017-09-18T13:26:25Z</published>
    <title>Estimating regional ground-level PM2.5 directly from satellite
  top-of-atmosphere reflectance using deep learning</title>
    <summary>  Almost all remote sensing atmospheric PM2.5 estimation methods need satellite
aerosol optical depth (AOD) products, which are often retrieved from
top-of-atmosphere (TOA) reflectance via an atmospheric radiative transfer
model. Then, is it possible to estimate ground-level PM2.5 directly from
satellite TOA reflectance without a physical model? In this study, this
challenging work are achieved based on a machine learning model. Specifically,
we establish the relationship between PM2.5, satellite TOA reflectance,
observation angles, and meteorological factors in a deep learning architecture
(denoted as Ref-PM modeling). Taking the Wuhan Urban Agglomeration (WUA) as a
case study, the results demonstrate that compared with the AOD-PM modeling, the
Ref-PM modeling obtains a competitive performance, with out-of-sample
cross-validated R2 and RMSE values of 0.87 and 9.89 ug/m3 respectively. Also,
the TOA-reflectance-derived PM2.5 have a finer resolution and larger spatial
coverage than the AOD-derived PM2.5. This work updates the traditional
cognition of remote sensing PM2.5 estimation and has the potential to promote
the application in atmospheric environmental monitoring.
</summary>
    <author>
      <name>Huanfeng Shen</name>
    </author>
    <author>
      <name>Tongwen Li</name>
    </author>
    <author>
      <name>Qiangqiang Yuan</name>
    </author>
    <author>
      <name>Liangpei Zhang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1029/2018JD028759</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1029/2018JD028759" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper is under review</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of geophysical research: Atmosphere (2018)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1709.05912v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.05912v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.05767v4</id>
    <updated>2018-02-05T15:57:57Z</updated>
    <published>2015-02-20T04:20:47Z</published>
    <title>Automatic differentiation in machine learning: a survey</title>
    <summary>  Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in
machine learning. Automatic differentiation (AD), also called algorithmic
differentiation or simply "autodiff", is a family of techniques similar to but
more general than backpropagation for efficiently and accurately evaluating
derivatives of numeric functions expressed as computer programs. AD is a small
but established field with applications in areas including computational fluid
dynamics, atmospheric sciences, and engineering design optimization. Until very
recently, the fields of machine learning and AD have largely been unaware of
each other and, in some cases, have independently discovered each other's
results. Despite its relevance, general-purpose AD has been missing from the
machine learning toolbox, a situation slowly changing with its ongoing adoption
under the names "dynamic computational graphs" and "differentiable
programming". We survey the intersection of AD and machine learning, cover
applications where AD has direct relevance, and address the main implementation
techniques. By precisely defining the main differentiation techniques and their
interrelationships, we aim to bring clarity to the usage of the terms
"autodiff", "automatic differentiation", and "symbolic differentiation" as
these are encountered more and more in machine learning settings.
</summary>
    <author>
      <name>Atilim Gunes Baydin</name>
    </author>
    <author>
      <name>Barak A. Pearlmutter</name>
    </author>
    <author>
      <name>Alexey Andreyevich Radul</name>
    </author>
    <author>
      <name>Jeffrey Mark Siskind</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">43 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Atilim Gunes Baydin, Barak A. Pearlmutter, Alexey Andreyevich
  Radul, Jeffrey Mark Siskind. Automatic differentiation in machine learning: a
  survey. The Journal of Machine Learning Research, 18(153):1--43, 2018</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1502.05767v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.05767v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68W30, 65D25, 68T05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.4; I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.05720v1</id>
    <updated>2019-07-11T04:03:27Z</updated>
    <published>2019-07-11T04:03:27Z</published>
    <title>Wind Estimation Using Quadcopter Motion: A Machine Learning Approach</title>
    <summary>  In this article, we study the well known problem of wind estimation in
atmospheric turbulence using small unmanned aerial systems (sUAS). We present a
machine learning approach to wind velocity estimation based on quadcopter state
measurements without a wind sensor. We accomplish this by training a long
short-term memory (LSTM) neural network (NN) on roll and pitch angles and
quadcopter position inputs with forcing wind velocities as the targets. The
datasets are generated using a simulated quadcopter in turbulent wind fields.
The trained neural network is deployed to estimate the turbulent winds as
generated by the Dryden gust model as well as a realistic large eddy simulation
(LES) of a near-neutral atmospheric boundary layer (ABL) over flat terrain. The
resulting NN predictions are compared to a wind triangle approach that uses
tilt angle as an approximation of airspeed. Results from this study indicate
that the LSTM-NN based approach predicts lower errors in both the mean and
variance of the local wind field as compared to the wind triangle approach. The
work reported in this article demonstrates the potential of machine learning
for sensor-less wind estimation and has strong implications to large-scale
low-altitude atmospheric sensing using sUAS for environmental and autonomous
navigation applications.
</summary>
    <author>
      <name>Sam Allison</name>
    </author>
    <author>
      <name>He Bai</name>
    </author>
    <author>
      <name>Balaji Jayaraman</name>
    </author>
    <link href="http://arxiv.org/abs/1907.05720v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.05720v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.08431v4</id>
    <updated>2017-09-06T19:31:51Z</updated>
    <published>2017-01-29T21:18:22Z</published>
    <title>Source localization in an ocean waveguide using supervised machine
  learning</title>
    <summary>  Source localization in ocean acoustics is posed as a machine learning problem
in which data-driven methods learn source ranges directly from observed
acoustic data. The pressure received by a vertical linear array is preprocessed
by constructing a normalized sample covariance matrix (SCM) and used as the
input. Three machine learning methods (feed-forward neural networks (FNN),
support vector machines (SVM) and random forests (RF)) are investigated in this
paper, with focus on the FNN. The range estimation problem is solved both as a
classification problem and as a regression problem by these three machine
learning algorithms. The results of range estimation for the Noise09 experiment
are compared for FNN, SVM, RF and conventional matched-field processing and
demonstrate the potential of machine learning for underwater source
localization..
</summary>
    <author>
      <name>Haiqiang Niu</name>
    </author>
    <author>
      <name>Emma Reeves</name>
    </author>
    <author>
      <name>Peter Gerstoft</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1121/1.5000165</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1121/1.5000165" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to The Journal of the Acoustical Society of America</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Journal of the Acoustical Society of America 142, 1176 (2017)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1701.08431v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.08431v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1811.03390v2</id>
    <updated>2018-12-02T13:01:22Z</updated>
    <published>2018-11-08T13:03:08Z</published>
    <title>Bayesian Deep Learning for Exoplanet Atmospheric Retrieval</title>
    <summary>  Over the past decade, the study of extrasolar planets has evolved rapidly
from plain detection and identification to comprehensive categorization and
characterization of exoplanet systems and their atmospheres. Atmospheric
retrieval, the inverse modeling technique used to determine an exoplanetary
atmosphere's temperature structure and composition from an observed spectrum,
is both time-consuming and compute-intensive, requiring complex algorithms that
compare thousands to millions of atmospheric models to the observational data
to find the most probable values and associated uncertainties for each model
parameter. For rocky, terrestrial planets, the retrieved atmospheric
composition can give insight into the surface fluxes of gaseous species
necessary to maintain the stability of that atmosphere, which may in turn
provide insight into the geological and/or biological processes active on the
planet. These atmospheres contain many molecules, some of them biosignatures,
spectral fingerprints indicative of biological activity, which will become
observable with the next generation of telescopes. Runtimes of traditional
retrieval models scale with the number of model parameters, so as more
molecular species are considered, runtimes can become prohibitively long.
Recent advances in machine learning (ML) and computer vision offer new ways to
reduce the time to perform a retrieval by orders of magnitude, given a
sufficient data set to train with. Here we present an ML-based retrieval
framework called Intelligent exoplaNet Atmospheric RetrievAl (INARA) that
consists of a Bayesian deep learning model for retrieval and a data set of
3,000,000 synthetic rocky exoplanetary spectra generated using the NASA
Planetary Spectrum Generator. Our work represents the first ML retrieval model
for rocky, terrestrial exoplanets and the first synthetic data set of
terrestrial spectra generated at this scale.
</summary>
    <author>
      <name>Frank Soboczenski</name>
    </author>
    <author>
      <name>Michael D. Himes</name>
    </author>
    <author>
      <name>Molly D. O'Beirne</name>
    </author>
    <author>
      <name>Simone Zorzan</name>
    </author>
    <author>
      <name>Atilim Gunes Baydin</name>
    </author>
    <author>
      <name>Adam D. Cobb</name>
    </author>
    <author>
      <name>Yarin Gal</name>
    </author>
    <author>
      <name>Daniel Angerhausen</name>
    </author>
    <author>
      <name>Massimo Mascaro</name>
    </author>
    <author>
      <name>Giada N. Arney</name>
    </author>
    <author>
      <name>Shawn D. Domagal-Goldman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Third workshop on Bayesian Deep Learning (NeurIPS 2018), Montreal,
  Canada</arxiv:comment>
    <link href="http://arxiv.org/abs/1811.03390v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1811.03390v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="85A20, 68T05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.2; I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.04951v1</id>
    <updated>2018-12-11T08:42:02Z</updated>
    <published>2018-12-11T08:42:02Z</published>
    <title>The FLUXCOM ensemble of global land-atmosphere energy fluxes</title>
    <summary>  Although a key driver of Earth's climate system, global land-atmosphere
energy fluxes are poorly constrained. Here we use machine learning to merge
energy flux measurements from FLUXNET eddy covariance towers with remote
sensing and meteorological data to estimate net radiation, latent and sensible
heat and their uncertainties. The resulting FLUXCOM database comprises 147
global gridded products in two setups: (1) 0.0833${\deg}$ resolution using
MODIS remote sensing data (RS) and (2) 0.5${\deg}$ resolution using remote
sensing and meteorological data (RS+METEO). Within each setup we use a full
factorial design across machine learning methods, forcing datasets and energy
balance closure corrections. For RS and RS+METEO setups respectively, we
estimate 2001-2013 global (${\pm}$ 1 standard deviation) net radiation as
75.8${\pm}$1.4 ${W\ m^{-2}}$ and 77.6${\pm}$2 ${W\ m^{-2}}$, sensible heat as
33${\pm}$4 ${W\ m^{-2}}$ and 36${\pm}$5 ${W\ m^{-2}}$, and evapotranspiration
as 75.6${\pm}$10 ${\times}$ 10$^3$ ${km^3\ yr^{-1}}$ and 76${\pm}$6 ${\times}$
10$^3$ ${km^3\ yr^{-1}}$. FLUXCOM products are suitable to quantify global
land-atmosphere interactions and benchmark land surface model simulations.
</summary>
    <author>
      <name>Martin Jung</name>
    </author>
    <author>
      <name>Sujan Koirala</name>
    </author>
    <author>
      <name>Ulrich Weber</name>
    </author>
    <author>
      <name>Kazuhito Ichii</name>
    </author>
    <author>
      <name>Fabian Gans</name>
    </author>
    <author>
      <name> Gustau-Camps-Valls</name>
    </author>
    <author>
      <name>Dario Papale</name>
    </author>
    <author>
      <name>Christopher Schwalm</name>
    </author>
    <author>
      <name>Gianluca Tramontana</name>
    </author>
    <author>
      <name>Markus Reichstein</name>
    </author>
    <link href="http://arxiv.org/abs/1812.04951v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.04951v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.08725v1</id>
    <updated>2017-09-25T21:12:12Z</updated>
    <published>2017-09-25T21:12:12Z</published>
    <title>A Machine Learning Framework to Forecast Wave Conditions</title>
    <summary>  A~machine learning framework is developed to estimate ocean-wave conditions.
By supervised training of machine learning models on many thousands of
iterations of a physics-based wave model, accurate representations of
significant wave heights and period can be used to predict ocean conditions. A
model of Monterey Bay was used as the example test site; it was forced by
measured wave conditions, ocean-current nowcasts, and reported winds. These
input data along with model outputs of spatially variable wave heights and
characteristic period were aggregated into supervised learning training and
test data sets, which were supplied to machine learning models. These machine
learning models replicated wave heights with a root-mean-squared error of 9cm
and correctly identify over 90% of the characteristic periods for the test-data
sets. Impressively, transforming model inputs to outputs through matrix
operations requires only a fraction (&lt;1/1,000) of the computation time compared
to forecasting with the physics-based model.
</summary>
    <author>
      <name>Scott C. James</name>
    </author>
    <author>
      <name>Yushan Zhang</name>
    </author>
    <author>
      <name>Fearghal O'Donncha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to Journal of Coastal Engineering</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.08725v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.08725v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.5125v1</id>
    <updated>2014-10-20T00:00:12Z</updated>
    <published>2014-10-20T00:00:12Z</published>
    <title>Gamma/hadron segregation for a ground based imaging atmospheric
  Cherenkov telescope using machine learning methods: Random Forest leads</title>
    <summary>  A detailed case study of $\gamma$-hadron segregation for a ground based
atmospheric Cherenkov telescope is presented. We have evaluated and compared
various supervised machine learning methods such as the Random Forest method,
Artificial Neural Network, Linear Discriminant method, Naive Bayes
Classifiers,Support Vector Machines as well as the conventional dynamic
supercut method by simulating triggering events with the Monte Carlo method and
applied the results to a Cherenkov telescope. It is demonstrated that the
Random Forest method is the most sensitive machine learning method for
$\gamma$-hadron segregation.
</summary>
    <author>
      <name>Mradul Sharma</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">BARC</arxiv:affiliation>
    </author>
    <author>
      <name>J. Nayak</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ISI</arxiv:affiliation>
    </author>
    <author>
      <name>M. K. Koul</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">BARC</arxiv:affiliation>
    </author>
    <author>
      <name>S. Bose</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">BARC</arxiv:affiliation>
    </author>
    <author>
      <name>Abhas Mitra</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">BARC</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1674-4527/14/11/012</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1674-4527/14/11/012" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to RAA</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Research in Astronomy and Astrophysics 14 (2014) 1491-1503</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1410.5125v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.5125v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.04621v1</id>
    <updated>2019-02-12T20:24:49Z</updated>
    <published>2019-02-12T20:24:49Z</published>
    <title>Deep Learning for Scientific Inference from Geophysical Data: The
  Madden-Julian Oscillation as a Test Case</title>
    <summary>  Deep learning can recognize complex geophysical phenomena by inferring which
variables are important for their identification and understanding their
spatial characteristics.
  We use a particular mode of multi-scale tropical atmospheric variability, the
Madden-Julian oscillation (MJO), to study the capabilities of deep learning, a
form of artificial intelligence and machine learning, in identifying spatial
geophysical phenomena. The MJO is characterized by its spatial and temporal
evolution of cloud patterns, and an extensive body of literature has examined
its defining characteristics. By applying a convolutional neural network (CNN),
a type of deep learning model, to the task of identifying the state of the MJO,
we show that deep learning can correctly identify geophysical phenomena by
"learning" the variables and spatial patterns important to their evolution. In
a broader sense, these findings suggest that deep learning models are
interpretable and viable for scientific inference in geoscientific
applications.
</summary>
    <author>
      <name>Benjamin A. Toms</name>
    </author>
    <author>
      <name>Karthik Kashinath</name>
    </author>
    <author>
      <name> Prabhat</name>
    </author>
    <author>
      <name>Da Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This manuscript has been submitted for review at the American
  Geophysical Union journal Geophysical Research Letters. Please contact the
  corresponding author, Benjamin A. Toms, for the supplementary material</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.04621v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.04621v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.01950v1</id>
    <updated>2018-05-04T22:16:16Z</updated>
    <published>2018-05-04T22:16:16Z</published>
    <title>A Data-driven Approach to Detecting Precipitation from Meteorological
  Sensor Data</title>
    <summary>  Precipitation is dependent on a myriad of atmospheric conditions. In this
paper, we study how certain atmospheric parameters impact the occurrence of
rainfall. We propose a data-driven, machine-learning based methodology to
detect precipitation using various meteorological sensor data. Our approach
achieves a true detection rate of 87.4% and a moderately low false alarm rate
of 32.2%.
</summary>
    <author>
      <name>Shilpa Manandhar</name>
    </author>
    <author>
      <name>Soumyabrata Dev</name>
    </author>
    <author>
      <name>Yee Hui Lee</name>
    </author>
    <author>
      <name>Yu Song Meng</name>
    </author>
    <author>
      <name>Stefan Winkler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in Proc. IEEE International Geoscience and Remote Sensing
  Symposium (IGARSS), 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1805.01950v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.01950v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.03010v1</id>
    <updated>2019-03-07T15:56:18Z</updated>
    <published>2019-03-07T15:56:18Z</published>
    <title>Characterizing Evaporation Ducts Within the Marine Atmospheric Boundary
  Layer Using Artificial Neural Networks</title>
    <summary>  We apply a multilayer perceptron machine learning (ML) regression approach to
infer electromagnetic (EM) duct heights within the marine atmospheric boundary
layer (MABL) using sparsely sampled EM propagation data obtained within a
bistatic context. This paper explains the rational behind the selection of the
ML network architecture, along with other model hyperparameters, in an effort
to demystify the process of arriving at a useful ML model. The resulting speed
of our ML predictions of EM duct heights, using sparse data measurements within
MABL, indicates the suitability of the proposed method for real-time
applications.
</summary>
    <author>
      <name>Hilarie Sit</name>
    </author>
    <author>
      <name>Christopher J. Earls</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.03010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.03010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.03891v1</id>
    <updated>2017-09-12T14:54:57Z</updated>
    <published>2017-09-12T14:54:57Z</published>
    <title>High-Dimensional Dependency Structure Learning for Physical Processes</title>
    <summary>  In this paper, we consider the use of structure learning methods for
probabilistic graphical models to identify statistical dependencies in
high-dimensional physical processes. Such processes are often synthetically
characterized using PDEs (partial differential equations) and are observed in a
variety of natural phenomena, including geoscience data capturing atmospheric
and hydrological phenomena. Classical structure learning approaches such as the
PC algorithm and variants are challenging to apply due to their high
computational and sample requirements. Modern approaches, often based on sparse
regression and variants, do come with finite sample guarantees, but are usually
highly sensitive to the choice of hyper-parameters, e.g., parameter $\lambda$
for sparsity inducing constraint or regularization. In this paper, we present
ACLIME-ADMM, an efficient two-step algorithm for adaptive structure learning,
which estimates an edge specific parameter $\lambda_{ij}$ in the first step,
and uses these parameters to learn the structure in the second step. Both steps
of our algorithm use (inexact) ADMM to solve suitable linear programs, and all
iterations can be done in closed form in an efficient block parallel manner. We
compare ACLIME-ADMM with baselines on both synthetic data simulated by partial
differential equations (PDEs) that model advection-diffusion processes, and
real data (50 years) of daily global geopotential heights to study information
flow in the atmosphere. ACLIME-ADMM is shown to be efficient, stable, and
competitive, usually better than the baselines especially on difficult
problems. On real data, ACLIME-ADMM recovers the underlying structure of global
atmospheric circulation, including switches in wind directions at the equator
and tropics entirely from the data.
</summary>
    <author>
      <name>Jamal Golmohammadi</name>
    </author>
    <author>
      <name>Imme Ebert-Uphoff</name>
    </author>
    <author>
      <name>Sijie He</name>
    </author>
    <author>
      <name>Yi Deng</name>
    </author>
    <author>
      <name>Arindam Banerjee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 8 figures, International Conference on Data Mining 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.03891v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.03891v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.07366v1</id>
    <updated>2019-05-17T16:36:00Z</updated>
    <published>2019-05-17T16:36:00Z</published>
    <title>Stratospheric Aerosol Injection as a Deep Reinforcement Learning Problem</title>
    <summary>  As global greenhouse gas emissions continue to rise, the use of stratospheric
aerosol injection (SAI), a form of solar geoengineering, is increasingly
considered in order to artificially mitigate climate change effects. However,
initial research in simulation suggests that naive SAI can have catastrophic
regional consequences, which may induce serious geostrategic conflicts. Current
geo-engineering research treats SAI control in low-dimensional approximation
only. We suggest treating SAI as a high-dimensional control problem, with
policies trained according to a context-sensitive reward function within the
Deep Reinforcement Learning (DRL) paradigm. In order to facilitate training in
simulation, we suggest to emulate HadCM3, a widely used General Circulation
Model, using deep learning techniques. We believe this is the first application
of DRL to the climate sciences.
</summary>
    <author>
      <name>Christian Schroeder de Witt</name>
    </author>
    <author>
      <name>Thomas Hornigold</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Awarded Poster and Spotlight Oral at Climate Change: How Can AI Help?
  (Workshop) at International Conference on Machine Learning, Long Beach,
  California, 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.07366v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.07366v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.05661v1</id>
    <updated>2019-04-11T12:27:08Z</updated>
    <published>2019-04-11T12:27:08Z</published>
    <title>A machine learning approach for underwater gas leakage detection</title>
    <summary>  Underwater gas reservoirs are used in many situations. In particular, Carbon
Capture and Storage (CCS) facilities that are currently being developed intend
to store greenhouse gases inside geological formations in the deep sea. In
these formations, however, the gas might percolate, leaking back to the water
and eventually to the atmosphere. The early detection of such leaks is
therefore tantamount to any underwater CCS project. In this work, we propose to
use Passive Acoustic Monitoring (PAM) and a machine learning approach to design
efficient detectors that can signal the presence of a leakage. We use data
obtained from simulation experiments off the Brazilian shore, and show that the
detection based on classification algorithms achieve good performance. We also
propose a smoothing strategy based on Hidden Markov Models in order to
incorporate previous knowledge about the probabilities of leakage occurrences.
</summary>
    <author>
      <name>Paulo Hubert</name>
    </author>
    <author>
      <name>Linilson Padovese</name>
    </author>
    <link href="http://arxiv.org/abs/1904.05661v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.05661v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.09064v1</id>
    <updated>2019-06-21T11:06:59Z</updated>
    <published>2019-06-21T11:06:59Z</published>
    <title>Constraining strongly-coupled new physics from cosmic rays with machine
  learning techniques</title>
    <summary>  Cosmic rays interacting with the atmosphere allow for the probing of
fundamental interactions at ultra-high energies. We thus obtain limits on
strongly-coupled new physics models via their imprints on cosmic ray air
showers. Using the Monte Carlo event generators Herwig and HERBVI, and the air
shower simulator CORSIKA, to simulate such processes, we apply machine learning
algorithms to the simulated observables to discriminate the events arising via
new physics from the QCD background, before using the signal and background
discrimination performance to set potential limits on the cross sections of the
new physics models.
</summary>
    <author>
      <name>Peter Schichtel</name>
    </author>
    <author>
      <name>Michael Spannowsky</name>
    </author>
    <author>
      <name>Philip Waite</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.09064v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.09064v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.04907v1</id>
    <updated>2018-05-13T16:18:32Z</updated>
    <published>2018-05-13T16:18:32Z</published>
    <title>A Computational Framework for Modelling and Analyzing Ice Storms</title>
    <summary>  Ice storms are extreme weather events that can have devastating implications
for the sustainability of natural ecosystems as well as man made
infrastructure. Ice storms are caused by a complex mix of atmospheric
conditions and are among the least understood of severe weather events. Our
ability to model ice storms and characterize storm features will go a long way
towards both enabling support systems that offset storm impacts and increasing
our understanding of ice storms. In this paper, we present a holistic
computational framework to answer key questions of interest about ice storms.
We model ice storms as a function of relevant surface and atmospheric
variables. We learn these models by adapting and applying supervised and
unsupervised machine learning algorithms on data with missing or incorrect
labels. We also include a knowledge representation module that reasons with
domain knowledge to revise the output of the learned models. Our models are
trained using reanalysis data and historical records of storm events. We
evaluate these models on reanalyis data as well as Global Climate Model (GCM)
data for historical and future climate change scenarios. Furthermore, we
discuss the use of appropriate bias correction approaches to run such modeling
frameworks with GCM data.
</summary>
    <author>
      <name>Ranjini Swaminathan</name>
    </author>
    <author>
      <name>Mohan Sridharan</name>
    </author>
    <author>
      <name>Katharine Hayhoe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages including bibliography</arxiv:comment>
    <link href="http://arxiv.org/abs/1805.04907v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.04907v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.10494v1</id>
    <updated>2018-05-26T15:19:46Z</updated>
    <published>2018-05-26T15:19:46Z</published>
    <title>Identifying typical Mg II flare spectra using machine learning</title>
    <summary>  IRIS performs solar observations over a large range of atmospheric heights,
including the chromosphere where the majority of flare energy is dissipated.
The strong Mg II h&amp;k spectral lines are capable of providing excellent
atmospheric diagnostics, but have not been fully utilized for flaring
atmospheres. We aim to investigate whether the physics of the chromosphere is
identical for all flare observations by analyzing if there are certain spectra
that occur in all flares. To achieve this, we automatically analyze hundreds of
thousands of Mg II h&amp;k line profiles from a set of 33 flares, and use a machine
learning technique which we call supervised hierarchical k-means, to cluster
all profile shapes. We identify a single peaked Mg II profile, in contrast to
the double-peaked quiet Sun profiles, appearing in every flare. Additionally,
we find extremely broad profiles with characteristic blue shifted central
reversals appearing at the front of fast-moving flare ribbons. These profiles
occur during the impulsive phase of the flare, and we present results of their
temporal and spatial correlation with non-thermal hard X-ray signatures,
suggesting that flare-accelerated electrons play an important role in the
formation of these profiles. The ratio of the integrated Mg II h&amp;k lines can
also serve as an opacity diagnostic, and we find higher opacities during each
flare maximum. Our study shows that machine learning is a powerful tool for
large scale statistical solar analyses.
</summary>
    <author>
      <name>B. Panos</name>
    </author>
    <author>
      <name>L. Kleint</name>
    </author>
    <author>
      <name>C. Huwyler</name>
    </author>
    <author>
      <name>S. Krucker</name>
    </author>
    <author>
      <name>M. Melchior</name>
    </author>
    <author>
      <name>D. Ullmann</name>
    </author>
    <author>
      <name>S. Voloshynovskiy</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3847/1538-4357/aac779</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3847/1538-4357/aac779" rel="related"/>
    <link href="http://arxiv.org/abs/1805.10494v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.10494v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.00037v3</id>
    <updated>2017-11-27T23:00:55Z</updated>
    <published>2017-08-31T18:45:40Z</published>
    <title>Earth System Modeling 2.0: A Blueprint for Models That Learn From
  Observations and Targeted High-Resolution Simulations</title>
    <summary>  Climate projections continue to be marred by large uncertainties, which
originate in processes that need to be parameterized, such as clouds,
convection, and ecosystems. But rapid progress is now within reach. New
computational tools and methods from data assimilation and machine learning
make it possible to integrate global observations and local high-resolution
simulations in an Earth system model (ESM) that systematically learns from
both. Here we propose a blueprint for such an ESM. We outline how
parameterization schemes can learn from global observations and targeted
high-resolution simulations, for example, of clouds and convection, through
matching low-order statistics between ESMs, observations, and high-resolution
simulations. We illustrate learning algorithms for ESMs with a simple dynamical
system that shares characteristics of the climate system; and we discuss the
opportunities the proposed framework presents and the challenges that remain to
realize it.
</summary>
    <author>
      <name>Tapio Schneider</name>
    </author>
    <author>
      <name>Shiwei Lan</name>
    </author>
    <author>
      <name>Andrew Stuart</name>
    </author>
    <author>
      <name>João Teixeira</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/2017GL076101</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/2017GL076101" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Geophysical Research Letters 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1709.00037v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.00037v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.09614v1</id>
    <updated>2019-05-23T12:25:05Z</updated>
    <published>2019-05-23T12:25:05Z</published>
    <title>Learning the Representations of Moist Convection with Convolutional
  Neural Networks</title>
    <summary>  The representations of atmospheric moist convection in general circulation
models have been one of the most challenging tasks due to its complexity in
physical processes, and the interaction between processes under different
time/spatial scales. This study proposes a new method to predict the effects of
moist convection on the environment using convolutional neural networks. With
the help of considering the gradient of physical fields between adjacent grids
in the grey zone resolution, the effects of moist convection predicted by the
convolutional neural networks are more realistic compared to the effects
predicted by other machine learning models. The result also suggests that the
method proposed in this study has the potential to replace the conventional
cumulus parameterization in the general circulation models.
</summary>
    <author>
      <name>Shih-Wen Tsou</name>
    </author>
    <author>
      <name>Chun-Yian Su</name>
    </author>
    <author>
      <name>Chien-Ming Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.09614v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.09614v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.05037v1</id>
    <updated>2019-05-13T13:51:51Z</updated>
    <published>2019-05-13T13:51:51Z</published>
    <title>Precipitation nowcasting using a stochastic variational frame predictor
  with learned prior distribution</title>
    <summary>  We propose the use of a stochastic variational frame prediction deep neural
network with a learned prior distribution trained on two-dimensional rain radar
reflectivity maps for precipitation nowcasting with lead times of up to 2 1/2
hours. We present a comparison to a standard convolutional LSTM network and
assess the evolution of the structural similarity index for both methods. Case
studies are presented that illustrate that the novel methodology can yield
meaningful forecasts without excessive blur for the time horizons of interest.
</summary>
    <author>
      <name>Alexander Bihlo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures, release version</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.05037v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.05037v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.06802v1</id>
    <updated>2019-02-26T02:09:31Z</updated>
    <published>2019-02-26T02:09:31Z</published>
    <title>Workflow-Driven Distributed Machine Learning in CHASE-CI: A Cognitive
  Hardware and Software Ecosystem Community Infrastructure</title>
    <summary>  The advances in data, computing and networking over the last two decades led
to a shift in many application domains that includes machine learning on big
data as a part of the scientific process, requiring new capabilities for
integrated and distributed hardware and software infrastructure. This paper
contributes a workflow-driven approach for dynamic data-driven application
development on top of a new kind of networked Cyberinfrastructure called
CHASE-CI. In particular, we present: 1) The architecture for CHASE-CI, a
network of distributed fast GPU appliances for machine learning and storage
managed through Kubernetes on the high-speed (10-100Gbps) Pacific Research
Platform (PRP); 2) A machine learning software containerization approach and
libraries required for turning such a network into a distributed computer for
big data analysis; 3) An atmospheric science case study that can only be made
scalable with an infrastructure like CHASE-CI; 4) Capabilities for virtual
cluster management for data communication and analysis in a dynamically
scalable fashion, and visualization across the network in specialized
visualization facilities in near real-time; and, 5) A step-by-step workflow and
performance measurement approach that enables taking advantage of the dynamic
architecture of the CHASE-CI network and container management infrastructure.
</summary>
    <author>
      <name>Ilkay Altintas</name>
    </author>
    <author>
      <name>Kyle Marcus</name>
    </author>
    <author>
      <name>Isaac Nealey</name>
    </author>
    <author>
      <name>Scott L. Sellars</name>
    </author>
    <author>
      <name>John Graham</name>
    </author>
    <author>
      <name>Dima Mishin</name>
    </author>
    <author>
      <name>Joel Polizzi</name>
    </author>
    <author>
      <name>Daniel Crawl</name>
    </author>
    <author>
      <name>Thomas DeFanti</name>
    </author>
    <author>
      <name>Larry Smarr</name>
    </author>
    <link href="http://arxiv.org/abs/1903.06802v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.06802v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.10904v1</id>
    <updated>2019-04-24T16:17:46Z</updated>
    <published>2019-04-24T16:17:46Z</published>
    <title>Applying machine learning to improve simulations of a chaotic dynamical
  system using empirical error correction</title>
    <summary>  Dynamical weather and climate prediction models underpin many studies of the
Earth system and hold the promise of being able to make robust projections of
future climate change based on physical laws. However, simulations from these
models still show many differences compared with observations. Machine learning
has been applied to solve certain prediction problems with great success, and
recently it's been proposed that this could replace the role of
physically-derived dynamical weather and climate models to give better quality
simulations. Here, instead, a framework using machine learning together with
physically-derived models is tested, in which it is learnt how to correct the
errors of the latter from timestep to timestep. This maintains the physical
understanding built into the models, whilst allowing performance improvements,
and also requires much simpler algorithms and less training data. This is
tested in the context of simulating the chaotic Lorenz '96 system, and it is
shown that the approach yields models that are stable and that give both
improved skill in initialised predictions and better long-term climate
statistics. Improvements in long-term statistics are smaller than for single
time-step tendencies, however, indicating that it would be valuable to develop
methods that target improvements on longer time scales. Future strategies for
the development of this approach and possible applications to making progress
on important scientific problems are discussed.
</summary>
    <author>
      <name>Peter A. G. Watson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26p, 7 figures To be published in Journal of Advances in Modeling
  Earth Systems</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.10904v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.10904v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.09370v1</id>
    <updated>2016-05-30T19:57:56Z</updated>
    <published>2016-05-30T19:57:56Z</published>
    <title>Unsupervised Discovery of El Nino Using Causal Feature Learning on
  Microlevel Climate Data</title>
    <summary>  We show that the climate phenomena of El Nino and La Nina arise naturally as
states of macro-variables when our recent causal feature learning framework
(Chalupka 2015, Chalupka 2016) is applied to micro-level measures of zonal wind
(ZW) and sea surface temperatures (SST) taken over the equatorial band of the
Pacific Ocean. The method identifies these unusual climate states on the basis
of the relation between ZW and SST patterns without any input about past
occurrences of El Nino or La Nina. The simpler alternatives of (i) clustering
the SST fields while disregarding their relationship with ZW patterns, or (ii)
clustering the joint ZW-SST patterns, do not discover El Nino. We discuss the
degree to which our method supports a causal interpretation and use a
low-dimensional toy example to explain its success over other clustering
approaches. Finally, we propose a new robust and scalable alternative to our
original algorithm (Chalupka 2016), which circumvents the need for
high-dimensional density learning.
</summary>
    <author>
      <name>Krzysztof Chalupka</name>
    </author>
    <author>
      <name>Tobias Bischoff</name>
    </author>
    <author>
      <name>Pietro Perona</name>
    </author>
    <author>
      <name>Frederick Eberhardt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for plenary presentation at UAI 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.09370v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.09370v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.07048v1</id>
    <updated>2018-09-19T08:09:04Z</updated>
    <published>2018-09-19T08:09:04Z</published>
    <title>New approach for solar tracking systems based on computer vision, low
  cost hardware and deep learning</title>
    <summary>  In this work, a new approach for Sun tracking systems is presented. Due to
the current system limitations regarding costs and operational problems, a new
approach based on low cost, computer vision open hardware and deep learning has
been developed. The preliminary tests carried out successfully in Plataforma
solar de Almeria (PSA), reveal the great potential and show the new approach as
a good alternative to traditional systems. The proposed approach can provide
key variables for the Sun tracking system control like cloud movements
prediction, block and shadow detection, atmospheric attenuation or measures of
concentrated solar radiation, which can improve the control strategies of the
system and therefore the system performance.
</summary>
    <author>
      <name>Jose A. Carballo</name>
    </author>
    <author>
      <name>Javier Bonilla</name>
    </author>
    <author>
      <name>Manuel Berenguel</name>
    </author>
    <author>
      <name>Jesús Fernández-Reche</name>
    </author>
    <author>
      <name>Ginés García</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.renene.2018.08.101</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.renene.2018.08.101" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 10 figures,</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Carballo, J. A., Bonilla, J., Berenguel, M., Fernandez-Reche, J.,
  &amp; Garcia, G. (2018). New approach for solar tracking systems based on
  computer vision, low cost hardware and deep learning. Renewable Energy</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1809.07048v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.07048v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T45" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.11682v1</id>
    <updated>2018-07-31T06:54:28Z</updated>
    <published>2018-07-31T06:54:28Z</published>
    <title>Deep Belief Networks Based Feature Generation and Regression for
  Predicting Wind Power</title>
    <summary>  Wind energy forecasting helps to manage power production, and hence, reduces
energy cost. Deep Neural Networks (DNN) mimics hierarchical learning in the
human brain and thus possesses hierarchical, distributed, and multi-task
learning capabilities. Based on aforementioned characteristics, we report Deep
Belief Network (DBN) based forecast engine for wind power prediction because of
its good generalization and unsupervised pre-training attributes. The proposed
DBN-WP forecast engine, which exhibits stochastic feature generation
capabilities and is composed of multiple Restricted Boltzmann Machines,
generates suitable features for wind power prediction using atmospheric
properties as input. DBN-WP, due to its unsupervised pre-training of RBM layers
and generalization capabilities, is able to learn the fluctuations in the
meteorological properties and thus is able to perform effective mapping of the
wind power. In the deep network, a regression layer is appended at the end to
predict sort-term wind power. It is experimentally shown that the deep learning
and unsupervised pre-training capabilities of DBN based model has comparable
and in some cases better results than hybrid and complex learning techniques
proposed for wind power prediction. The proposed prediction system based on
DBN, achieves mean values of RMSE, MAE and SDE as 0.124, 0.083 and 0.122,
respectively. Statistical analysis of several independent executions of the
proposed DBN-WP wind power prediction system demonstrates the stability of the
system. The proposed DBN-WP architecture is easy to implement and offers
generalization as regards the change in location of the wind farm is concerned.
</summary>
    <author>
      <name>Asifullah Khan</name>
    </author>
    <author>
      <name>Aneela Zameer</name>
    </author>
    <author>
      <name>Tauseef Jamal</name>
    </author>
    <author>
      <name>Ahmad Raza</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Pages:31 Figure:11 Table:5</arxiv:comment>
    <link href="http://arxiv.org/abs/1807.11682v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.11682v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.08736v1</id>
    <updated>2019-05-21T16:29:27Z</updated>
    <published>2019-05-21T16:29:27Z</published>
    <title>Identification of synoptic weather types over Taiwan area with multiple
  classifiers</title>
    <summary>  In this study, a novel machine learning approach was used to classify three
types of synoptic weather events in Taiwan area from 2001 to 2010. We used
reanalysis data with three machine learning algorithms to recognize weather
systems and evaluated their performance. Overall, the classifiers successfully
identified 52-83% of weather events (hit rate), which is higher than the
performance of traditional objective methods. The results showed that the
machine learning approach gave low false alarm rate in general, while the
support vector machine (SVM) with more principal components of reanalysis data
had higher hit rate on all tested weather events. The sensitivity tests of grid
data resolution indicated that the differences between the high- and
low-resolution datasets are limited, which implied that the proposed method can
achieve reasonable performance in weather forecasting with minimal resources.
By identifying daily weather systems in historical reanalysis data, this method
can be used to study long-term weather changes, to monitor climatological-scale
variations, and to provide a better estimate of climate projections.
Furthermore, this method can also serve as an alternative to model output
statistics and potentially be used for synoptic weather forecasting.
</summary>
    <author>
      <name>Shih-Hao Su</name>
    </author>
    <author>
      <name>Jung-Lien Chu</name>
    </author>
    <author>
      <name>Ting-Shuo Yo</name>
    </author>
    <author>
      <name>Lee-Yaw Lin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/asl.861</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/asl.861" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">journal article, open access</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Atmos Sci Lett.2018;e861</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1905.08736v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.08736v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.04067v1</id>
    <updated>2017-01-15T16:18:05Z</updated>
    <published>2017-01-15T16:18:05Z</published>
    <title>Development of a Machine Learning Based Analysis Chain for the
  Measurement of Atmospheric Muon Spectra with IceCube</title>
    <summary>  High-energy muons from air shower events detected in IceCube are selected
using state of the art machine learning algorithms. Attributes to distinguish a
HE-muon event from the background of low-energy muon bundles are selected using
the mRMR algorithm and the events are classified by a random forest model. In a
subsequent analysis step the obtained sample is used to reconstruct the
atmospheric muon energy spectrum, using the unfolding software TRUEE. The
reconstructed spectrum covers an energy range from $10^4\,$GeV to $10^6\,$GeV.
The general analysis scheme is presented, including results using the first
year of data taken with IceCube in its complete configuration with $86$
instrumented strings.
</summary>
    <author>
      <name>Tomasz Fuchs</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">XXV ECRS 2016 Proceedings - eConf C16-09-04.3</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.04067v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.04067v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.08915v1</id>
    <updated>2017-06-26T05:05:00Z</updated>
    <published>2017-06-26T05:05:00Z</published>
    <title>The Fog of War: A Machine Learning Approach to Forecasting Weather on
  Mars</title>
    <summary>  For over a decade, scientists at NASA's Jet Propulsion Laboratory (JPL) have
been recording measurements from the Martian surface as a part of the Mars
Exploration Rovers mission. One quantity of interest has been the opacity of
Mars's atmosphere for its importance in day-to-day estimations of the amount of
power available to the rover from its solar arrays. This paper proposes the use
of neural networks as a method for forecasting Martian atmospheric opacity that
is more effective than the current empirical model. The more accurate
prediction provided by these networks would allow operators at JPL to make more
accurate predictions of the amount of energy available to the rover when they
plan activities for coming sols.
</summary>
    <author>
      <name>Daniele Bellutta</name>
    </author>
    <link href="http://arxiv.org/abs/1706.08915v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.08915v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.11380v1</id>
    <updated>2018-05-29T12:19:41Z</updated>
    <published>2018-05-29T12:19:41Z</published>
    <title>Kernel embedding of maps for sequential Bayesian inference: The
  variational mapping particle filter</title>
    <summary>  In this work, a novel sequential Monte Carlo filter is introduced which aims
at efficient sampling of high-dimensional state spaces with a limited number of
particles. Particles are pushed forward from the prior to the posterior density
using a sequence of mappings that minimizes the Kullback-Leibler divergence
between the posterior and the sequence of intermediate densities. The sequence
of mappings represents a gradient flow. A key ingredient of the mappings is
that they are embedded in a reproducing kernel Hilbert space, which allows for
a practical and efficient algorithm. The embedding provides a direct means to
calculate the gradient of the Kullback-Leibler divergence leading to quick
convergence using well-known gradient-based stochastic optimization algorithms.
Evaluation of the method is conducted in the chaotic Lorenz-63 system, the
Lorenz-96 system, which is a coarse prototype of atmospheric dynamics, and an
epidemic model that describes cholera dynamics. No resampling is required in
the mapping particle filter even for long recursive sequences. The number of
effective particles remains close to the total number of particles in all the
experiments.
</summary>
    <author>
      <name>Manuel Pulido</name>
    </author>
    <author>
      <name>Peter Jan vanLeeuwen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to PNAS</arxiv:comment>
    <link href="http://arxiv.org/abs/1805.11380v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.11380v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.4245v3</id>
    <updated>2013-12-31T16:41:30Z</updated>
    <published>2013-02-18T12:41:50Z</published>
    <title>Gaussian Process Kernels for Pattern Discovery and Extrapolation</title>
    <summary>  Gaussian processes are rich distributions over functions, which provide a
Bayesian nonparametric approach to smoothing and interpolation. We introduce
simple closed form kernels that can be used with Gaussian processes to discover
patterns and enable extrapolation. These kernels are derived by modelling a
spectral density -- the Fourier transform of a kernel -- with a Gaussian
mixture. The proposed kernels support a broad class of stationary covariances,
but Gaussian process inference remains simple and analytic. We demonstrate the
proposed kernels by discovering patterns and performing long range
extrapolation on synthetic examples, as well as atmospheric CO2 trends and
airline passenger data. We also show that we can reconstruct standard
covariances within our framework.
</summary>
    <author>
      <name>Andrew Gordon Wilson</name>
    </author>
    <author>
      <name>Ryan Prescott Adams</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 5 figures, 1 table. Minor edits and titled changed from
  "Gaussian Process Covariance Kernels for Pattern Discovery and Extrapolation"
  to "Gaussian Process Kernels for Pattern Discovery and Extrapolation".
  Appears at the International Conference on Machine Learning (ICML), JMLR W&amp;CP
  28(3):1067-1075, 2013</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Machine Learning (ICML), JMLR W&amp;CP
  28(3):1067-1075, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1302.4245v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.4245v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.02811v1</id>
    <updated>2016-06-09T03:33:11Z</updated>
    <published>2016-06-09T03:33:11Z</published>
    <title>Machine Learning Techniques and Applications For Ground-based Image
  Analysis</title>
    <summary>  Ground-based whole sky cameras have opened up new opportunities for
monitoring the earth's atmosphere. These cameras are an important complement to
satellite images by providing geoscientists with cheaper, faster, and more
localized data. The images captured by whole sky imagers can have high spatial
and temporal resolution, which is an important pre-requisite for applications
such as solar energy modeling, cloud attenuation analysis, local weather
prediction, etc.
  Extracting valuable information from the huge amount of image data by
detecting and analyzing the various entities in these images is challenging.
However, powerful machine learning techniques have become available to aid with
the image analysis. This article provides a detailed walk-through of recent
developments in these techniques and their applications in ground-based
imaging. We aim to bridge the gap between computer vision and remote sensing
with the help of illustrative examples. We demonstrate the advantages of using
machine learning techniques in ground-based image analysis via three primary
applications -- segmentation, classification, and denoising.
</summary>
    <author>
      <name>Soumyabrata Dev</name>
    </author>
    <author>
      <name>Bihan Wen</name>
    </author>
    <author>
      <name>Yee Hui Lee</name>
    </author>
    <author>
      <name>Stefan Winkler</name>
    </author>
    <link href="http://arxiv.org/abs/1606.02811v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.02811v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/math/0410419v1</id>
    <updated>2004-10-19T19:47:24Z</updated>
    <published>2004-10-19T19:47:24Z</published>
    <title>An introduction to (smoothing spline) ANOVA models in RKHS with examples
  in geographical data, medicine, atmospheric science and machine learning</title>
    <summary>  Smoothing Spline ANOVA (SS-ANOVA) models in reproducing kernel Hilbert spaces
(RKHS) provide a very general framework for data analysis, modeling and
learning in a variety of fields. Discrete, noisy scattered, direct and indirect
observations can be accommodated with multiple inputs and multiple possibly
correlated outputs and a variety of meaningful structures. The purpose of this
paper is to give a brief overview of the approach and describe and contrast a
series of applications, while noting some recent results.
</summary>
    <author>
      <name>Grace Wahba</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This note has appeared in the Proceedings of the 13th IFAC Symposium
  on System Identification 2003, Rotterdam, 549-559</arxiv:comment>
    <link href="http://arxiv.org/abs/math/0410419v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/math/0410419v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62G08, 62-02, 62-07" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.04436v1</id>
    <updated>2019-06-11T08:17:17Z</updated>
    <published>2019-06-11T08:17:17Z</published>
    <title>Metrics for Learning in Topological Persistence</title>
    <summary>  Persistent homology analysis provides means to capture the connectivity
structure of data sets in various dimensions. On the mathematical level, by
defining a metric between the objects that persistence attaches to data sets,
we can stabilize invariants characterizing these objects. We outline how so
called contour functions induce relevant metrics for stabilizing the rank
invariant. On the practical level, the stable ranks are used as fingerprints
for data. Different choices of contour lead to different stable ranks and the
topological learning is then the question of finding the optimal contour. We
outline our analysis pipeline and show how it can enhance classification of
physical activities data. As our main application we study how stable ranks and
contours provide robust descriptors of spatial patterns of atmospheric cloud
fields.
</summary>
    <author>
      <name>Henri Riihimäki</name>
    </author>
    <author>
      <name>José Licón-Saláiz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.04436v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.04436v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.05418v1</id>
    <updated>2017-09-15T21:40:02Z</updated>
    <published>2017-09-15T21:40:02Z</published>
    <title>Deep Scattering: Rendering Atmospheric Clouds with Radiance-Predicting
  Neural Networks</title>
    <summary>  We present a technique for efficiently synthesizing images of atmospheric
clouds using a combination of Monte Carlo integration and neural networks. The
intricacies of Lorenz-Mie scattering and the high albedo of cloud-forming
aerosols make rendering of clouds---e.g. the characteristic silverlining and
the "whiteness" of the inner body---challenging for methods based solely on
Monte Carlo integration or diffusion theory. We approach the problem
differently. Instead of simulating all light transport during rendering, we
pre-learn the spatial and directional distribution of radiant flux from tens of
cloud exemplars. To render a new scene, we sample visible points of the cloud
and, for each, extract a hierarchical 3D descriptor of the cloud geometry with
respect to the shading location and the light source. The descriptor is input
to a deep neural network that predicts the radiance function for each shading
configuration. We make the key observation that progressively feeding the
hierarchical descriptor into the network enhances the network's ability to
learn faster and predict with high accuracy while using few coefficients. We
also employ a block design with residual connections to further improve
performance. A GPU implementation of our method synthesizes images of clouds
that are nearly indistinguishable from the reference solution within seconds
interactively. Our method thus represents a viable solution for applications
such as cloud design and, thanks to its temporal stability, also for
high-quality production of animated content.
</summary>
    <author>
      <name>Simon Kallweit</name>
    </author>
    <author>
      <name>Thomas Müller</name>
    </author>
    <author>
      <name>Brian McWilliams</name>
    </author>
    <author>
      <name>Markus Gross</name>
    </author>
    <author>
      <name>Jan Novák</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3130800.3130880</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3130800.3130880" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia 2017)</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.05418v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.05418v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.03874v1</id>
    <updated>2018-08-11T22:32:55Z</updated>
    <published>2018-08-11T22:32:55Z</published>
    <title>Orders-of-magnitude speedup in atmospheric chemistry modeling through
  neural network-based emulation</title>
    <summary>  Chemical transport models (CTMs), which simulate air pollution transport,
transformation, and removal, are computationally expensive, largely because of
the computational intensity of the chemical mechanisms: systems of coupled
differential equations representing atmospheric chemistry. Here we investigate
the potential for machine learning to reproduce the behavior of a chemical
mechanism, yet with reduced computational expense. We create a 17-layer
residual multi-target regression neural network to emulate the Carbon Bond
Mechanism Z (CBM-Z) gas-phase chemical mechanism. We train the network to match
CBM-Z predictions of changes in concentrations of 77 chemical species after one
hour, given a range of chemical and meteorological input conditions, which it
is able to do with root-mean-square error (RMSE) of less than 1.97 ppb (median
RMSE = 0.02 ppb), while achieving a 250x computational speedup. An additional
17x speedup (total 4250x speedup) is achieved by running the neural network on
a graphics-processing unit (GPU). The neural network is able to reproduce the
emergent behavior of the chemical system over diurnal cycles using Euler
integration, but additional work is needed to constrain the propagation of
errors as simulation time progresses.
</summary>
    <author>
      <name>Makoto M. Kelp</name>
    </author>
    <author>
      <name>Christopher W. Tessum</name>
    </author>
    <author>
      <name>Julian D. Marshall</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Computer code for training the neural network emulator and the
  trained model (CSV and python scripts) and supplemental text and figures
  (PDF) are available by request by emailing corresponding author Christopher
  Tessum</arxiv:comment>
    <link href="http://arxiv.org/abs/1808.03874v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.03874v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.13444v1</id>
    <updated>2018-10-31T17:57:26Z</updated>
    <published>2018-10-31T17:57:26Z</published>
    <title>Model parameter estimation using coherent structure coloring</title>
    <summary>  Lagrangian data assimilation is a complex problem in oceanic and atmospheric
modeling. Tracking drifters in large-scale geophysical flows can involve
uncertainty in drifter location, complex inertial effects, and other factors
which make comparing them to simulated Lagrangian trajectories from numerical
models extremely challenging. Temporal and spatial discretization, factors
necessary in modeling large scale flows, also contribute to separation between
real and simulated drifter trajectories. The chaotic advection inherent in
these turbulent flows tends to separate even closely spaced tracer particles,
making error metrics based solely on drifter displacements unsuitable for
estimating model parameters. We propose to instead use error in the coherent
structure coloring (CSC) field to assess model skill. The CSC field provides a
spatial representation of the underlying coherent patterns in the flow, and we
show that it is a more robust metric for assessing model accuracy. Through the
use of two test cases, one considering spatial uncertainty in particle
initialization, and one examining the influence of stochastic error along a
trajectory and temporal discretization, we show that error in the coherent
structure coloring field can be used to accurately determine single or multiple
simultaneously unknown model parameters, whereas a conventional error metric
based on error in drifter displacement fails. Because the CSC field enhances
the difference in error between correct and incorrect model parameters, error
minima in model parameter sweeps become more distinct. The effectiveness and
robustness of this method for single and multi-parameter estimation in
analytical flows suggests that Lagrangian data assimilation for real oceanic
and atmospheric models would benefit from a similar approach.
</summary>
    <author>
      <name>Kristy L. Schlueter-Kuck</name>
    </author>
    <author>
      <name>John O. Dabiri</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1017/jfm.2018.898</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1017/jfm.2018.898" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in the Journal of Fluid Mechanics</arxiv:comment>
    <link href="http://arxiv.org/abs/1810.13444v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.13444v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.04566v1</id>
    <updated>2019-07-10T08:25:02Z</updated>
    <published>2019-07-10T08:25:02Z</published>
    <title>Prospects for the Use of Photosensor Timing Information with Machine
  Learning Techniques in Background Rejection</title>
    <summary>  Recent developments in machine learning (ML) techniques present a promising
new analysis method for high-speed imaging in astroparticle physics
experiments, for example with imaging atmospheric Cherenkov telescopes (IACTs).
In particular, the use of timing information with new machine learning
techniques provides a novel method for event classification. Previous work in
this field has utilised images of the integrated charge from IACT camera
photomultipliers, but the majority of current and upcoming IACT cameras have
the capacity to read out the entire photosensor waveform following a trigger.
As the arrival times of Cherenkov photons from extensive air showers (EAS) at
the camera plane are dependent upon the altitude of their emission, these
waveforms contain information useful for IACT event classification. In this
work, we investigate the potential for using these waveforms with ML
techniques, and find that a highly effective means of utilising their
information is to create a set of seven additional two dimensional histograms
of waveform parameters to be fed into the machine learning algorithm along with
the integrated charge image. This appears to be superior to using only these
new ML techniques with the waveform integrated charge alone. We also examine
these timing-based ML techniques in the context of other experiments.
</summary>
    <author>
      <name>Samuel Spencer</name>
    </author>
    <author>
      <name>Thomas Armstrong</name>
    </author>
    <author>
      <name>Jason Watson</name>
    </author>
    <author>
      <name>Garret Cotter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 figures, Submitted to Proceedings of the 36th
  International Cosmic Ray Conference (ICRC 2019), Madison, WI, U.S.A</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.04566v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.04566v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.10012v1</id>
    <updated>2019-03-24T16:17:07Z</updated>
    <published>2019-03-24T16:17:07Z</published>
    <title>A mixture of experts model for predicting persistent weather patterns</title>
    <summary>  Weather and atmospheric patterns are often persistent. The simplest weather
forecasting method is the so-called persistence model, which assumes that the
future state of a system will be similar (or equal) to the present state.
Machine learning (ML) models are widely used in different weather forecasting
applications, but they need to be compared to the persistence model to analyse
whether they provide a competitive solution to the problem at hand. In this
paper, we devise a new model for predicting low-visibility in airports using
the concepts of mixture of experts. Visibility level is coded as two different
ordered categorical variables: cloud height and runway visual height. The
underlying system in this application is stagnant approximately in 90% of the
cases, and standard ML models fail to improve on the performance of the
persistence model. Because of this, instead of trying to simply beat the
persistence model using ML, we use this persistence as a baseline and learn an
ordinal neural network model that refines its results by focusing on learning
weather fluctuations. The results show that the proposal outperforms
persistence and other ordinal autoregressive models, especially for longer time
horizon predictions and for the runway visual height variable.
</summary>
    <author>
      <name>Maria Perez-Ortiz</name>
    </author>
    <author>
      <name>Pedro A. Gutierrez</name>
    </author>
    <author>
      <name>Peter Tino</name>
    </author>
    <author>
      <name>Carlos Casanova-Mateo</name>
    </author>
    <author>
      <name>Sancho Salcedo-Sanz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in IEEE International Joint Conference on Neural Networks
  (IJCNN) 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.10012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.10012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.08158v1</id>
    <updated>2019-01-23T22:37:11Z</updated>
    <published>2019-01-23T22:37:11Z</published>
    <title>A Tool for Spatio-Temporal Analysis of Social Anxiety with Twitter Data</title>
    <summary>  In this paper, we present a tool for analyzing spatio-temporal distribution
of social anxiety. Twitter, one of the most popular social network services,
has been chosen as data source for analysis of social anxiety. Tweets (posted
on the Twitter) contain various emotions and thus these individual emotions
reflect social atmosphere and public opinion, which are often dependent on
spatial and temporal factors. The reason why we choose anxiety among various
emotions is that anxiety is very important emotion that is useful for observing
and understanding social events of communities. We develop a machine learning
based tool to analyze the changes of social atmosphere spatially and
temporally. Our tool classifies whether each Tweet contains anxious content or
not, and also estimates degree of Tweet anxiety. Furthermore, it also
visualizes spatio-temporal distribution of anxiety as a form of web
application, which is incorporated with physical map, word cloud, search engine
and chart viewer. Our tool is applied to a big tweet data in South Korea to
illustrate its usefulness for exploring social atmosphere and public opinion
spatio-temporally.
</summary>
    <author>
      <name>Joohong Lee</name>
    </author>
    <author>
      <name>Dongyoung Son</name>
    </author>
    <author>
      <name>Yong Suk Choi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In proceedings of the 34th ACM/SIGAPP Symposium On Applied Computing
  (SAC 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.08158v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.08158v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.04816v1</id>
    <updated>2019-07-10T16:29:55Z</updated>
    <published>2019-07-10T16:29:55Z</published>
    <title>A Data-Driven Approach for Accurate Rainfall Prediction</title>
    <summary>  In recent years, there has been growing interest in using Precipitable Water
Vapor (PWV) derived from Global Positioning System (GPS) signal delays to
predict rainfall. However, the occurrence of rainfall is dependent on a myriad
of atmospheric parameters. This paper proposes a systematic approach to analyze
various parameters that affect precipitation in the atmosphere. Different
ground-based weather features like Temperature, Relative Humidity, Dew Point,
Solar Radiation, PWV along with Seasonal and Diurnal variables are identified,
and a detailed feature correlation study is presented. While all features play
a significant role in rainfall classification, only a few of them, such as PWV,
Solar Radiation, Seasonal and Diurnal features, stand out for rainfall
prediction. Based on these findings, an optimum set of features are used in a
data-driven machine learning algorithm for rainfall prediction. The
experimental evaluation using a four-year (2012-2015) database shows a true
detection rate of 80.4%, a false alarm rate of 20.3%, and an overall accuracy
of 79.6%. Compared to the existing literature, our method significantly reduces
the false alarm rates.
</summary>
    <author>
      <name>Shilpa Manandhar</name>
    </author>
    <author>
      <name>Soumyabrata Dev</name>
    </author>
    <author>
      <name>Yee Hui Lee</name>
    </author>
    <author>
      <name>Yu Song Meng</name>
    </author>
    <author>
      <name>Stefan Winkler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in IEEE Transactions on Geoscience and Remote Sensing, 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.04816v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.04816v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.07286v1</id>
    <updated>2019-05-17T14:19:30Z</updated>
    <published>2019-05-17T14:19:30Z</published>
    <title>A deep learning approach to detecting volcano deformation from satellite
  imagery using synthetic datasets</title>
    <summary>  Satellites enable widespread, regional or global surveillance of volcanoes
and can provide the first indication of volcanic unrest or eruption. Here we
consider Interferometric Synthetic Aperture Radar (InSAR), which can be
employed to detect surface deformation with a strong statistical link to
eruption. The ability of machine learning to automatically identify signals of
interest in these large InSAR datasets has already been demonstrated, but
data-driven techniques, such as convolutional neutral networks (CNN) require
balanced training datasets of positive and negative signals to effectively
differentiate between real deformation and noise. As only a small proportion of
volcanoes are deforming and atmospheric noise is ubiquitous, the use of machine
learning for detecting volcanic unrest is more challenging. In this paper, we
address this problem using synthetic interferograms to train the AlexNet. The
synthetic interferograms are composed of 3 parts: 1) deformation patterns based
on a Monte Carlo selection of parameters for analytic forward models, 2)
stratified atmospheric effects derived from weather models and 3) turbulent
atmospheric effects based on statistical simulations of correlated noise. The
AlexNet architecture trained with synthetic data outperforms that trained using
real interferograms alone, based on classification accuracy and positive
predictive value (PPV). However, the models used to generate the synthetic
signals are a simplification of the natural processes, so we retrain the CNN
with a combined dataset consisting of synthetic models and selected real
examples, achieving a final PPV of 82%. Although applying atmospheric
corrections to the entire dataset is computationally expensive, it is
relatively simple to apply them to the small subset of positive results. This
further improves the detection performance without a significant increase in
computational burden.
</summary>
    <author>
      <name>Nantheera Anantrasirichai</name>
    </author>
    <author>
      <name>Juliet Biggs</name>
    </author>
    <author>
      <name>Fabien Albino</name>
    </author>
    <author>
      <name>David Bull</name>
    </author>
    <link href="http://arxiv.org/abs/1905.07286v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.07286v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.00511v1</id>
    <updated>2018-11-28T09:55:53Z</updated>
    <published>2018-11-28T09:55:53Z</published>
    <title>Ensemble model aggregation using a computationally lightweight
  machine-learning model to forecast ocean waves</title>
    <summary>  This study investigated an approach to improve the accuracy of
computationally lightweight surrogate models by updating forecasts based on
historical accuracy relative to sparse observation data. Using a lightweight,
ocean-wave forecasting model, we created a large number of model ensembles,
with perturbed inputs, for a two-year study period. Forecasts were aggregated
using a machine-learning algorithm that combined forecasts from multiple,
independent models into a single 'best-estimate' prediction of the true state,
based on historical performance relative to observations. The framework was
applied to a case-study site in Monterey Bay, California.
A~learning-aggregation technique used historical observations and model
forecasts to calculate a weight for each ensemble member. Weighted ensemble
predictions were compared to measured wave conditions to evaluate performance
against present state-of-the-art. Finally, we discuss how this framework, which
integrates ensemble aggregations and surrogate models, can be used to improve
forecasting systems and scientific process studies.
</summary>
    <author>
      <name>Fearghal O'Donncha</name>
    </author>
    <author>
      <name>Yushan Zhang</name>
    </author>
    <author>
      <name>Bei Chen</name>
    </author>
    <author>
      <name>Scott c. James</name>
    </author>
    <link href="http://arxiv.org/abs/1812.00511v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.00511v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.07903v1</id>
    <updated>2019-03-19T09:38:37Z</updated>
    <published>2019-03-19T09:38:37Z</published>
    <title>NeuralHydrology - Interpreting LSTMs in Hydrology</title>
    <summary>  Despite the huge success of Long Short-Term Memory networks, their
applications in environmental sciences are scarce. We argue that one reason is
the difficulty to interpret the internals of trained networks. In this study,
we look at the application of LSTMs for rainfall-runoff forecasting, one of the
central tasks in the field of hydrology, in which the river discharge has to be
predicted from meteorological observations. LSTMs are particularly well-suited
for this problem since memory cells can represent dynamic reservoirs and
storages, which are essential components in state-space modelling approaches of
the hydrological system. On basis of two different catchments, one with snow
influence and one without, we demonstrate how the trained model can be analyzed
and interpreted. In the process, we show that the network internally learns to
represent patterns that are consistent with our qualitative understanding of
the hydrological system.
</summary>
    <author>
      <name>Frederik Kratzert</name>
    </author>
    <author>
      <name>Mathew Herrnegger</name>
    </author>
    <author>
      <name>Daniel Klotz</name>
    </author>
    <author>
      <name>Sepp Hochreiter</name>
    </author>
    <author>
      <name>Günter Klambauer</name>
    </author>
    <link href="http://arxiv.org/abs/1903.07903v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.07903v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.04595v1</id>
    <updated>2019-06-10T01:18:35Z</updated>
    <published>2019-06-10T01:18:35Z</published>
    <title>Evaluating aleatoric and epistemic uncertainties of time series deep
  learning models for soil moisture predictions</title>
    <summary>  Soil moisture is an important variable that determines floods, vegetation
health, agriculture productivity, and land surface feedbacks to the atmosphere,
etc. Accurately modeling soil moisture has important implications in both
weather and climate models. The recently available satellite-based observations
give us a unique opportunity to build data-driven models to predict soil
moisture instead of using land surface models, but previously there was no
uncertainty estimate. We tested Monte Carlo dropout (MCD) with an aleatoric
term for our long short-term memory models for this problem, and asked if the
uncertainty terms behave as they were argued to. We show that the method
successfully captures the predictive error after tuning a hyperparameter on a
representative training dataset. We show the MCD uncertainty estimate, as
previously argued, does detect dissimilarity.
</summary>
    <author>
      <name>Kuai Fang</name>
    </author>
    <author>
      <name>Chaopeng Shen</name>
    </author>
    <author>
      <name>Daniel Kifer</name>
    </author>
    <link href="http://arxiv.org/abs/1906.04595v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.04595v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.02546v2</id>
    <updated>2016-12-08T17:41:49Z</updated>
    <published>2016-08-08T18:30:22Z</published>
    <title>A Stackelberg Game Perspective on the Conflict Between Machine Learning
  and Data Obfuscation</title>
    <summary>  Data is the new oil; this refrain is repeated extensively in the age of
internet tracking, machine learning, and data analytics. As data collection
becomes more personal and pervasive, however, public pressure is mounting for
privacy protection. In this atmosphere, developers have created applications to
add noise to user attributes visible to tracking algorithms. This creates a
strategic interaction between trackers and users when incentives to maintain
privacy and improve accuracy are misaligned. In this paper, we conceptualize
this conflict through an N+1-player, augmented Stackelberg game. First a
machine learner declares a privacy protection level, and then users respond by
choosing their own perturbation amounts. We use the general frameworks of
differential privacy and empirical risk minimization to quantify the utility
components due to privacy and accuracy, respectively. In equilibrium, each user
perturbs her data independently, which leads to a high net loss in accuracy. To
remedy this scenario, we show that the learner improves his utility by
proactively perturbing the data himself. While other work in this area has
studied privacy markets and mechanism design for truthful reporting of user
information, we take a different viewpoint by considering both user and learner
perturbation.
</summary>
    <author>
      <name>Jeffrey Pawlick</name>
    </author>
    <author>
      <name>Quanyan Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, Presented at the 2016 IEEE International Workshop on
  Information Forensics and Security (IEEE WIFS 2016)</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.02546v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.02546v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.05668v1</id>
    <updated>2017-07-18T15:06:01Z</updated>
    <published>2017-07-18T15:06:01Z</published>
    <title>Empirical evaluation of a Q-Learning Algorithm for Model-free Autonomous
  Soaring</title>
    <summary>  Autonomous unpowered flight is a challenge for control and guidance systems:
all the energy the aircraft might use during flight has to be harvested
directly from the atmosphere. We investigate the design of an algorithm that
optimizes the closed-loop control of a glider's bank and sideslip angles, while
flying in the lower convective layer of the atmosphere in order to increase its
mission endurance. Using a Reinforcement Learning approach, we demonstrate the
possibility for real-time adaptation of the glider's behaviour to the
time-varying and noisy conditions associated with thermal soaring flight. Our
approach is online, data-based and model-free, hence avoids the pitfalls of
aerological and aircraft modelling and allow us to deal with uncertainties and
non-stationarity. Additionally, we put a particular emphasis on keeping low
computational requirements in order to make on-board execution feasible. This
article presents the stochastic, time-dependent aerological model used for
simulation, together with a standard aircraft model. Then we introduce an
adaptation of a Q-learning algorithm and demonstrate its ability to control the
aircraft and improve its endurance by exploiting updrafts in non-stationary
scenarios.
</summary>
    <author>
      <name>Erwan Lecarpentier</name>
    </author>
    <author>
      <name>Sebastian Rapp</name>
    </author>
    <author>
      <name>Marc Melo</name>
    </author>
    <author>
      <name>Emmanuel Rachelson</name>
    </author>
    <link href="http://arxiv.org/abs/1707.05668v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.05668v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.04731v3</id>
    <updated>2018-09-07T08:28:05Z</updated>
    <published>2018-06-12T19:29:25Z</published>
    <title>Deep learning to represent sub-grid processes in climate models</title>
    <summary>  The representation of nonlinear sub-grid processes, especially clouds, has
been a major source of uncertainty in climate models for decades.
Cloud-resolving models better represent many of these processes and can now be
run globally but only for short-term simulations of at most a few years because
of computational limitations. Here we demonstrate that deep learning can be
used to capture many advantages of cloud-resolving modeling at a fraction of
the computational cost. We train a deep neural network to represent all
atmospheric sub-grid processes in a climate model by learning from a
multi-scale model in which convection is treated explicitly. The trained neural
network then replaces the traditional sub-grid parameterizations in a global
general circulation model in which it freely interacts with the resolved
dynamics and the surface-flux scheme. The prognostic multi-year simulations are
stable and closely reproduce not only the mean climate of the cloud-resolving
simulation but also key aspects of variability, including precipitation
extremes and the equatorial wave spectrum. Furthermore, the neural network
approximately conserves energy despite not being explicitly instructed to.
Finally, we show that the neural network parameterization generalizes to new
surface forcing patterns but struggles to cope with temperatures far outside
its training manifold. Our results show the feasibility of using deep learning
for climate model parameterization. In a broader context, we anticipate that
data-driven Earth System Model development could play a key role in reducing
climate prediction uncertainty in the coming decade.
</summary>
    <author>
      <name>Stephan Rasp</name>
    </author>
    <author>
      <name>Michael S. Pritchard</name>
    </author>
    <author>
      <name>Pierre Gentine</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">View official PNAS version at https://doi.org/10.1073/pnas.1810286115</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the National Academy of Sciences Sep 2018,
  201810286; DOI: 10.1073/pnas.1810286115</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1806.04731v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.04731v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.04840v3</id>
    <updated>2017-03-15T22:51:17Z</updated>
    <published>2016-09-15T20:11:50Z</published>
    <title>Dictionary learning of sound speed profiles</title>
    <summary>  To provide constraints on their inversion, ocean sound speed profiles (SSPs)
often are modeled using empirical orthogonal functions (EOFs). However, this
regularization, which uses the leading order EOFs with a minimum-energy
constraint on their coefficients, often yields low resolution SSP estimates. In
this paper, it is shown that dictionary learning, a form of unsupervised
machine learning, can improve SSP resolution by generating a dictionary of
shape functions for sparse processing (e.g. compressive sensing) that optimally
compress SSPs; both minimizing the reconstruction error and the number of
coefficients. These learned dictionaries (LDs) are not constrained to be
orthogonal and thus, fit the given signals such that each signal example is
approximated using few LD entries. Here, LDs describing SSP observations from
the HF-97 experiment and the South China Sea are generated using the K-SVD
algorithm. These LDs better explain SSP variability and require fewer
coefficients than EOFs, describing much of the variability with one
coefficient. Thus, LDs improve the resolution of SSP estimates with negligible
computational burden.
</summary>
    <author>
      <name>Michael Bianco</name>
    </author>
    <author>
      <name>Peter Gerstoft</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1121/1.4977926</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1121/1.4977926" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in the Journal of the Acoustical Society of America</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J Acoust. Soc. Am. 141(3), 1749-1758, March 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1609.04840v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.04840v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.06331v1</id>
    <updated>2015-03-21T17:43:28Z</updated>
    <published>2015-03-21T17:43:28Z</published>
    <title>Exploratory Data Analysis of The KelvinHelmholtz instability in Jets</title>
    <summary>  The KelvinHelmholtz (KH) instability is a fundamental wave instability that
is frequently observed in all kinds of shear layer (jets, wakes, atmospheric
air currents etc). The study of KH-instability, coherent flow structures has a
major impact in understanding the fundamentals of fluid dynamics. Therefore
there is a need for methods that can identify and analyse these structures. In
this Final assignment, we use machine-learning methods such as Proper
Orthogonal Decomposition (POD) and Dynamic Mode Decomposition (DMD) to analyse
the coherent flow structures. We used a 2D co-axial jet as our data, with
Reynolds number corresponding to Re: 10,000. Results for POD modes and DMD
modes are discussed and compared.
</summary>
    <author>
      <name>Santosh Tirunagari</name>
    </author>
    <link href="http://arxiv.org/abs/1503.06331v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.06331v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.05857v1</id>
    <updated>2018-06-15T08:40:31Z</updated>
    <published>2018-06-15T08:40:31Z</published>
    <title>Constructing an efficient machine learning model for tornado prediction</title>
    <summary>  Tornado prediction methods and main mechanisms of tornado genesis were
analyzed. A model, based on the superposition principle, has been built. For
efficiency evaluation, the constructed model has been tested on real-life data
obtained from the University of Oklahoma (USA). It is shown that the
constructed tornado prediction model is more efficient than all previous
models.
</summary>
    <author>
      <name>F. Aleskerov</name>
    </author>
    <author>
      <name>N. Baiborodov</name>
    </author>
    <author>
      <name>S. Demin</name>
    </author>
    <author>
      <name>S. Shvydun</name>
    </author>
    <author>
      <name>T. Trafalis</name>
    </author>
    <author>
      <name>M. Richman</name>
    </author>
    <author>
      <name>V. Yakuba</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Working paper WP7/2016/05. Moscow: HSE Publishing House, 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1806.05857v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.05857v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.00132v1</id>
    <updated>2019-06-29T02:29:38Z</updated>
    <published>2019-06-29T02:29:38Z</published>
    <title>Searching for Hot Subdwarf Stars in LAMOST DR1-II. Pure spectroscopic
  identification method for hot subdwarfs</title>
    <summary>  Employing a new machine learning method, named hierarchical extreme learning
machine (HELM) algorithm, we identified 56 hot subdwarf stars in the first data
release (DR1) of the Large Sky Area Multi-Object Fibre Spectroscopic Telescope
(LAMOST) survey. The atmospheric parameters of the stars are obtained by
fitting the profiles of hydrogen (H) Balmer lines and helium (He) lines with
synthetic spectra calculated from non-Local Thermodynamic Equilibrium (NLTE)
model atmospheres. Five He-rich hot subdwarf stars were found in our sample
with their log(nHe/nH) &gt; -1 , while 51 stars are He-poor sdB, sdO and sdOB
stars. We also confirmed the two He sequences of hot subdwarf stars found by
Edelmann et al. (2003) in Teff - log(nHe/nH) diagram. The HELM algorithm works
directly on the observed spectroscopy and is able to filter out spectral
properties without supplementary photometric data. The results presented in
this study demonstrate that the HELM algorithm is a reliable method to search
for hot subdwarf stars after a suitable training is performed, and it is also
suitable to search for other objects which have obvious features in their
spectra or images.
</summary>
    <author>
      <name>Zhenxin Lei</name>
    </author>
    <author>
      <name>Yude Bu</name>
    </author>
    <author>
      <name>Jingkun Zhao</name>
    </author>
    <author>
      <name>Péter Németh</name>
    </author>
    <author>
      <name>Gang Zhao</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1093/pasj/psz006</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1093/pasj/psz006" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 8 figures, 1 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PASJ, 71, 41 (2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1907.00132v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.00132v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.07394v3</id>
    <updated>2019-05-22T10:16:23Z</updated>
    <published>2018-09-19T20:08:26Z</published>
    <title>Improving Subseasonal Forecasting in the Western U.S. with Machine
  Learning</title>
    <summary>  Water managers in the western United States (U.S.) rely on longterm forecasts
of temperature and precipitation to prepare for droughts and other wet weather
extremes. To improve the accuracy of these longterm forecasts, the U.S. Bureau
of Reclamation and the National Oceanic and Atmospheric Administration (NOAA)
launched the Subseasonal Climate Forecast Rodeo, a year-long real-time
forecasting challenge in which participants aimed to skillfully predict
temperature and precipitation in the western U.S. two to four weeks and four to
six weeks in advance. Here we present and evaluate our machine learning
approach to the Rodeo and release our SubseasonalRodeo dataset, collected to
train and evaluate our forecasting system.
  Our system is an ensemble of two regression models. The first integrates the
diverse collection of meteorological measurements and dynamic model forecasts
in the SubseasonalRodeo dataset and prunes irrelevant predictors using a
customized multitask model selection procedure. The second uses only historical
measurements of the target variable (temperature or precipitation) and
introduces multitask nearest neighbor features into a weighted local linear
regression. Each model alone is significantly more accurate than the debiased
operational U.S. Climate Forecasting System (CFSv2), and our ensemble skill
exceeds that of the top Rodeo competitor for each target variable and forecast
horizon. Moreover, over 2011-2018, an ensemble of our regression models and
debiased CFSv2 improves debiased CFSv2 skill by 40-50% for temperature and
129-169% for precipitation. We hope that both our dataset and our methods will
help to advance the state of the art in subseasonal forecasting.
</summary>
    <author>
      <name>Jessica Hwang</name>
    </author>
    <author>
      <name>Paulo Orenstein</name>
    </author>
    <author>
      <name>Judah Cohen</name>
    </author>
    <author>
      <name>Karl Pfeiffer</name>
    </author>
    <author>
      <name>Lester Mackey</name>
    </author>
    <link href="http://arxiv.org/abs/1809.07394v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.07394v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.12303v1</id>
    <updated>2019-04-28T11:07:24Z</updated>
    <published>2019-04-28T11:07:24Z</published>
    <title>Exploring Urban Air Quality with MAPS: Mobile Air Pollution Sensing</title>
    <summary>  Mobile and ubiquitous sensing of urban air quality (AQ) has received
increased attention as an economically and operationally viable means to survey
atmospheric environment with high spatial-temporal resolution. A necessary and
value-added step towards data-driven sustainable urban management is
fine-granular AQ inference, which estimates grid-level pollutant concentrations
at every instance of time using AQ data collected from fixed-location and
mobile sensors. We present the Mobile Air Pollution Sensing (MAPS) framework,
which consists of data preprocessing, urban feature extraction, and AQ
inference. This is applied to a case study in Beijing (3,025 square km, 19 June
- 16 July 2018), where PM2.5 concentrations measured by 28 fixed monitoring
stations and 15 vehicles are fused to infer hourly PM2.5 concentrations in
3,025 1km-by-1km grids. Two machine learning structures, namely Deep Feature
Spatial-Temporal Tree (DFeaST-Tree) and Deep Feature Spatial-Temporal Network
(DFeaST-Net), are proposed to infer PM2.5 concentrations supported by 62 types
of urban data that encompass geography, land use, traffic, public, and
meteorology. This allows us to infer fine-granular PM2.5 concentrations based
on sparse AQ measurements (less than 5% coverage) with good accuracy
(SMAPE&lt;15%, R-square&gt;0.9), while accounting for the regional transport of air
pollutants outside the study area. In-depth discussions are provided on the
heterogeneity of fixed and mobile data sources, spatial coverage of mobile
sensing, and importance of urban features for inferring PM2.5 concentrations.
</summary>
    <author>
      <name>Jun Song</name>
    </author>
    <author>
      <name>Ke Han</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 13 figures, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.12303v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.12303v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.06393v1</id>
    <updated>2017-08-21T19:54:05Z</updated>
    <published>2017-08-21T19:54:05Z</published>
    <title>A citizen-science approach to muon events in imaging atmospheric
  Cherenkov telescope data: the Muon Hunter</title>
    <summary>  Event classification is a common task in gamma-ray astrophysics. It can be
treated with rapidly-advancing machine learning algorithms, which have the
potential to outperform traditional analysis methods. However, a major
challenge for machine learning models is extracting reliably labelled training
examples from real data. Citizen science offers a promising approach to tackle
this challenge.
  We present "Muon Hunter", a citizen science project hosted on the Zooniverse
platform, where VERITAS data are classified multiple times by individual users
in order to select and parameterize muon events, a product from cosmic ray
induced showers. We use this dataset to train and validate a convolutional
neural-network model to identify muon events for use in monitoring and
calibration. The results of this work and our experience of using the
Zooniverse are presented.
</summary>
    <author>
      <name>Q. Feng</name>
    </author>
    <author>
      <name>for the VERITAS Collaboration</name>
    </author>
    <author>
      <name>J. Jarvis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 figures, in Proceedings of the 35th International Cosmic
  Ray Conference (ICRC 2017), Busan, South Korea</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.06393v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.06393v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.02548v3</id>
    <updated>2018-09-12T07:30:52Z</updated>
    <published>2018-02-01T08:17:58Z</published>
    <title>Predicting Hurricane Trajectories using a Recurrent Neural Network</title>
    <summary>  Hurricanes are cyclones circulating about a defined center whose closed wind
speeds exceed 75 mph originating over tropical and subtropical waters. At
landfall, hurricanes can result in severe disasters. The accuracy of predicting
their trajectory paths is critical to reduce economic loss and save human
lives. Given the complexity and nonlinearity of weather data, a recurrent
neural network (RNN) could be beneficial in modeling hurricane behavior. We
propose the application of a fully connected RNN to predict the trajectory of
hurricanes. We employed the RNN over a fine grid to reduce typical truncation
errors. We utilized their latitude, longitude, wind speed, and pressure
publicly provided by the National Hurricane Center (NHC) to predict the
trajectory of a hurricane at 6-hour intervals. Results show that this proposed
technique is competitive to methods currently employed by the NHC and can
predict up to approximately 120 hours of hurricane path.
</summary>
    <author>
      <name>Sheila Alemany</name>
    </author>
    <author>
      <name>Jonathan Beltran</name>
    </author>
    <author>
      <name>Adrian Perez</name>
    </author>
    <author>
      <name>Sam Ganzfried</name>
    </author>
    <link href="http://arxiv.org/abs/1802.02548v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.02548v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1803.10076v2</id>
    <updated>2018-08-10T13:45:00Z</updated>
    <published>2018-03-27T13:42:31Z</published>
    <title>Using Network Theory and Machine Learning to predict El Niño</title>
    <summary>  The skill of current predictions of the warm phase of the El Ni\~no Southern
Oscillation (ENSO) reduces significantly beyond a lag of six months. In this
paper, we aim to increase this prediction skill at lags up to one year. The new
method to do so combines a classical Autoregressive Integrated Moving Average
technique with a modern machine learning approach (through an Artificial Neural
Network). The attributes in such a neural network are derived from topological
properties of Climate Networks and are tested on both a Zebiak-Cane-type model
and observations. For predictions up to six months ahead, the results of the
hybrid model give a better skill than the CFSv2 ensemble prediction by the
National Centers for Environmental Prediction (NCEP). Moreover, results for a
twelve month lead time prediction have a similar skill as the shorter lead time
predictions.
</summary>
    <author>
      <name>Peter D. Nooteboom</name>
    </author>
    <author>
      <name>Qing Yi Feng</name>
    </author>
    <author>
      <name>Cristóbal López</name>
    </author>
    <author>
      <name>Emilio Hernández-García</name>
    </author>
    <author>
      <name>Henk A. Dijkstra</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5194/esd-9-969-2018</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5194/esd-9-969-2018" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Earth Syst. Dynam., 2018</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Earth System Dynamics 9, 969-983 (2018)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1803.10076v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1803.10076v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.00144v1</id>
    <updated>2018-06-01T00:10:04Z</updated>
    <published>2018-06-01T00:10:04Z</published>
    <title>Sea surface temperature prediction and reconstruction using patch-level
  neural network representations</title>
    <summary>  The forecasting and reconstruction of ocean and atmosphere dynamics from
satellite observation time series are key challenges. While model-driven
representations remain the classic approaches, data-driven representations
become more and more appealing to benefit from available large-scale
observation and simulation datasets. In this work we investigate the relevance
of recently introduced bilinear residual neural network representations, which
mimic numerical integration schemes such as Runge-Kutta, for the forecasting
and assimilation of geophysical fields from satellite-derived remote sensing
data. As a case-study, we consider satellite-derived Sea Surface Temperature
time series off South Africa, which involves intense and complex upper ocean
dynamics. Our numerical experiments demonstrate that the proposed patch-level
neural-network-based representations outperform other data-driven models,
including analog schemes, both in terms of forecasting and missing data
interpolation performance with a relative gain up to 50\% for highly dynamic
areas.
</summary>
    <author>
      <name>Said Ouala</name>
    </author>
    <author>
      <name>Cedric Herzet</name>
    </author>
    <author>
      <name>Ronan Fablet</name>
    </author>
    <link href="http://arxiv.org/abs/1806.00144v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.00144v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1811.07998v1</id>
    <updated>2018-11-14T17:50:46Z</updated>
    <published>2018-11-14T17:50:46Z</published>
    <title>Generating a Training Dataset for Land Cover Classification to Advance
  Global Development</title>
    <summary>  Semantic segmentation of land cover classes is fundamental for agricultural
and economic development work, from sustainable forestry to urban planning, yet
existing training datasets have significant limitations. To generate an open
and comprehensive training library of high resolution Earth imagery and high
quality land cover classifications, public Sentinel-2 data at 10 m spatial
resolution was matched with accurate GlobeLand30 labels from 2010, which were
filtered by agreement with an intermediary Sentinel-2 classification at 20 m
produced during atmospheric correction. Scene-level classifications were
predicted by Random Forests trained on valid reflectance data and the filtered
labels, and achieved over 80% model accuracy for a variety of locations.
Further work is required to aggregate individual scene classifications for
annual labels and to test the approach in more locations, before crowdsourcing
human validation. The goal is to create a sustained community-wide effort to
generate image labels not only for land cover, but also very specific images
for major agriculture crops across the world and other thematic categories of
interest to the global development community.
</summary>
    <author>
      <name>Yoni Nachmany</name>
    </author>
    <author>
      <name>Hamed Alemohammad</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at NIPS 2018 Workshop on Machine Learning for the
  Developing World</arxiv:comment>
    <link href="http://arxiv.org/abs/1811.07998v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1811.07998v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.11576v1</id>
    <updated>2019-04-17T08:25:02Z</updated>
    <published>2019-04-17T08:25:02Z</published>
    <title>Forecasting Drought Using Multilayer Perceptron Artificial Neural
  Network Model</title>
    <summary>  These days human beings are facing many environmental challenges due to
frequently occurring drought hazards. It may have an effect on the countrys
environment, the community, and industries. Several adverse impacts of drought
hazard are continued in Pakistan, including other hazards. However, early
measurement and detection of drought can provide guidance to water resources
management for employing drought mitigation policies. In this paper, we used a
multilayer perceptron neural network (MLPNN) algorithm for drought forecasting.
We applied and tested MLPNN algorithm on monthly time series data of
Standardized Precipitation Evapotranspiration Index (SPEI) for seventeen
climatological stations located in Northern Area and KPK (Pakistan). We found
that MLPNN has potential capability for SPEI drought forecasting based on
performance measures (i.e., Mean Average Error (MAE), the coefficient of
correlation R, and Root Mean Square Error (RMSE). Water resources and
management planner can take necessary action in advance (e.g., in water
scarcity areas) by using MLPNN model as part of their decision making.
</summary>
    <author>
      <name>Zulifqar Ali</name>
    </author>
    <author>
      <name>Ijaz Hussain</name>
    </author>
    <author>
      <name>Muhammad Faisal</name>
    </author>
    <author>
      <name>Hafiza Mamona Nazir</name>
    </author>
    <author>
      <name>Tajammal Hussain</name>
    </author>
    <author>
      <name>Muhammad Yousaf Shad</name>
    </author>
    <author>
      <name>Alaa Mohamd Shoukry</name>
    </author>
    <author>
      <name>Showkat Hussain Gani</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1155/2017/5681308</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1155/2017/5681308" rel="related"/>
    <link href="http://arxiv.org/abs/1904.11576v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.11576v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.00195v1</id>
    <updated>2019-06-01T09:58:15Z</updated>
    <published>2019-06-01T09:58:15Z</published>
    <title>Multivariate, Multistep Forecasting, Reconstruction and Feature
  Selection of Ocean Waves via Recurrent and Sequence-to-Sequence Networks</title>
    <summary>  This article explores the concepts of ocean wave multivariate multistep
forecasting, reconstruction and feature selection. We introduce recurrent
neural network frameworks, integrated with Bayesian hyperparameter optimization
and Elastic Net methods. We consider both short- and long-term forecasts and
reconstruction, for significant wave height and output power of the ocean
waves. Sequence-to-sequence neural networks are being developed for the first
time to reconstruct the missing characteristics of ocean waves based on
information from nearby wave sensors. Our results indicate that the Adam and
AMSGrad optimization algorithms are the most robust ones to optimize the
sequence-to-sequence network. For the case of significant wave height
reconstruction, we compare the proposed methods with alternatives on a
well-studied dataset. We show the superiority of the proposed methods
considering several error metrics. We design a new case study based on
measurement stations along the east coast of the United States and investigate
the feature selection concept. Comparisons substantiate the benefit of
utilizing Elastic Net. Moreover, case study results indicate that when the
number of features is considerable, having deeper structures improves the
performance.
</summary>
    <author>
      <name>Mohammad Pirhooshyaran</name>
    </author>
    <author>
      <name>Lawrence V. Snyder</name>
    </author>
    <link href="http://arxiv.org/abs/1906.00195v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00195v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.08587v1</id>
    <updated>2019-03-19T14:25:19Z</updated>
    <published>2019-03-19T14:25:19Z</published>
    <title>REBEC: Robust Evolutionary-based Calibration Approach for the Numerical
  Wind Wave Model</title>
    <summary>  The adaptation of numerical wind wave models to the local time-spatial
conditions is a problem that can be solved by using various calibration
techniques. However, the obtained sets of physical parameters become over-tuned
to specific events if there is a lack of observations. In this paper, we
propose a robust evolutionary calibration approach that allows to build the
stochastic ensemble of perturbed models and use it to achieve the trade-off
between quality and robustness of the target model. The implemented robust
ensemble-based evolutionary calibration (REBEC) approach was compared to the
baseline SPEA2 algorithm in a set of experiments with the SWAN wind wave model
configuration for the Kara Sea domain. Provided metrics for the set of
scenarios confirm the effectiveness of the REBEC approach for the majority of
calibration scenarios.
</summary>
    <author>
      <name>Pavel Vychuzhanin</name>
    </author>
    <author>
      <name>Nikolay O. Nikitin</name>
    </author>
    <author>
      <name>Anna V. Kalyuzhnaya</name>
    </author>
    <link href="http://arxiv.org/abs/1906.08587v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.08587v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.08055v1</id>
    <updated>2018-02-20T09:11:30Z</updated>
    <published>2018-02-20T09:11:30Z</published>
    <title>A Learning Based Approach for Uncertainty Analysis in Numerical Weather
  Prediction Models</title>
    <summary>  Complex numerical weather prediction models incorporate a variety of physical
processes, each described by multiple alternative physical schemes with
specific parameters. The selection of the physical schemes and the choice of
the corresponding physical parameters during model configuration can
significantly impact the accuracy of model forecasts. There is no combination
of physical schemes that works best for all times, at all locations, and under
all conditions. It is therefore of considerable interest to understand the
interplay between the choice of physics and the accuracy of the resulting
forecasts under different conditions. This paper demonstrates the use of
machine learning techniques to study the uncertainty in numerical weather
prediction models due to the interaction of multiple physical processes. The
first problem addressed herein is the estimation of systematic model errors in
output quantities of interest at future times, and the use of this information
to improve the model forecasts. The second problem considered is the
identification of those specific physical processes that contribute most to the
forecast uncertainty in the quantity of interest under specified meteorological
conditions.
  The discrepancies between model results and observations at past times are
used to learn the relationships between the choice of physical processes and
the resulting forecast errors. Numerical experiments are carried out with the
Weather Research and Forecasting (WRF) model. The output quantity of interest
is the model precipitation, a variable that is both extremely important and
very challenging to forecast. The physical processes under consideration
include various micro-physics schemes, cumulus parameterizations, short wave,
and long wave radiation schemes. The experiments demonstrate the strong
potential of machine learning approaches to aid the study of model errors.
</summary>
    <author>
      <name>Azam Moosavi</name>
    </author>
    <author>
      <name>Vishwas Rao</name>
    </author>
    <author>
      <name>Adrian Sandu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 5 figures, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1802.08055v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.08055v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.09091v1</id>
    <updated>2018-05-23T12:30:28Z</updated>
    <published>2018-05-23T12:30:28Z</published>
    <title>Neural networks for post-processing ensemble weather forecasts</title>
    <summary>  Ensemble weather predictions require statistical post-processing of
systematic errors to obtain reliable and accurate probabilistic forecasts.
Traditionally, this is accomplished with distributional regression models in
which the parameters of a predictive distribution are estimated from a training
period. We propose a flexible alternative based on neural networks that can
incorporate nonlinear relationships between arbitrary predictor variables and
forecast distribution parameters that are automatically learned in a
data-driven way rather than requiring pre-specified link functions. In a case
study of 2-meter temperature forecasts at surface stations in Germany, the
neural network approach significantly outperforms benchmark post-processing
methods while being computationally more affordable. Key components to this
improvement are the use of auxiliary predictor variables and station-specific
information with the help of embeddings. Furthermore, the trained neural
network can be used to gain insight into the importance of meteorological
variables thereby challenging the notion of neural networks as uninterpretable
black boxes. Our approach can easily be extended to other statistical
post-processing and forecasting problems. We anticipate that recent advances in
deep learning combined with the ever-increasing amounts of model and
observation data will transform the post-processing of numerical weather
forecasts in the coming decade.
</summary>
    <author>
      <name>Stephan Rasp</name>
    </author>
    <author>
      <name>Sebastian Lerch</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1175/MWR-D-18-0187.1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1175/MWR-D-18-0187.1" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Monthly Weather Review 2018, 146, 3885-3900</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1805.09091v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.09091v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.05285v1</id>
    <updated>2015-09-17T15:16:05Z</updated>
    <published>2015-09-17T15:16:05Z</published>
    <title>Decadal climate predictions using sequential learning algorithms</title>
    <summary>  Ensembles of climate models are commonly used to improve climate predictions
and assess the uncertainties associated with them. Weighting the models
according to their performances holds the promise of further improving their
predictions. Here, we use an ensemble of decadal climate predictions to
demonstrate the ability of sequential learning algorithms (SLAs) to reduce the
forecast errors and reduce the uncertainties. Three different SLAs are
considered, and their performances are compared with those of an equally
weighted ensemble, a linear regression and the climatology. Predictions of four
different variables--the surface temperature, the zonal and meridional wind,
and pressure--are considered. The spatial distributions of the performances are
presented, and the statistical significance of the improvements achieved by the
SLAs is tested. Based on the performances of the SLAs, we propose one to be
highly suitable for the improvement of decadal climate predictions.
</summary>
    <author>
      <name>Ehud Strobach</name>
    </author>
    <author>
      <name>Golan Bel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1175/JCLI-D-15-0648.1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1175/JCLI-D-15-0648.1" rel="related"/>
    <link href="http://arxiv.org/abs/1509.05285v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.05285v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62C99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.07584v2</id>
    <updated>2016-11-19T08:56:13Z</updated>
    <published>2016-03-24T14:15:17Z</published>
    <title>Source Localization on Graphs via l1 Recovery and Spectral Graph Theory</title>
    <summary>  We cast the problem of source localization on graphs as the simultaneous
problem of sparse recovery and diffusion kernel learning. An l1 regularization
term enforces the sparsity constraint while we recover the sources of diffusion
from a single snapshot of the diffusion process. The diffusion kernel is
estimated by assuming the process to be as generic as the standard heat
diffusion. We show with synthetic data that we can concomitantly learn the
diffusion kernel and the sources, given an estimated initialization. We
validate our model with cholera mortality and atmospheric tracer diffusion
data, showing also that the accuracy of the solution depends on the
construction of the graph from the data points.
</summary>
    <author>
      <name>Rodrigo Pena</name>
    </author>
    <author>
      <name>Xavier Bresson</name>
    </author>
    <author>
      <name>Pierre Vandergheynst</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/IVMSPW.2016.7528230</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/IVMSPW.2016.7528230" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 figures, published in "Image, Video, and Multidimensional
  Signal Processing Workshop (IVMSP), 2016 IEEE 12th"</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.07584v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.07584v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.06611v3</id>
    <updated>2017-09-11T18:38:40Z</updated>
    <published>2017-07-20T17:06:47Z</published>
    <title>Prolongation of SMAP to Spatio-temporally Seamless Coverage of
  Continental US Using a Deep Learning Neural Network</title>
    <summary>  The Soil Moisture Active Passive (SMAP) mission has delivered valuable
sensing of surface soil moisture since 2015. However, it has a short time span
and irregular revisit schedule. Utilizing a state-of-the-art time-series deep
learning neural network, Long Short-Term Memory (LSTM), we created a system
that predicts SMAP level-3 soil moisture data with atmospheric forcing,
model-simulated moisture, and static physiographic attributes as inputs. The
system removes most of the bias with model simulations and improves predicted
moisture climatology, achieving small test root-mean-squared error (&lt;0.035) and
high correlation coefficient &gt;0.87 for over 75\% of Continental United States,
including the forested Southeast. As the first application of LSTM in
hydrology, we show the proposed network avoids overfitting and is robust for
both temporal and spatial extrapolation tests. LSTM generalizes well across
regions with distinct climates and physiography. With high fidelity to SMAP,
LSTM shows great potential for hindcasting, data assimilation, and weather
forecasting.
</summary>
    <author>
      <name>Kuai Fang</name>
    </author>
    <author>
      <name>Chaopeng Shen</name>
    </author>
    <author>
      <name>Daniel Kifer</name>
    </author>
    <author>
      <name>Xiao Yang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/2017GL075619</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/2017GL075619" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Geophysical Research Letters, 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1707.06611v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.06611v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.05799v1</id>
    <updated>2017-11-15T20:50:08Z</updated>
    <published>2017-11-15T20:50:08Z</published>
    <title>ORBIT: Ordering Based Information Transfer Across Space and Time for
  Global Surface Water Monitoring</title>
    <summary>  Many earth science applications require data at both high spatial and
temporal resolution for effective monitoring of various ecosystem resources.
Due to practical limitations in sensor design, there is often a trade-off in
different resolutions of spatio-temporal datasets and hence a single sensor
alone cannot provide the required information. Various data fusion methods have
been proposed in the literature that mainly rely on individual timesteps when
both datasets are available to learn a mapping between features values at
different resolutions using local relationships between pixels. Earth
observation data is often plagued with spatially and temporally correlated
noise, outliers and missing data due to atmospheric disturbances which pose a
challenge in learning the mapping from a local neighborhood at individual
timesteps. In this paper, we aim to exploit time-independent global
relationships between pixels for robust transfer of information across
different scales. Specifically, we propose a new framework, ORBIT (Ordering
Based Information Transfer) that uses relative ordering constraint among pixels
to transfer information across both time and scales. The effectiveness of the
framework is demonstrated for global surface water monitoring using both
synthetic and real-world datasets.
</summary>
    <author>
      <name>Ankush Khandelwal</name>
    </author>
    <author>
      <name>Anuj Karpatne</name>
    </author>
    <author>
      <name>Vipin Kumar</name>
    </author>
    <link href="http://arxiv.org/abs/1711.05799v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.05799v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.11136v1</id>
    <updated>2019-02-26T12:50:49Z</updated>
    <published>2019-02-26T12:50:49Z</published>
    <title>Learning Dynamical Systems from Partial Observations</title>
    <summary>  We consider the problem of forecasting complex, nonlinear space-time
processes when observations provide only partial information of on the system's
state. We propose a natural data-driven framework, where the system's dynamics
are modelled by an unknown time-varying differential equation, and the
evolution term is estimated from the data, using a neural network. Any future
state can then be computed by placing the associated differential equation in
an ODE solver. We first evaluate our approach on shallow water and Euler
simulations. We find that our method not only demonstrates high quality
long-term forecasts, but also learns to produce hidden states closely
resembling the true states of the system, without direct supervision on the
latter. Additional experiments conducted on challenging, state of the art ocean
simulations further validate our findings, while exhibiting notable
improvements over classical baselines.
</summary>
    <author>
      <name>Ibrahim Ayed</name>
    </author>
    <author>
      <name>Emmanuel de Bézenac</name>
    </author>
    <author>
      <name>Arthur Pajot</name>
    </author>
    <author>
      <name>Julien Brajard</name>
    </author>
    <author>
      <name>Patrick Gallinari</name>
    </author>
    <link href="http://arxiv.org/abs/1902.11136v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.11136v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1712.01961v3</id>
    <updated>2018-07-10T22:36:57Z</updated>
    <published>2017-12-05T23:03:07Z</published>
    <title>The First Comparison Between Swarm-C Accelerometer-Derived Thermospheric
  Densities and Physical and Empirical Model Estimates</title>
    <summary>  The first systematic comparison between Swarm-C accelerometer-derived
thermospheric density and both empirical and physics-based model results using
multiple model performance metrics is presented. This comparison is performed
at the satellite's high temporal 10-s resolution, which provides a meaningful
evaluation of the models' fidelity for orbit prediction and other space weather
forecasting applications. The comparison against the physical model is
influenced by the specification of the lower atmospheric forcing, the
high-latitude ionospheric plasma convection, and solar activity. Some insights
into the model response to thermosphere-driving mechanisms are obtained through
a machine learning exercise. The results of this analysis show that the
short-timescale variations observed by Swarm-C during periods of high solar and
geomagnetic activity were better captured by the physics-based model than the
empirical models. It is concluded that Swarm-C data agree well with the
climatologies inherent within the models and are, therefore, a useful data set
for further model validation and scientific research.
</summary>
    <author>
      <name>Timothy Kodikara</name>
    </author>
    <author>
      <name>Brett Carter</name>
    </author>
    <author>
      <name>Kefei Zhang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1029/2017JA025118</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1029/2017JA025118" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">https://goo.gl/n4QvU7</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Geophysical Research: Space Physics, 123, 2018</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1712.01961v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1712.01961v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.space-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.6273v3</id>
    <updated>2015-05-09T19:06:37Z</updated>
    <published>2014-09-22T18:42:10Z</published>
    <title>Impact of Atmospheric Chromatic Effects on Weak Lensing Measurements</title>
    <summary>  Current and future imaging surveys will measure cosmic shear with statistical
precision that demands a deeper understanding of potential systematic biases in
galaxy shape measurements than has been achieved to date. We use analytic and
computational techniques to study the impact on shape measurements of two
atmospheric chromatic effects for ground-based surveys such as the Dark Energy
Survey and the Large Synoptic Survey Telescope (LSST): (i) atmospheric
differential chromatic refraction and (ii) wavelength dependence of seeing. We
investigate the effects of using the point spread function (PSF) measured with
stars to determine the shapes of galaxies that have different spectral energy
distributions than the stars. We find that both chromatic effects lead to
significant biases in galaxy shape measurements for current and future surveys,
if not corrected. Using simulated galaxy images, we find a form of chromatic
`model bias' that arises when fitting a galaxy image with a model that has been
convolved with a stellar, instead of galactic, point spread function. We show
that both forms of atmospheric chromatic biases can be predicted (and
corrected) with minimal model bias by applying an ordered set of perturbative
PSF-level corrections based on machine-learning techniques applied to six-band
photometry. Catalog-level corrections do not address the model bias. We
conclude that achieving the ultimate precision for weak lensing from current
and future ground-based imaging surveys requires a detailed understanding of
the wavelength dependence of the PSF from the atmosphere, and from other
sources such as optics and sensors. The source code for this analysis is
available at https://github.com/DarkEnergyScienceCollaboration/chroma .
</summary>
    <author>
      <name>Joshua E. Meyers</name>
    </author>
    <author>
      <name>Patricia R. Burchat</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/0004-637X/807/2/182</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/0004-637X/807/2/182" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 14 figures, accepted by ApJ</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.6273v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.6273v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.12971v1</id>
    <updated>2018-10-30T19:31:47Z</updated>
    <published>2018-10-30T19:31:47Z</published>
    <title>Fully scalable forward model grid of exoplanet transmission spectra</title>
    <summary>  Simulated exoplanet transmission spectra are critical for planning and
interpretation of observations and to explore the sensitivity of spectral
features to atmospheric thermochemical processes. We present a publicly
available generic model grid of planetary transmission spectra, scalable to a
wide range of H$_2$/He dominated atmospheres. The grid is computed using the
1D/2D atmosphere model ATMO for two different chemical scenarios, first
considering local condensation only, secondly considering global condensation
and removal of species from the atmospheric column (rainout). The entire grid
consists of 56,320 model simulations across 22 equilibrium temperatures (400 -
2600 K), four planetary gravities (5 - 50 ms$^{-2}$), five atmospheric
metallicities (1x - 200x), four C/O ratios (0.35 - 1.0), four scattering haze
parameters, four uniform cloud parameters, and two chemical scenarios. We
derive scaling equations which can be used with this grid, for a wide range of
planet-star combinations. We validate this grid by comparing it with other
model transmission spectra available in the literature. We highlight some of
the important findings, such as the rise of SO$_2$ features at 100x solar
metallicity, differences in spectral features at high C/O ratios between two
condensation approaches, the importance of VO features without TiO to constrain
the limb temperature and features of TiO/VO both, to constrain the condensation
processes. Finally, this generic grid can be used to plan future observations
using the HST, VLT, JWST and various other telescopes. The fine variation of
parameters in the grid also allows it to be incorporated in a retrieval
framework, with various machine learning techniques.
</summary>
    <author>
      <name>Jayesh M. Goyal</name>
    </author>
    <author>
      <name>Hannah R. Wakeford</name>
    </author>
    <author>
      <name>Nathan J. Mayne</name>
    </author>
    <author>
      <name>Nikole K. Lewis</name>
    </author>
    <author>
      <name>Benjamin Drummond</name>
    </author>
    <author>
      <name>David K. Sing</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1093/mnras/sty3001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1093/mnras/sty3001" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 7 figures. Accepted for Publication in MNRAS. Full grid of
  model transmission spectra and chemical abundances are available here,
  https://drive.google.com/open?id=1ZFbkPdqg37_Om7ECSspSpEp5QrUMfA9J</arxiv:comment>
    <link href="http://arxiv.org/abs/1810.12971v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.12971v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.00548v3</id>
    <updated>2018-02-11T04:30:49Z</updated>
    <published>2018-01-02T04:39:59Z</published>
    <title>A Machine Learning Approach to Adaptive Covariance Localization</title>
    <summary>  Data assimilation plays a key role in large-scale atmospheric weather
forecasting, where the state of the physical system is estimated from model
outputs and observations, and is then used as initial condition to produce
accurate future forecasts. The Ensemble Kalman Filter (EnKF) provides a
practical implementation of the statistical solution of the data assimilation
problem and has gained wide popularity as. This success can be attributed to
its simple formulation and ease of implementation. EnKF is a Monte-Carlo
algorithm that solves the data assimilation problem by sampling the probability
distributions involved in Bayes theorem. Because of this, all flavors of EnKF
are fundamentally prone to sampling errors when the ensemble size is small. In
typical weather forecasting applications, the model state space has dimension
$10^{9}-10^{12}$, while the ensemble size typically ranges between $30-100$
members. Sampling errors manifest themselves as long-range spurious
correlations and have been shown to cause filter divergence. To alleviate this
effect covariance localization dampens spurious correlations between state
variables located at a large distance in the physical space, via an empirical
distance-dependent function. The quality of the resulting analysis and forecast
is greatly influenced by the choice of the localization function parameters,
e.g., the radius of influence. The localization radius is generally tuned
empirically to yield desirable results.This work, proposes two adaptive
algorithms for covariance localization in the EnKF framework, both based on a
machine learning approach. The first algorithm adapts the localization radius
in time, while the second algorithm tunes the localization radius in both time
and space. Numerical experiments carried out with the Lorenz-96 model, and a
quasi-geostrophic model, reveal the potential of the proposed machine learning
approaches.
</summary>
    <author>
      <name>Azam Moosavi</name>
    </author>
    <author>
      <name>Ahmed Attia</name>
    </author>
    <author>
      <name>Adrian Sandu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1801.00548v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.00548v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.01603v2</id>
    <updated>2019-04-22T08:55:16Z</updated>
    <published>2018-07-03T10:50:03Z</published>
    <title>BIN-CT: Urban Waste Collection based in Predicting the Container Fill
  Level</title>
    <summary>  The fast demographic growth, together with the concentration of the
population in cities and the increasing amount of daily waste, are factors that
push to the limit the ability of waste assimilation by Nature. Therefore, we
need technological means to make an optimal management of the waste collection
process, which represents 70% of the operational cost in waste treatment. In
this article, we present a free intelligent software system, based on
computational learning algorithms, which plans the best routes for waste
collection supported by past (historical) and future (predictions) data.
  The objective of the system is the cost reduction of the waste collection
service by means of the minimization in distance traveled by any truck to
collect a container, hence the fuel consumption. At the same time the quality
of service to the citizen is increased avoiding the annoying overflows of
containers thanks to the accurate fill level predictions performed by BIN-CT.
In this article we show the features of our software system, illustrating it
operation with a real case study of a Spanish city. We conclude that the use of
BIN-CT avoids unnecessary visits to containers, reduces the distance traveled
to collect a container and therefore we obtain a reduction of total costs and
harmful emissions thrown to the atmosphere.
</summary>
    <author>
      <name>Javier Ferrer</name>
    </author>
    <author>
      <name>Enrique Alba</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.biosystems.2019.04.006</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.biosystems.2019.04.006" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, double column, 4 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1807.01603v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.01603v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.6862v1</id>
    <updated>2014-05-27T10:30:14Z</updated>
    <published>2014-05-27T10:30:14Z</published>
    <title>Open-loop tomography with artificial neural networks on CANARY: on-sky
  results</title>
    <summary>  We present recent results from the initial testing of an Artificial Neural
Network (ANN) based tomographic reconstructor Complex Atmospheric Reconstructor
based on Machine lEarNing (CARMEN) on Canary, an Adaptive Optics demonstrator
operated on the 4.2m William Herschel Telescope, La Palma. The reconstructor
was compared with contemporaneous data using the Learn and Apply (L&amp;A)
tomographic reconstructor. We find that the fully optimised L&amp;A tomographic
reconstructor outperforms CARMEN by approximately 5% in Strehl ratio or 15nm
rms in wavefront error. We also present results for Canary in Ground Layer
Adaptive Optics mode to show that the reconstructors are tomographic. The
results are comparable and this small deficit is attributed to limitations in
the training data used to build the ANN. Laboratory bench tests show that the
ANN can out perform L&amp;A under certain conditions, e.g. if the higher layer of a
model two layer atmosphere was to change in altitude by ~300~m (equivalent to a
shift of approximately one tenth of a subaperture).
</summary>
    <author>
      <name>J. Osborn</name>
    </author>
    <author>
      <name>F. J. De Cos Juez</name>
    </author>
    <author>
      <name>D. Guzman</name>
    </author>
    <author>
      <name>A. Basden</name>
    </author>
    <author>
      <name>T. J. Morris</name>
    </author>
    <author>
      <name>E. Gendron</name>
    </author>
    <author>
      <name>T. Butterley</name>
    </author>
    <author>
      <name>R. M. Myers</name>
    </author>
    <author>
      <name>A. Gueslaga</name>
    </author>
    <author>
      <name>F. S. Lasheras</name>
    </author>
    <author>
      <name>M. G. Victoria</name>
    </author>
    <author>
      <name>M. L. S. Rodriguez</name>
    </author>
    <author>
      <name>D. Gratadour</name>
    </author>
    <author>
      <name>G. Rousset</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1093/mnras/stu758</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1093/mnras/stu758" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">MNRAS 441 (3) 2508 2514 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1405.6862v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.6862v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.04103v2</id>
    <updated>2017-04-08T06:39:31Z</updated>
    <published>2016-09-14T01:01:29Z</published>
    <title>A Machine Learning Nowcasting Method based on Real-time Reanalysis Data</title>
    <summary>  Despite marked progress over the past several decades, convective storm
nowcasting remains a challenge because most nowcasting systems are based on
linear extrapolation of radar reflectivity without much consideration for other
meteorological fields. The variational Doppler radar analysis system (VDRAS) is
an advanced convective-scale analysis system capable of providing analysis of
3-D wind, temperature, and humidity by assimilating Doppler radar observations.
Although potentially useful, it is still an open question as to how to use
these fields to improve nowcasting. In this study, we present results from our
first attempt at developing a Support Vector Machine (SVM) Box-based nOWcasting
(SBOW) method under the machine learning framework using VDRAS analysis data.
The key design points of SBOW are as follows: 1) The study domain is divided
into many position-fixed small boxes and the nowcasting problem is transformed
into one question, i.e., will a radar echo &gt; 35 dBZ appear in a box in 30
minutes? 2) Box-based temporal and spatial features, which include time trends
and surrounding environmental information, are elaborately constructed, and 3)
The box-based constructed features are used to first train the SVM classifier,
and then the trained classifier is used to make predictions. Compared with
complicated and expensive expert systems, the above design of SBOW allows the
system to be small, compact, straightforward, and easy to maintain and expand
at low cost. The experimental results show that, although no complicated
tracking algorithm is used, SBOW can predict the storm movement trend and storm
growth with reasonable skill.
</summary>
    <author>
      <name>Lei Han</name>
    </author>
    <author>
      <name>Juanzhen Sun</name>
    </author>
    <author>
      <name>Wei Zhang</name>
    </author>
    <author>
      <name>Yuanyuan Xiu</name>
    </author>
    <author>
      <name>Hailei Feng</name>
    </author>
    <author>
      <name>Yinjing Lin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/2016JD025783</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/2016JD025783" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 11 figures, submitted to Journal of Geophysical Research:
  Atmospheres</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Geophys. Res. Atmos., 122, (2017)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1609.04103v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.04103v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.06920v1</id>
    <updated>2015-09-23T11:04:42Z</updated>
    <published>2015-09-23T11:04:42Z</published>
    <title>Predicting Climate Variability over the Indian Region Using Data Mining
  Strategies</title>
    <summary>  In this paper an approach based on expectation maximization (EM) clustering
to find the climate regions and a support vector machine to build a predictive
model for each of these regions is proposed. To minimize the biases in the
estimations a ten cross fold validation is adopted both for obtaining clusters
and building the predictive models. The EM clustering could identify all the
zones as per the Koppen classification over Indian region. The proposed
strategy when employed for predicting temperature has resulted in an RMSE of
$1.19$ in the Montane climate region and $0.89$ in the Humid Sub Tropical
region as compared to $2.9$ and $0.95$ respectively predicted using k-means and
linear regression method.
</summary>
    <author>
      <name>Naresh Kumar Mallenahalli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.06920v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.06920v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.06573v1</id>
    <updated>2019-02-18T13:57:55Z</updated>
    <published>2019-02-18T13:57:55Z</published>
    <title>Expanding the horizon of automated metamaterials discovery via quantum
  annealing</title>
    <summary>  Complexity of materials designed by machine learning is currently limited by
the inefficiency of classical computers. We show how quantum annealing can be
incorporated into automated materials discovery and conduct a
proof-of-principle study on designing complex thermofunctional metamaterials
consisting of SiO2, SiC, and Poly(methyl methacrylate). Empirical computing
time of our quantum-classical hybrid algorithm involving a factorization
machine, a rigorous coupled wave analysis, and a D-Wave 2000Q quantum annealer
was insensitive to the problem size, while a classical counterpart experienced
rapid increase. Our method was used to design complex structures of wavelength
selective radiators showing much better concordance with the thermal
atmospheric transparency window in comparison to existing human-designed
alternatives. Our result shows that quantum annealing provides scientists
gigantic computational power that may change how materials are designed.
</summary>
    <author>
      <name>Koki Kitai</name>
    </author>
    <author>
      <name>Jiang Guo</name>
    </author>
    <author>
      <name>Shenghong Ju</name>
    </author>
    <author>
      <name>Shu Tanaka</name>
    </author>
    <author>
      <name>Koji Tsuda</name>
    </author>
    <author>
      <name>Junichiro Shiomi</name>
    </author>
    <author>
      <name>Ryo Tamura</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.06573v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.06573v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.app-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.app-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.05468v1</id>
    <updated>2016-04-19T08:31:23Z</updated>
    <published>2016-04-19T08:31:23Z</published>
    <title>Understanding Rating Behaviour and Predicting Ratings by Identifying
  Representative Users</title>
    <summary>  Online user reviews describing various products and services are now abundant
on the web. While the information conveyed through review texts and ratings is
easily comprehensible, there is a wealth of hidden information in them that is
not immediately obvious. In this study, we unlock this hidden value behind user
reviews to understand the various dimensions along which users rate products.
We learn a set of users that represent each of these dimensions and use their
ratings to predict product ratings. Specifically, we work with restaurant
reviews to identify users whose ratings are influenced by dimensions like
'Service', 'Atmosphere' etc. in order to predict restaurant ratings and
understand the variation in rating behaviour across different cuisines. While
previous approaches to obtaining product ratings require either a large number
of user ratings or a few review texts, we show that it is possible to predict
ratings with few user ratings and no review text. Our experiments show that our
approach outperforms other conventional methods by 16-27% in terms of RMSE.
</summary>
    <author>
      <name>Rahul Kamath</name>
    </author>
    <author>
      <name>Masanao Ochi</name>
    </author>
    <author>
      <name>Yutaka Matsuo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 29th Pacific Asia Conference on Language, Information and
  Computation (PACLIC-29)</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.05468v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.05468v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.05840v2</id>
    <updated>2018-01-13T12:22:56Z</updated>
    <published>2017-09-18T09:55:31Z</published>
    <title>Autoencoder-Driven Weather Clustering for Source Estimation during
  Nuclear Events</title>
    <summary>  Emergency response applications for nuclear or radiological events can be
significantly improved via deep feature learning due to the hidden complexity
of the data and models involved. In this paper we present a novel methodology
for rapid source estimation during radiological releases based on deep feature
extraction and weather clustering. Atmospheric dispersions are then calculated
based on identified predominant weather patterns and are matched against
simulated incidents indicated by radiation readings on the ground. We evaluate
the accuracy of our methods over multiple years of weather reanalysis data in
the European region. We juxtapose these results with deep classification
convolution networks and discuss advantages and disadvantages.
</summary>
    <author>
      <name>I. A. Klampanos</name>
    </author>
    <author>
      <name>A. Davvetas</name>
    </author>
    <author>
      <name>S. Andronopoulos</name>
    </author>
    <author>
      <name>C. Pappas</name>
    </author>
    <author>
      <name>A. Ikonomopoulos</name>
    </author>
    <author>
      <name>V. Karkaletsis</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.envsoft.2018.01.014</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.envsoft.2018.01.014" rel="related"/>
    <link href="http://arxiv.org/abs/1709.05840v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.05840v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.10274v1</id>
    <updated>2019-03-25T12:44:35Z</updated>
    <published>2019-03-25T12:44:35Z</published>
    <title>A data-driven approach to precipitation parameterizations using
  convolutional encoder-decoder neural networks</title>
    <summary>  Numerical Weather Prediction (NWP) models represent sub-grid processes using
parameterizations, which are often complex and a major source of uncertainty in
weather forecasting. In this work, we devise a simple machine learning (ML)
methodology to learn parameterizations from basic NWP fields. Specifically, we
demonstrate how encoder-decoder Convolutional Neural Networks (CNN) can be used
to derive total precipitation using geopotential height as the only input.
Several popular neural network architectures, from the field of image
processing, are considered and a comparison with baseline ML methodologies is
provided. We use NWP reanalysis data to train different ML models showing how
encoder-decoder CNNs are able to interpret the spatial information contained in
the geopotential field to infer total precipitation with a high degree of
accuracy. We also provide a method to identify the levels of the geopotential
height that have a higher influence on precipitation through a variable
selection process. As far as we know, this paper covers the first attempt to
model NWP parameterizations using CNN methodologies.
</summary>
    <author>
      <name>Pablo Rozas Larraondo</name>
    </author>
    <author>
      <name>Luigi J. Renzullo</name>
    </author>
    <author>
      <name>Inaki Inza</name>
    </author>
    <author>
      <name>Jose A. Lozano</name>
    </author>
    <link href="http://arxiv.org/abs/1903.10274v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.10274v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="86-08" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.9; I.6.6; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.08279v1</id>
    <updated>2015-12-27T21:42:06Z</updated>
    <published>2015-12-27T21:42:06Z</published>
    <title>Using Causal Discovery to Track Information Flow in Spatio-Temporal Data
  - A Testbed and Experimental Results Using Advection-Diffusion Simulations</title>
    <summary>  Causal discovery algorithms based on probabilistic graphical models have
emerged in geoscience applications for the identification and visualization of
dynamical processes. The key idea is to learn the structure of a graphical
model from observed spatio-temporal data, which indicates information flow,
thus pathways of interactions, in the observed physical system. Studying those
pathways allows geoscientists to learn subtle details about the underlying
dynamical mechanisms governing our planet. Initial studies using this approach
on real-world atmospheric data have shown great potential for scientific
discovery. However, in these initial studies no ground truth was available, so
that the resulting graphs have been evaluated only by whether a domain expert
thinks they seemed physically plausible. This paper seeks to fill this gap. We
develop a testbed that emulates two dynamical processes dominant in many
geoscience applications, namely advection and diffusion, in a 2D grid. Then we
apply the causal discovery based information tracking algorithms to the
simulation data to study how well the algorithms work for different scenarios
and to gain a better understanding of the physical meaning of the graph
results, in particular of instantaneous connections. We make all data sets used
in this study available to the community as a benchmark.
  Keywords: Information flow, graphical model, structure learning, causal
discovery, geoscience.
</summary>
    <author>
      <name>Imme Ebert-Uphoff</name>
    </author>
    <author>
      <name>Yi Deng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages, 19 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.08279v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.08279v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.2194v4</id>
    <updated>2016-02-03T22:59:26Z</updated>
    <published>2012-02-10T06:35:20Z</published>
    <title>Efficient statistical classification of satellite measurements</title>
    <summary>  Supervised statistical classification is a vital tool for satellite image
processing. It is useful not only when a discrete result, such as feature
extraction or surface type, is required, but also for continuum retrievals by
dividing the quantity of interest into discrete ranges. Because of the high
resolution of modern satellite instruments and because of the requirement for
real-time processing, any algorithm has to be fast to be useful. Here we
describe an algorithm based on kernel estimation called Adaptive Gaussian
Filtering that incorporates several innovations to produce superior efficiency
as compared to three other popular methods: k-nearest-neighbour (KNN), Learning
Vector Quantization (LVQ) and Support Vector Machines (SVM). This efficiency is
gained with no compromises: accuracy is maintained, while estimates of the
conditional probabilities are returned. These are useful not only to gauge the
accuracy of an estimate in the absence of its true value, but also to
re-calibrate a retrieved image and as a proxy for a discretized continuum
variable. The algorithm is demonstrated and compared with the other three on a
pair of synthetic test classes and to map the waterways of the Netherlands.
Software may be found at: http://libagf.sourceforge.net.
</summary>
    <author>
      <name>Peter Mills</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/01431161.2010.507795</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/01431161.2010.507795" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Corrected formatting errors, corrected equation in appendix</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Remote Sensing, 2011, 32(21): 6109-6132</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.2194v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.2194v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.3775v1</id>
    <updated>2012-09-17T20:00:02Z</updated>
    <published>2012-09-17T20:00:02Z</published>
    <title>Using Machine Learning for Discovery in Synoptic Survey Imaging</title>
    <summary>  Modern time-domain surveys continuously monitor large swaths of the sky to
look for astronomical variability. Astrophysical discovery in such data sets is
complicated by the fact that detections of real transient and variable sources
are highly outnumbered by bogus detections caused by imperfect subtractions,
atmospheric effects and detector artefacts. In this work we present a machine
learning (ML) framework for discovery of variability in time-domain imaging
surveys. Our ML methods provide probabilistic statements, in near real time,
about the degree to which each newly observed source is astrophysically
relevant source of variable brightness. We provide details about each of the
analysis steps involved, including compilation of the training and testing
sets, construction of descriptive image-based and contextual features, and
optimization of the feature subset and model tuning parameters. Using a
validation set of nearly 30,000 objects from the Palomar Transient Factory, we
demonstrate a missed detection rate of at most 7.7% at our chosen
false-positive rate of 1% for an optimized ML classifier of 23 features,
selected to avoid feature correlation and over-fitting from an initial library
of 42 attributes. Importantly, we show that our classification methodology is
insensitive to mis-labelled training data up to a contamination of nearly 10%,
making it easier to compile sufficient training sets for accurate performance
in future surveys. This ML framework, if so adopted, should enable the
maximization of scientific gain from future synoptic survey and enable fast
follow-up decisions on the vast amounts of streaming data produced by such
experiments.
</summary>
    <author>
      <name>Henrik Brink</name>
    </author>
    <author>
      <name>Joseph W. Richards</name>
    </author>
    <author>
      <name>Dovi Poznanski</name>
    </author>
    <author>
      <name>Joshua S. Bloom</name>
    </author>
    <author>
      <name>John Rice</name>
    </author>
    <author>
      <name>Sahand Negahban</name>
    </author>
    <author>
      <name>Martin Wainwright</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1093/mnras/stt1306</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1093/mnras/stt1306" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.3775v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.3775v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.01617v3</id>
    <updated>2019-03-05T00:34:45Z</updated>
    <published>2018-05-04T05:44:56Z</published>
    <title>Searching for hot subdwarf stars from the LAMOST spectra. III.
  classifying the hot subdwarf stars from LAMOST DR4 using deep learning method</title>
    <summary>  Hot subdwarf stars are core He burning stars located at the blue end of the
horizontal branch, also known as the extreme horizontal branch. The properties
of hot subdwarf stars are important for our understanding of the stellar
astrophysics, globular clusters and galaxies. The spectra of hot subdwarf stars
can provide us with the detailed information of the stellar atmospheric
parameters (such as effective temperature, gravity, and helium abundances),
which is important to clarify the astrophysical and statistical properties of
hot subdwarf stars. These properties can provide important constraint on the
theoretical models of hot subdwarf stars. Searching for hot subdwarf stars from
the spectra data obtained by the Large Sky Area Multi-Object Fiber
Spectroscopic Telescope (LAMOST) can significantly enlarge the sample size of
hot subdwarf stars, and help us better study the nature of hot subdwarf stars.
In this paper we study a new method of searching for hot subdwarf stars from
LAMOST spectra using convolutional neural networks and support vector machine
(CNN+SVM). The experiment on the spectra from LAMOST DR4 shows that CNN+SVM can
classify the hot subdwarf stars accurately: the accuracy is 88.98$\%$ and the
recall is 94.38 $\%$. Our research provides a new machine learning tool for
searching for hot subdwarf stars in large spectroscopic surveys.
</summary>
    <author>
      <name>Yude Bu</name>
    </author>
    <author>
      <name>Jingjing Zeng</name>
    </author>
    <author>
      <name>Zhenxin Lei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">There are too many errors</arxiv:comment>
    <link href="http://arxiv.org/abs/1805.01617v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.01617v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.11542v1</id>
    <updated>2018-05-29T15:33:08Z</updated>
    <published>2018-05-29T15:33:08Z</published>
    <title>Forward Amortized Inference for Likelihood-Free Variational
  Marginalization</title>
    <summary>  In this paper, we introduce a new form of amortized variational inference by
using the forward KL divergence in a joint-contrastive variational loss. The
resulting forward amortized variational inference is a likelihood-free method
as its gradient can be sampled without bias and without requiring any
evaluation of either the model joint distribution or its derivatives. We prove
that our new variational loss is optimized by the exact posterior marginals in
the fully factorized mean-field approximation, a property that is not shared
with the more conventional reverse KL inference. Furthermore, we show that
forward amortized inference can be easily marginalized over large families of
latent variables in order to obtain a marginalized variational posterior. We
consider two examples of variational marginalization. In our first example we
train a Bayesian forecaster for predicting a simplified chaotic model of
atmospheric convection. In the second example we train an amortized variational
approximation of a Bayesian optimal classifier by marginalizing over the model
space. The result is a powerful meta-classification network that can solve
arbitrary classification problems without further training.
</summary>
    <author>
      <name>Luca Ambrogioni</name>
    </author>
    <author>
      <name>Umut Güçlü</name>
    </author>
    <author>
      <name>Julia Berezutskaya</name>
    </author>
    <author>
      <name>Eva W. P. van den Borne</name>
    </author>
    <author>
      <name>Yağmur Güçlütürk</name>
    </author>
    <author>
      <name>Max Hinne</name>
    </author>
    <author>
      <name>Eric Maris</name>
    </author>
    <author>
      <name>Marcel A. J. van Gerven</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1805.11542v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.11542v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.03456v2</id>
    <updated>2019-06-05T22:32:08Z</updated>
    <published>2018-07-10T02:39:33Z</published>
    <title>Predicting property damage from tornadoes with zero-inflated neural
  networks</title>
    <summary>  Tornadoes are the most violent of all atmospheric storms. In a typical year,
the United States experiences hundreds of tornadoes with associated damages on
the order of one billion dollars. Community preparation and resilience would
benefit from accurate predictions of these economic losses, particularly as
populations in tornado-prone areas increase in density and extent. Here, we use
a zero-inflated modeling approach and artificial neural networks to predict
tornado-induced property damage using publicly available data. We developed a
neural network that predicts whether a tornado will cause property damage
(out-of-sample accuracy = 0.821 and area under the receiver operating
characteristic curve, AUROC, = 0.872). Conditional on a tornado causing damage,
another neural network predicts the amount of damage (out-of-sample mean
squared error = 0.0918 and R2 = 0.432). When used together, these two models
function as a zero-inflated log-normal regression with hidden layers. From the
best-performing models, we provide static and interactive gridded maps of
monthly predicted probabilities of damage and property damages for the year
2019. Two primary weaknesses include (1) model fitting requires log-scale data
which leads to large natural-scale residuals and (2) beginning tornado
coordinates were utilized rather than tornado paths. Ultimately, this is the
first known study to directly model tornado-induced property damages, and all
data, code, and tools are publicly available. The predictive capacity of this
model along with an interactive interface may provide an opportunity for
science-informed tornado disaster planning.
</summary>
    <author>
      <name>Jeremy Diaz</name>
    </author>
    <author>
      <name>Maxwell Joseph</name>
    </author>
    <link href="http://arxiv.org/abs/1807.03456v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.03456v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.08390v2</id>
    <updated>2019-04-18T08:07:04Z</updated>
    <published>2019-04-17T17:46:02Z</published>
    <title>Recovering Thermodynamics from Spectral Profiles observed by IRIS: A
  Machine and Deep Learning Approach</title>
    <summary>  Inversion codes allow reconstructing a model atmosphere from observations.
With the inclusion of optically thick lines that form in the solar
chromosphere, such modelling is computationally very expensive because a
non-LTE evaluation of the radiation field is required. In this study, we
combine the results provided by these traditional methods with machine and deep
learning techniques to obtain similar-quality results in an easy-touse, much
faster way. We have applied these new methods to Mg II h&amp;k lines observed by
IRIS. As a result, we are able to reconstruct the thermodynamic state
(temperature, line-of-sight velocity, non-thermal velocities, electron density,
etc.) in the chromosphere and upper photosphere of an area equivalent to an
active region in a few CPU minutes, speeding up the process by a factor of
$10^5$-$10^6$. The open-source code accompanying this paper will allow the
community to use IRIS observations to open a new window to a host of solar
phenomena.
</summary>
    <author>
      <name>Alberto Sainz Dalda</name>
    </author>
    <author>
      <name>Jaime de la Cruz Rodríguez</name>
    </author>
    <author>
      <name>Bart De Pontieu</name>
    </author>
    <author>
      <name>Milan Gošić</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3847/2041-8213/ab15d9</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3847/2041-8213/ab15d9" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ApJL 875 L18 (2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1904.08390v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.08390v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.13290v2</id>
    <updated>2019-07-10T05:28:16Z</updated>
    <published>2019-05-30T20:24:25Z</published>
    <title>Seeing the Wind: Visual Wind Speed Prediction with a Coupled
  Convolutional and Recurrent Neural Network</title>
    <summary>  Wind energy resource quantification, air pollution monitoring, and weather
forecasting all rely on rapid, accurate measurement of local wind conditions.
Visual observations of the effects of wind---the swaying of trees and flapping
of flags, for example---encode information regarding local wind conditions that
can potentially be leveraged for visual anemometry that is inexpensive and
ubiquitous. Here, we demonstrate a coupled convolutional neural network and
recurrent neural network architecture that extracts the wind speed encoded in
visually recorded flow-structure interactions of a flag in naturally occurring
wind. Predictions for wind speeds ranging from 0.75-11 m/s showed agreement
with measurements from a cup anemometer on site, with a root-mean-square error
approaching the natural wind speed variability due to atmospheric turbulence.
Generalizability of the network was demonstrated by successful prediction of
wind speed based on recordings of other flags in the field and in a controlled
in wind tunnel test. Furthermore, physics-based scaling of the flapping
dynamics accurately predicts the dependence of the network performance on the
video frame rate and duration.
</summary>
    <author>
      <name>Jennifer L Cardona</name>
    </author>
    <author>
      <name>Michael F Howland</name>
    </author>
    <author>
      <name>John O Dabiri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In this updated submission, the adjacent flag test set and the
  calculation of the root-mean-square error for the tunnel test set were
  corrected. These corrections manifested in changes to the reported error
  values in Table 2, and the results for the adjacent flag test set shown in
  Figure 3b. Section 5.2 and Section 5.3 have also been updated to reflect
  these changes</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.13290v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.13290v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.07912v2</id>
    <updated>2018-02-08T10:09:35Z</updated>
    <published>2018-01-24T10:24:23Z</published>
    <title>Machine learning in APOGEE: Unsupervised spectral classification with
  $K$-means</title>
    <summary>  The data volume generated by astronomical surveys is growing rapidly.
Traditional analysis techniques in spectroscopy either demand intensive human
interaction or are computationally expensive. In this scenario, machine
learning, and unsupervised clustering algorithms in particular offer
interesting alternatives. The Apache Point Observatory Galactic Evolution
Experiment (APOGEE) offers a vast data set of near-infrared stellar spectra
which is perfect for testing such alternatives. Apply an unsupervised
classification scheme based on $K$-means to the massive APOGEE data set.
Explore whether the data are amenable to classification into discrete classes.
We apply the $K$-means algorithm to 153,847 high resolution spectra
($R\approx22,500$). We discuss the main virtues and weaknesses of the
algorithm, as well as our choice of parameters. We show that a classification
based on normalised spectra captures the variations in stellar atmospheric
parameters, chemical abundances, and rotational velocity, among other factors.
The algorithm is able to separate the bulge and halo populations, and
distinguish dwarfs, sub-giants, RC and RGB stars. However, a discrete
classification in flux space does not result in a neat organisation in the
parameters space. Furthermore, the lack of obvious groups in flux space causes
the results to be fairly sensitive to the initialisation, and disrupts the
efficiency of commonly-used methods to select the optimal number of clusters.
Our classification is publicly available, including extensive online material
associated with the APOGEE Data Release 12 (DR12). Our description of the
APOGEE database can enormously help with the identification of specific types
of targets for various applications. We find a lack of obvious groups in flux
space, and identify limitations of the $K$-means algorithm in dealing with this
kind of data.
</summary>
    <author>
      <name>Rafael Garcia-Dias</name>
    </author>
    <author>
      <name>Carlos Allende Prieto</name>
    </author>
    <author>
      <name>Jorge Sánchez Almeida</name>
    </author>
    <author>
      <name>Ignacio Ordovás-Pascual</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1051/0004-6361/201732134</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1051/0004-6361/201732134" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 24 images and online material</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">A&amp;A 612, A98 (2018)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1801.07912v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.07912v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.06841v1</id>
    <updated>2019-05-13T18:45:55Z</updated>
    <published>2019-05-13T18:45:55Z</published>
    <title>Enforcing Statistical Constraints in Generative Adversarial Networks for
  Modeling Chaotic Dynamical Systems</title>
    <summary>  Simulating complex physical systems often involves solving partial
differential equations (PDEs) with some closures due to the presence of
multi-scale physics that cannot be fully resolved. Therefore, reliable and
accurate closure models for unresolved physics remains an important requirement
for many computational physics problems, e.g., turbulence simulation. Recently,
several researchers have adopted generative adversarial networks (GANs), a
novel paradigm of training machine learning models, to generate solutions of
PDEs-governed complex systems without having to numerically solve these PDEs.
However, GANs are known to be difficult in training and likely to converge to
local minima, where the generated samples do not capture the true statistics of
the training data. In this work, we present a statistical constrained
generative adversarial network by enforcing constraints of covariance from the
training data, which results in an improved machine-learning-based emulator to
capture the statistics of the training data generated by solving fully resolved
PDEs. We show that such a statistical regularization leads to better
performance compared to standard GANs, measured by (1) the constrained model's
ability to more faithfully emulate certain physical properties of the system
and (2) the significantly reduced (by up to 80%) training time to reach the
solution. We exemplify this approach on the Rayleigh-Benard convection, a
turbulent flow system that is an idealized model of the Earth's atmosphere.
With the growth of high-fidelity simulation databases of physical systems, this
work suggests great potential for being an alternative to the explicit modeling
of closures or parameterizations for unresolved physics, which are known to be
a major source of uncertainty in simulating multi-scale physical systems, e.g.,
turbulence or Earth's climate.
</summary>
    <author>
      <name>Jin-Long Wu</name>
    </author>
    <author>
      <name>Karthik Kashinath</name>
    </author>
    <author>
      <name>Adrian Albert</name>
    </author>
    <author>
      <name>Dragos Chirila</name>
    </author>
    <author>
      <name> Prabhat</name>
    </author>
    <author>
      <name>Heng Xiao</name>
    </author>
    <link href="http://arxiv.org/abs/1905.06841v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.06841v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.07328v1</id>
    <updated>2017-09-21T13:53:42Z</updated>
    <published>2017-09-21T13:53:42Z</published>
    <title>Stochastic parameterization identification using ensemble Kalman
  filtering combined with expectation-maximization and Newton-Raphson maximum
  likelihood methods</title>
    <summary>  For modelling geophysical systems, large-scale processes are described
through a set of coarse-grained dynamical equations while small-scale processes
are represented via parameterizations. This work proposes a method for
identifying the best possible stochastic parameterization from noisy data.
State-the-art sequential estimation methods such as Kalman and particle filters
do not achieve this goal succesfully because both suffer from the collapse of
the parameter posterior distribution. To overcome this intrinsic limitation, we
propose two statistical learning methods. They are based on the combination of
two methodologies: the maximization of the likelihood via
Expectation-Maximization (EM) and Newton-Raphson (NR) algorithms which are
mainly applied in the statistic and machine learning communities, and the
ensemble Kalman filter (EnKF). The methods are derived using a Bayesian
approach for a hidden Markov model. They are applied to infer deterministic and
stochastic physical parameters from noisy observations in coarse-grained
dynamical models. Numerical experiments are conducted using the Lorenz-96
dynamical system with one and two scales as a proof-of-concept. The imperfect
coarse-grained model is modelled through a one-scale Lorenz-96 system in which
a stochastic parameterization is incorpored to represent the small-scale
dynamics. The algorithms are able to identify an optimal stochastic
parameterization with a good accuracy under moderate observational noise. The
proposed EnKF-EM and EnKF-NR are promising statistical learning methods for
developing stochastic parameterizations in high-dimensional geophysical models.
</summary>
    <author>
      <name>Manuel Pulido</name>
    </author>
    <author>
      <name>Pierre Tandeo</name>
    </author>
    <author>
      <name>Marc Bocquet</name>
    </author>
    <author>
      <name>Alberto Carrassi</name>
    </author>
    <author>
      <name>Magdalena Lucini</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/16000870.2018.1442099</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/16000870.2018.1442099" rel="related"/>
    <link href="http://arxiv.org/abs/1709.07328v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.07328v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.00125v1</id>
    <updated>2019-03-30T00:30:06Z</updated>
    <published>2019-03-30T00:30:06Z</published>
    <title>Identifying Solar Flare Precursors Using Time Series of SDO/HMI Images
  and SHARP Parameters</title>
    <summary>  We present several methods towards construction of precursors, which show
great promise towards early predictions, of solar flare events in this paper. A
data pre-processing pipeline is built to extract useful data from multiple
sources (Geostationary Operational Environmental Satellites (GOES) and Solar
Dynamics Observatory (SDO)/Helioseismic and Magnetic Imager (HMI) to prepare
inputs for machine learning algorithms. Two classification models are
presented: classification of flares from quiet times for active regions and
classification of strong versus weak flare events. We adopt deep learning
algorithms to capture both the spatial and temporal information from HMI
magnetogram data. Effective feature extraction and feature selection with raw
magnetogram data using deep learning and statistical algorithms enable us to
train classification models to achieve almost as good performance as using
active region parameters provided in HMI/Space-Weather HMI-Active Region Patch
(SHARP) data files. The results show great promise towards accurate, reliable,
and timely predictions of solar flare events. The use of Atmospheric Imaging
Assembly (AIA) data will be the topic of future studies.
</summary>
    <author>
      <name>Yang Chen</name>
    </author>
    <author>
      <name>Ward B. Manchester</name>
    </author>
    <author>
      <name>Alfred O. Hero</name>
    </author>
    <author>
      <name>Gabor Toth</name>
    </author>
    <author>
      <name>Benoit DuFumier</name>
    </author>
    <author>
      <name>Tian Zhou</name>
    </author>
    <author>
      <name>Xiantong Wang</name>
    </author>
    <author>
      <name>Haonan Zhu</name>
    </author>
    <author>
      <name>Zeyu Sun</name>
    </author>
    <author>
      <name>Tamas I. Gombosi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages, 16 figures, submitted to "Space Weather"</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.00125v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.00125v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.3251v2</id>
    <updated>2011-09-28T11:35:38Z</updated>
    <published>2011-09-15T03:31:13Z</published>
    <title>A Gaussian process framework for modelling instrumental systematics:
  application to transmission spectroscopy</title>
    <summary>  Transmission spectroscopy, which consists of measuring the
wavelength-dependent absorption of starlight by a planet's atmosphere during a
transit, is a powerful probe of atmospheric composition. However, the expected
signal is typically orders of magnitude smaller than instrumental systematics,
and the results are crucially dependent on the treatment of the latter. In this
paper, we propose a new method to infer transit parameters in the presence of
systematic noise using Gaussian processes, a technique widely used in the
machine learning community for Bayesian regression and classification problems.
Our method makes use of auxiliary information about the state of the
instrument, but does so in a non-parametric manner, without imposing a specific
dependence of the systematics on the instrumental parameters, and naturally
allows for the correlated nature of the noise. We give an example application
of the method to archival NICMOS transmission spectroscopy of the hot Jupiter
HD 189733, which goes some way towards reconciling the controversy surrounding
this dataset in the literature. Finally, we provide an appendix giving a
general introduction to Gaussian processes for regression, in order to
encourage their application to a wider range of problems.
</summary>
    <author>
      <name>N. P. Gibson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Oxford</arxiv:affiliation>
    </author>
    <author>
      <name>S. Aigrain</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Oxford</arxiv:affiliation>
    </author>
    <author>
      <name>S. Roberts</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Oxford</arxiv:affiliation>
    </author>
    <author>
      <name>T. M. Evans</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Oxford</arxiv:affiliation>
    </author>
    <author>
      <name>M. Osborne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Oxford</arxiv:affiliation>
    </author>
    <author>
      <name>F. Pont</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Exeter</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1111/j.1365-2966.2011.19915.x</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1111/j.1365-2966.2011.19915.x" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 figures, 1 table, accepted for publication in MNRAS</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.3251v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.3251v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.7476v1</id>
    <updated>2014-09-26T06:27:30Z</updated>
    <published>2014-09-26T06:27:30Z</published>
    <title>Short-term solar irradiance and irradiation forecasts via different time
  series techniques: A preliminary study</title>
    <summary>  This communication is devoted to solar irradiance and irradiation short-term
forecasts, which are useful for electricity production. Several different time
series approaches are employed. Our results and the corresponding numerical
simulations show that techniques which do not need a large amount of historical
data behave better than those which need them, especially when those data are
quite noisy.
</summary>
    <author>
      <name>Cédric Join</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lille - Nord Europe, CRAN, AL.I.E.N.</arxiv:affiliation>
    </author>
    <author>
      <name>Cyril Voyant</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SPE</arxiv:affiliation>
    </author>
    <author>
      <name>Michel Fliess</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AL.I.E.N., LIX</arxiv:affiliation>
    </author>
    <author>
      <name>Marc Muselli</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SPE</arxiv:affiliation>
    </author>
    <author>
      <name>Marie Laure Nivet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SPE</arxiv:affiliation>
    </author>
    <author>
      <name>Christophe Paoli</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CRAN</arxiv:affiliation>
    </author>
    <author>
      <name>Frédéric Chaxel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CRAN</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">3rd International Symposium on Environment-Friendly Energies and
  Applications (EFEA 2014), Pars : France (2014)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1409.7476v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.7476v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.6219v1</id>
    <updated>2014-12-19T05:22:07Z</updated>
    <published>2014-12-19T05:22:07Z</published>
    <title>Information-Theoretic Methods for Identifying Relationships among
  Climate Variables</title>
    <summary>  Information-theoretic quantities, such as entropy, are used to quantify the
amount of information a given variable provides. Entropies can be used together
to compute the mutual information, which quantifies the amount of information
two variables share. However, accurately estimating these quantities from data
is extremely challenging. We have developed a set of computational techniques
that allow one to accurately compute marginal and joint entropies. These
algorithms are probabilistic in nature and thus provide information on the
uncertainty in our estimates, which enable us to establish statistical
significance of our findings. We demonstrate these methods by identifying
relations between cloud data from the International Satellite Cloud Climatology
Project (ISCCP) and data from other sources, such as equatorial pacific sea
surface temperatures (SST).
</summary>
    <author>
      <name>Kevin H. Knuth</name>
    </author>
    <author>
      <name>Deniz Gençağa</name>
    </author>
    <author>
      <name>William B. Rossow</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the Earth-Sun System Technology Conference (ESTC 2008),
  Adelphi, MD. http://esto.nasa.gov/conferences/estc2008/ 3 pages, 3 figures.
  Appears in the Proceedings of the Earth-Sun System Technology Conference
  (ESTC 2008), Adelphi, MD</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.6219v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.6219v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.01729v1</id>
    <updated>2016-02-04T16:21:09Z</updated>
    <published>2016-02-04T16:21:09Z</published>
    <title>Correntropy Maximization via ADMM - Application to Robust Hyperspectral
  Unmixing</title>
    <summary>  In hyperspectral images, some spectral bands suffer from low signal-to-noise
ratio due to noisy acquisition and atmospheric effects, thus requiring robust
techniques for the unmixing problem. This paper presents a robust supervised
spectral unmixing approach for hyperspectral images. The robustness is achieved
by writing the unmixing problem as the maximization of the correntropy
criterion subject to the most commonly used constraints. Two unmixing problems
are derived: the first problem considers the fully-constrained unmixing, with
both the non-negativity and sum-to-one constraints, while the second one deals
with the non-negativity and the sparsity-promoting of the abundances. The
corresponding optimization problems are solved efficiently using an alternating
direction method of multipliers (ADMM) approach. Experiments on synthetic and
real hyperspectral images validate the performance of the proposed algorithms
for different scenarios, demonstrating that the correntropy-based unmixing is
robust to outlier bands.
</summary>
    <author>
      <name>Fei Zhu</name>
    </author>
    <author>
      <name>Abderrahim Halimi</name>
    </author>
    <author>
      <name>Paul Honeine</name>
    </author>
    <author>
      <name>Badong Chen</name>
    </author>
    <author>
      <name>Nanning Zheng</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TGRS.2017.2696262</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TGRS.2017.2696262" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.01729v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.01729v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.05012v1</id>
    <updated>2016-09-16T11:45:50Z</updated>
    <published>2016-09-16T11:45:50Z</published>
    <title>Spatial Patterns of Wind Speed Distributions in Switzerland</title>
    <summary>  This paper presents an initial exploration of high frequency records of
extreme wind speed in two steps. The first consists in finding the suitable
extreme distribution for $120$ measuring stations in Switzerland, by comparing
three known distributions: Weibull, Gamma, and Generalized extreme value. This
comparison serves as a basis for the second step which applies a spatial
modelling by using Extreme Learning Machine. The aim is to model distribution
parameters by employing a high dimensional input space of topographical
information. The knowledge of probability distribution gives a comprehensive
information and a global overview of wind phenomena. Through this study, a
flexible and a simple modelling approach is presented, which can be generalized
to almost extreme environmental data for risk assessment and to model renewable
energy.
</summary>
    <author>
      <name>Mohamed Laib</name>
    </author>
    <author>
      <name>Mikhail Kanevski</name>
    </author>
    <link href="http://arxiv.org/abs/1609.05012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.05012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
