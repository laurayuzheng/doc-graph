<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Asatellite%20AND%20all%3Amachine%20AND%20all%3Alearning%26id_list%3D%26start%3D0%26max_results%3D100" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:satellite AND all:machine AND all:learning&amp;id_list=&amp;start=0&amp;max_results=100</title>
  <id>http://arxiv.org/api/I+FKsLNlO5jN0FnMU99sB3oalv4</id>
  <updated>2019-07-16T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">177</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">100</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/1806.03002v1</id>
    <updated>2018-06-08T07:46:34Z</updated>
    <published>2018-06-08T07:46:34Z</published>
    <title>Domain Adaptive Generation of Aircraft on Satellite Imagery via
  Simulated and Unsupervised Learning</title>
    <summary>  Object detection and classification for aircraft are the most important tasks
in the satellite image analysis. The success of modern detection and
classification methods has been based on machine learning and deep learning.
One of the key requirements for those learning processes is huge data to train.
However, there is an insufficient portion of aircraft since the targets are on
military action and oper- ation. Considering the characteristics of satellite
imagery, this paper attempts to provide a framework of the simulated and
unsupervised methodology without any additional su- pervision or physical
assumptions. Finally, the qualitative and quantitative analysis revealed a
potential to replenish insufficient data for machine learning platform for
satellite image analysis.
</summary>
    <author>
      <name>Junghoon Seo</name>
    </author>
    <author>
      <name>Seunghyun Jeon</name>
    </author>
    <author>
      <name>Taegyun Jeon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">presented at the International Workshop on Machine Learning for
  Artificial Intelligence Platforms held in 2017 Asian Conference on Machine
  Learning (MLAIP@ACML)</arxiv:comment>
    <link href="http://arxiv.org/abs/1806.03002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.03002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.03654v1</id>
    <updated>2017-11-10T00:21:54Z</updated>
    <published>2017-11-10T00:21:54Z</published>
    <title>Poverty Prediction with Public Landsat 7 Satellite Imagery and Machine
  Learning</title>
    <summary>  Obtaining detailed and reliable data about local economic livelihoods in
developing countries is expensive, and data are consequently scarce. Previous
work has shown that it is possible to measure local-level economic livelihoods
using high-resolution satellite imagery. However, such imagery is relatively
expensive to acquire, often not updated frequently, and is mainly available for
recent years. We train CNN models on free and publicly available multispectral
daytime satellite images of the African continent from the Landsat 7 satellite,
which has collected imagery with global coverage for almost two decades. We
show that despite these images' lower resolution, we can achieve accuracies
that exceed previous benchmarks.
</summary>
    <author>
      <name>Anthony Perez</name>
    </author>
    <author>
      <name>Christopher Yeh</name>
    </author>
    <author>
      <name>George Azzari</name>
    </author>
    <author>
      <name>Marshall Burke</name>
    </author>
    <author>
      <name>David Lobell</name>
    </author>
    <author>
      <name>Stefano Ermon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at NIPS 2017 Workshop on Machine Learning for the
  Developing World</arxiv:comment>
    <link href="http://arxiv.org/abs/1711.03654v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.03654v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.00571v1</id>
    <updated>2019-06-03T04:41:48Z</updated>
    <published>2019-06-03T04:41:48Z</published>
    <title>Deep Reinforcement Learning Architecture for Continuous Power Allocation
  in High Throughput Satellites</title>
    <summary>  In the coming years, the satellite broadband market will experience
significant increases in the service demand, especially for the mobility
sector, where demand is burstier. Many of the next generation of satellites
will be equipped with numerous degrees of freedom in power and bandwidth
allocation capabilities, making manual resource allocation impractical and
inefficient. Therefore, it is desirable to automate the operation of these
highly flexible satellites. This paper presents a novel power allocation
approach based on Deep Reinforcement Learning (DRL) that represents the problem
as continuous state and action spaces. We make use of the Proximal Policy
Optimization (PPO) algorithm to optimize the allocation policy for minimum
Unmet System Demand (USD) and power consumption. The performance of the
algorithm is analyzed through simulations of a multibeam satellite system,
which show promising results for DRL to be used as a dynamic resource
allocation algorithm.
</summary>
    <author>
      <name>Juan Jose Garau Luis</name>
    </author>
    <author>
      <name>Markus Guerster</name>
    </author>
    <author>
      <name>Inigo del Portillo</name>
    </author>
    <author>
      <name>Edward Crawley</name>
    </author>
    <author>
      <name>Bruce Cameron</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.13140/RG.2.2.15014.98882</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.13140/RG.2.2.15014.98882" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures, workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.00571v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00571v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.04329v1</id>
    <updated>2019-04-08T19:54:27Z</updated>
    <published>2019-04-08T19:54:27Z</published>
    <title>Automated Monitoring Cropland Using Remote Sensing Data: Challenges and
  Opportunities for Machine Learning</title>
    <summary>  This paper provides an overview of how recent advances in machine learning
and the availability of data from earth observing satellites can dramatically
improve our ability to automatically map croplands over long period and over
large regions. It discusses three applications in the domain of crop monitoring
where ML approaches are beginning to show great promise. For each application,
it highlights machine learning challenges, proposed approaches, and recent
results. The paper concludes with discussion of major challenges that need to
be addressed before ML approaches will reach their full potential for this
problem of great societal relevance.
</summary>
    <author>
      <name>Xiaowei Jia</name>
    </author>
    <author>
      <name>Ankush Khandelwal</name>
    </author>
    <author>
      <name>Vipin Kumar</name>
    </author>
    <link href="http://arxiv.org/abs/1904.04329v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.04329v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.11893v1</id>
    <updated>2019-05-28T15:40:18Z</updated>
    <published>2019-05-28T15:40:18Z</published>
    <title>BreizhCrops: A Satellite Time Series Dataset for Crop Type
  Identification</title>
    <summary>  This dataset challenges the time series community with the task of
satellite-based vegetation identification on large scale real-world dataset of
satellite data acquired during one entire year. It consists of time series data
with associated crop types from 580k field parcels in Brittany, France (Breizh
in local language). Along with this dataset, we provide results and code of a
Long Short-Term Memory network and Transformer network as baselines. We release
dataset, along with preprocessing scripts and baseline models in
https://github.com/TUM-LMF/BreizhCrops and encourage methodical researchers to
benchmark and develop novel methods applied to satellite-based crop monitoring.
</summary>
    <author>
      <name>Marc Rußwurm</name>
    </author>
    <author>
      <name>Sébastien Lefèvre</name>
    </author>
    <author>
      <name>Marco Körner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to the Time Series Workshop of the 36th International
  Conference on Machine Learning (ICML), Long Beach, California</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.11893v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.11893v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.03602v1</id>
    <updated>2015-09-11T18:32:51Z</updated>
    <published>2015-09-11T18:32:51Z</published>
    <title>DeepSat - A Learning framework for Satellite Imagery</title>
    <summary>  Satellite image classification is a challenging problem that lies at the
crossroads of remote sensing, computer vision, and machine learning. Due to the
high variability inherent in satellite data, most of the current object
classification approaches are not suitable for handling satellite datasets. The
progress of satellite image analytics has also been inhibited by the lack of a
single labeled high-resolution dataset with multiple class labels. The
contributions of this paper are twofold - (1) first, we present two new
satellite datasets called SAT-4 and SAT-6, and (2) then, we propose a
classification framework that extracts features from an input image, normalizes
them and feeds the normalized feature vectors to a Deep Belief Network for
classification. On the SAT-4 dataset, our best network produces a
classification accuracy of 97.95% and outperforms three state-of-the-art object
recognition algorithms, namely - Deep Belief Networks, Convolutional Neural
Networks and Stacked Denoising Autoencoders by ~11%. On SAT-6, it produces a
classification accuracy of 93.9% and outperforms the other algorithms by ~15%.
Comparative studies with a Random Forest classifier show the advantage of an
unsupervised learning approach over traditional supervised learning techniques.
A statistical analysis based on Distribution Separability Criterion and
Intrinsic Dimensionality Estimation substantiates the effectiveness of our
approach in learning better representations for satellite imagery.
</summary>
    <author>
      <name>Saikat Basu</name>
    </author>
    <author>
      <name>Sangram Ganguly</name>
    </author>
    <author>
      <name>Supratik Mukhopadhyay</name>
    </author>
    <author>
      <name>Robert DiBiano</name>
    </author>
    <author>
      <name>Manohar Karki</name>
    </author>
    <author>
      <name>Ramakrishna Nemani</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper was accepted at ACM SIGSPATIAL 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.03602v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.03602v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.08701v2</id>
    <updated>2019-02-10T07:31:43Z</updated>
    <published>2018-02-23T19:11:25Z</published>
    <title>Machine learning based hyperspectral image analysis: A survey</title>
    <summary>  Hyperspectral sensors enable the study of the chemical properties of scene
materials remotely for the purpose of identification, detection, and chemical
composition analysis of objects in the environment. Hence, hyperspectral images
captured from earth observing satellites and aircraft have been increasingly
important in agriculture, environmental monitoring, urban planning, mining, and
defense. Machine learning algorithms due to their outstanding predictive power
have become a key tool for modern hyperspectral image analysis. Therefore, a
solid understanding of machine learning techniques have become essential for
remote sensing researchers and practitioners. This paper reviews and compares
recent machine learning-based hyperspectral image analysis methods published in
literature. We organize the methods by the image analysis task and by the type
of machine learning algorithm, and present a two-way mapping between the image
analysis tasks and the types of machine learning algorithms that can be applied
to them. The paper is comprehensive in coverage of both hyperspectral image
analysis tasks and machine learning algorithms. The image analysis tasks
considered are land cover classification, target detection, unmixing, and
physical parameter estimation. The machine learning algorithms covered are
Gaussian models, linear regression, logistic regression, support vector
machines, Gaussian mixture model, latent linear models, sparse linear models,
Gaussian mixture models, ensemble learning, directed graphical models,
undirected graphical models, clustering, Gaussian processes, Dirichlet
processes, and deep learning. We also discuss the open challenges in the field
of hyperspectral image analysis and explore possible future directions.
</summary>
    <author>
      <name>Utsav B. Gewali</name>
    </author>
    <author>
      <name>Sildomar T. Monteiro</name>
    </author>
    <author>
      <name>Eli Saber</name>
    </author>
    <link href="http://arxiv.org/abs/1802.08701v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.08701v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.10130v1</id>
    <updated>2019-04-23T03:05:31Z</updated>
    <published>2019-04-23T03:05:31Z</published>
    <title>Spatio-temporal crop classification of low-resolution satellite imagery
  with capsule layers and distributed attention</title>
    <summary>  Land use classification of low resolution spatial imagery is one of the most
extensively researched fields in remote sensing. Despite significant
advancements in satellite technology, high resolution imagery lacks global
coverage and can be prohibitively expensive to procure for extended time
periods. Accurately classifying land use change without high resolution imagery
offers the potential to monitor vital aspects of global development agenda
including climate smart agriculture, drought resistant crops, and sustainable
land management. Utilizing a combination of capsule layers and long-short term
memory layers with distributed attention, the present paper achieves
state-of-the-art accuracy on temporal crop type classification at a 30x30m
resolution with Sentinel 2 imagery.
</summary>
    <author>
      <name>John Brandt</name>
    </author>
    <link href="http://arxiv.org/abs/1904.10130v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.10130v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.01133v1</id>
    <updated>2017-04-04T18:03:55Z</updated>
    <published>2017-04-04T18:03:55Z</published>
    <title>Satellite Image-based Localization via Learned Embeddings</title>
    <summary>  We propose a vision-based method that localizes a ground vehicle using
publicly available satellite imagery as the only prior knowledge of the
environment. Our approach takes as input a sequence of ground-level images
acquired by the vehicle as it navigates, and outputs an estimate of the
vehicle's pose relative to a georeferenced satellite image. We overcome the
significant viewpoint and appearance variations between the images through a
neural multi-view model that learns location-discriminative embeddings in which
ground-level images are matched with their corresponding satellite view of the
scene. We use this learned function as an observation model in a filtering
framework to maintain a distribution over the vehicle's pose. We evaluate our
method on different benchmark datasets and demonstrate its ability localize
ground-level images in environments novel relative to training, despite the
challenges of significant viewpoint and appearance variations.
</summary>
    <author>
      <name>Dong-Ki Kim</name>
    </author>
    <author>
      <name>Matthew R. Walter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published in IEEE International Conference on Robotics and
  Automation (ICRA), 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.01133v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.01133v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.03697v1</id>
    <updated>2019-06-05T11:03:17Z</updated>
    <published>2019-06-05T11:03:17Z</published>
    <title>Prediction of Soil Moisture Content Based On Satellite Data and
  Sequence-to-Sequence Networks</title>
    <summary>  The main objective of this study is to combine remote sensing and machine
learning to detect soil moisture content. Growing population and food
consumption has led to the need to improve agricultural yield and to reduce
wastage of natural resources. In this paper, we propose a neural network
architecture, based on recent work by the research community, that can make a
strong social impact and aid United Nations Sustainable Development Goal of
Zero Hunger. The main aims here are to: improve efficiency of water usage;
reduce dependence on irrigation; increase overall crop yield; minimise risk of
crop loss due to drought and extreme weather conditions. We achieve this by
applying satellite imagery, crop segmentation, soil classification and NDVI and
soil moisture prediction on satellite data, ground truth and climate data
records. By applying machine learning to sensor data and ground data, farm
management systems can evolve into a real time AI enabled platform that can
provide actionable recommendations and decision support tools to the farmers.
</summary>
    <author>
      <name>Natalia Efremova</name>
    </author>
    <author>
      <name>Dmitry Zausaev</name>
    </author>
    <author>
      <name>Gleb Antipov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented on NeurIPS 2018 WiML workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.03697v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.03697v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.09302v2</id>
    <updated>2017-07-05T12:58:35Z</updated>
    <published>2017-06-28T14:06:24Z</published>
    <title>Deep Learning Based Large-Scale Automatic Satellite Crosswalk
  Classification</title>
    <summary>  High-resolution satellite imagery have been increasingly used on remote
sensing classification problems. One of the main factors is the availability of
this kind of data. Even though, very little effort has been placed on the zebra
crossing classification problem. In this letter, crowdsourcing systems are
exploited in order to enable the automatic acquisition and annotation of a
large-scale satellite imagery database for crosswalks related tasks. Then, this
dataset is used to train deep-learning-based models in order to accurately
classify satellite images that contains or not zebra crossings. A novel dataset
with more than 240,000 images from 3 continents, 9 countries and more than 20
cities was used in the experiments. Experimental results showed that freely
available crowdsourcing data can be used to accurately (97.11%) train robust
models to perform crosswalk classification on a global scale.
</summary>
    <author>
      <name>Rodrigo F. Berriel</name>
    </author>
    <author>
      <name>Andre Teixeira Lopes</name>
    </author>
    <author>
      <name>Alberto F. de Souza</name>
    </author>
    <author>
      <name>Thiago Oliveira-Santos</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/LGRS.2017.2719863</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/LGRS.2017.2719863" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures, accepted by IEEE Geoscience and Remote Sensing
  Letters</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.09302v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.09302v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.05912v2</id>
    <updated>2018-02-06T08:57:21Z</updated>
    <published>2017-09-18T13:26:25Z</published>
    <title>Estimating regional ground-level PM2.5 directly from satellite
  top-of-atmosphere reflectance using deep learning</title>
    <summary>  Almost all remote sensing atmospheric PM2.5 estimation methods need satellite
aerosol optical depth (AOD) products, which are often retrieved from
top-of-atmosphere (TOA) reflectance via an atmospheric radiative transfer
model. Then, is it possible to estimate ground-level PM2.5 directly from
satellite TOA reflectance without a physical model? In this study, this
challenging work are achieved based on a machine learning model. Specifically,
we establish the relationship between PM2.5, satellite TOA reflectance,
observation angles, and meteorological factors in a deep learning architecture
(denoted as Ref-PM modeling). Taking the Wuhan Urban Agglomeration (WUA) as a
case study, the results demonstrate that compared with the AOD-PM modeling, the
Ref-PM modeling obtains a competitive performance, with out-of-sample
cross-validated R2 and RMSE values of 0.87 and 9.89 ug/m3 respectively. Also,
the TOA-reflectance-derived PM2.5 have a finer resolution and larger spatial
coverage than the AOD-derived PM2.5. This work updates the traditional
cognition of remote sensing PM2.5 estimation and has the potential to promote
the application in atmospheric environmental monitoring.
</summary>
    <author>
      <name>Huanfeng Shen</name>
    </author>
    <author>
      <name>Tongwen Li</name>
    </author>
    <author>
      <name>Qiangqiang Yuan</name>
    </author>
    <author>
      <name>Liangpei Zhang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1029/2018JD028759</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1029/2018JD028759" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper is under review</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of geophysical research: Atmosphere (2018)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1709.05912v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.05912v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.05433v2</id>
    <updated>2019-04-25T19:47:36Z</updated>
    <published>2019-02-13T02:22:12Z</published>
    <title>Predicting Food Security Outcomes Using Convolutional Neural Networks
  (CNNs) for Satellite Tasking</title>
    <summary>  Obtaining reliable data describing local Food Security Metrics (FSM) at a
granularity that is informative to policy-makers requires expensive and
logistically difficult surveys, particularly in the developing world. We train
a CNN on publicly available satellite data describing land cover classification
and use both transfer learning and direct training to build a model for FSM
prediction purely from satellite imagery data. We then propose efficient
tasking algorithms for high resolution satellite assets via transfer learning,
Markovian search algorithms, and Bayesian networks.
</summary>
    <author>
      <name>Swetava Ganguli</name>
    </author>
    <author>
      <name>Jared Dunnmon</name>
    </author>
    <author>
      <name>Darren Hau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Research performed as part of the Sustainability and Artificial
  Intelligence Laboratory (SAIL) at Stanford University. Second revised version
  corrects typographical errors and adds a few references</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.05433v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.05433v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.02506v2</id>
    <updated>2019-05-11T08:02:01Z</updated>
    <published>2019-05-07T12:47:39Z</published>
    <title>Learning to Interpret Satellite Images in Global Scale Using Wikipedia</title>
    <summary>  Despite recent progress in computer vision, finegrained interpretation of
satellite images remains challenging because of a lack of labeled training
data. To overcome this limitation, we construct a novel dataset called
WikiSatNet by pairing georeferenced Wikipedia articles with satellite imagery
of their corresponding locations. We then propose two strategies to learn
representations of satellite images by predicting properties of the
corresponding articles from the images. Leveraging this new multi-modal
dataset, we can drastically reduce the quantity of human-annotated labels and
time required for downstream tasks. On the recently released fMoW dataset, our
pre-training strategies can boost the performance of a model pre-trained on
ImageNet by up to 4:5% in F1 score.
</summary>
    <author>
      <name>Burak Uzkent</name>
    </author>
    <author>
      <name>Evan Sheehan</name>
    </author>
    <author>
      <name>Chenlin Meng</name>
    </author>
    <author>
      <name>Zhongyi Tang</name>
    </author>
    <author>
      <name>Marshall Burke</name>
    </author>
    <author>
      <name>David Lobell</name>
    </author>
    <author>
      <name>Stefano Ermon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to IJCAI 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.02506v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.02506v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.04881v1</id>
    <updated>2018-02-13T22:28:58Z</updated>
    <published>2018-02-13T22:28:58Z</published>
    <title>Satellite Image Forgery Detection and Localization Using GAN and
  One-Class Classifier</title>
    <summary>  Current satellite imaging technology enables shooting high-resolution
pictures of the ground. As any other kind of digital images, overhead pictures
can also be easily forged. However, common image forensic techniques are often
developed for consumer camera images, which strongly differ in their nature
from satellite ones (e.g., compression schemes, post-processing, sensors,
etc.). Therefore, many accurate state-of-the-art forensic algorithms are bound
to fail if blindly applied to overhead image analysis. Development of novel
forensic tools for satellite images is paramount to assess their authenticity
and integrity. In this paper, we propose an algorithm for satellite image
forgery detection and localization. Specifically, we consider the scenario in
which pixels within a region of a satellite image are replaced to add or remove
an object from the scene. Our algorithm works under the assumption that no
forged images are available for training. Using a generative adversarial
network (GAN), we learn a feature representation of pristine satellite images.
A one-class support vector machine (SVM) is trained on these features to
determine their distribution. Finally, image forgeries are detected as
anomalies. The proposed algorithm is validated against different kinds of
satellite images containing forgeries of different size and shape.
</summary>
    <author>
      <name>Sri Kalyan Yarlagadda</name>
    </author>
    <author>
      <name>David Güera</name>
    </author>
    <author>
      <name>Paolo Bestagini</name>
    </author>
    <author>
      <name>Fengqing Maggie Zhu</name>
    </author>
    <author>
      <name>Stefano Tubaro</name>
    </author>
    <author>
      <name>Edward J. Delp</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the IS&amp;T International Symposium on Electronic Imaging
  (EI)</arxiv:comment>
    <link href="http://arxiv.org/abs/1802.04881v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.04881v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.08863v1</id>
    <updated>2019-03-21T07:55:11Z</updated>
    <published>2019-03-21T07:55:11Z</published>
    <title>Learning Disentangled Representations of Satellite Image Time Series</title>
    <summary>  In this paper, we investigate how to learn a suitable representation of
satellite image time series in an unsupervised manner by leveraging large
amounts of unlabeled data. Additionally , we aim to disentangle the
representation of time series into two representations: a shared representation
that captures the common information between the images of a time series and an
exclusive representation that contains the specific information of each image
of the time series. To address these issues, we propose a model that combines a
novel component called cross-domain autoencoders with the variational
autoencoder (VAE) and generative ad-versarial network (GAN) methods. In order
to learn disentangled representations of time series, our model learns the
multimodal image-to-image translation task. We train our model using satellite
image time series from the Sentinel-2 mission. Several experiments are carried
out to evaluate the obtained representations. We show that these disentangled
representations can be very useful to perform multiple tasks such as image
classification, image retrieval, image segmentation and change detection.
</summary>
    <author>
      <name>Eduardo Sanchez</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRIT</arxiv:affiliation>
    </author>
    <author>
      <name>Mathieu Serrurier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRIT</arxiv:affiliation>
    </author>
    <author>
      <name>Mathias Ortner</name>
    </author>
    <link href="http://arxiv.org/abs/1903.08863v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.08863v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.00812v1</id>
    <updated>2018-11-30T10:38:37Z</updated>
    <published>2018-11-30T10:38:37Z</published>
    <title>Mapping Informal Settlements in Developing Countries with
  Multi-resolution, Multi-spectral Data</title>
    <summary>  Detecting and mapping informal settlements encompasses several of the United
Nations sustainable development goals. This is because informal settlements are
home to the most socially and economically vulnerable people on the planet.
Thus, understanding where these settlements are is of paramount importance to
both government and non-government organizations (NGOs), such as the United
Nations Children's Fund (UNICEF), who can use this information to deliver
effective social and economic aid. We propose two effective methods for
detecting and mapping the locations of informal settlements. One uses only
low-resolution (LR), freely available, Sentinel-2 multispectral satellite
imagery with noisy annotations, whilst the other is a deep learning approach
that uses only costly very-high-resolution (VHR) satellite imagery. To our
knowledge, we are the first to map informal settlements successfully with
low-resolution satellite imagery. We extensively evaluate and compare the
proposed methods. Please find additional material at
https://frontierdevelopmentlab.github.io/informal-settlements/.
</summary>
    <author>
      <name>Patrick Helber</name>
    </author>
    <author>
      <name>Bradley Gram-Hansen</name>
    </author>
    <author>
      <name>Indhu Varatharajan</name>
    </author>
    <author>
      <name>Faiza Azam</name>
    </author>
    <author>
      <name>Alejandro Coca-Castro</name>
    </author>
    <author>
      <name>Veronika Kopackova</name>
    </author>
    <author>
      <name>Piotr Bilinski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1812.00786</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.00812v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.00812v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.03383v1</id>
    <updated>2017-07-11T17:44:20Z</updated>
    <published>2017-07-11T17:44:20Z</published>
    <title>A step towards procedural terrain generation with GANs</title>
    <summary>  Procedural terrain generation for video games has been traditionally been
done with smartly designed but handcrafted algorithms that generate heightmaps.
We propose a first step toward the learning and synthesis of these using recent
advances in deep generative modelling with openly available satellite imagery
from NASA.
</summary>
    <author>
      <name>Christopher Beckham</name>
    </author>
    <author>
      <name>Christopher Pal</name>
    </author>
    <link href="http://arxiv.org/abs/1707.03383v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.03383v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.01699v2</id>
    <updated>2018-12-06T02:38:23Z</updated>
    <published>2018-12-01T01:43:26Z</published>
    <title>Assigning a Grade: Accurate Measurement of Road Quality Using Satellite
  Imagery</title>
    <summary>  Roads are critically important infrastructure to societal and economic
development, with huge investments made by governments every year. However,
methods for monitoring those investments tend to be time-consuming, laborious,
and expensive, placing them out of reach for many developing regions. In this
work, we develop a model for monitoring the quality of road infrastructure
using satellite imagery. For this task, we harness two trends: the increasing
availability of high-resolution, often-updated satellite imagery, and the
enormous improvement in speed and accuracy of convolutional neural
network-based methods for performing computer vision tasks. We employ a unique
dataset of road quality information on 7000km of roads in Kenya combined with
50cm resolution satellite imagery. We create models for a binary classification
task as well as a comprehensive 5-category classification task, with accuracy
scores of 88 and 73 percent respectively. We also provide evidence of the
robustness of our methods with challenging held-out scenarios, though we note
some improvement is still required for confident analysis of a never before
seen road. We believe these results are well-positioned to have substantial
impact on a broad set of transport applications.
</summary>
    <author>
      <name>Gabriel Cadamuro</name>
    </author>
    <author>
      <name>Aggrey Muhebwa</name>
    </author>
    <author>
      <name>Jay Taneja</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at NIPS 2018 Workshop on Machine Learning for the
  Developing World</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.01699v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.01699v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.02996v1</id>
    <updated>2018-08-09T02:12:43Z</updated>
    <published>2018-08-09T02:12:43Z</published>
    <title>Object Detection in Satellite Imagery using 2-Step Convolutional Neural
  Networks</title>
    <summary>  This paper presents an efficient object detection method from satellite
imagery. Among a number of machine learning algorithms, we proposed a
combination of two convolutional neural networks (CNN) aimed at high precision
and high recall, respectively. We validated our models using golf courses as
target objects. The proposed deep learning method demonstrated higher accuracy
than previous object identification methods.
</summary>
    <author>
      <name>Hiroki Miyamoto</name>
    </author>
    <author>
      <name>Kazuki Uehara</name>
    </author>
    <author>
      <name>Masahiro Murakawa</name>
    </author>
    <author>
      <name>Hidenori Sakanashi</name>
    </author>
    <author>
      <name>Hirokazu Nosato</name>
    </author>
    <author>
      <name>Toru Kouyama</name>
    </author>
    <author>
      <name>Ryosuke Nakamura</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages,5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1808.02996v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.02996v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.00786v2</id>
    <updated>2019-05-30T12:19:50Z</updated>
    <published>2018-11-30T09:09:41Z</published>
    <title>Generating Material Maps to Map Informal Settlements</title>
    <summary>  Detecting and mapping informal settlements encompasses several of the United
Nations sustainable development goals. This is because informal settlements are
home to the most socially and economically vulnerable people on the planet.
Thus, understanding where these settlements are is of paramount importance to
both government and non-government organizations (NGOs), such as the United
Nations Children's Fund (UNICEF), who can use this information to deliver
effective social and economic aid. We propose a method that detects and maps
the locations of informal settlements using only freely available, Sentinel-2
low-resolution satellite spectral data and socio-economic data. This is in
contrast to previous studies that only use costly very-high resolution (VHR)
satellite and aerial imagery. We show how we can detect informal settlements by
combining both domain knowledge and machine learning techniques, to build a
classifier that looks for known roofing materials used in informal settlements.
Please find additional material at
https://frontierdevelopmentlab.github.io/informal-settlements/.
</summary>
    <author>
      <name>Patrick Helber</name>
    </author>
    <author>
      <name>Bradley Gram-Hansen</name>
    </author>
    <author>
      <name>Indhu Varatharajan</name>
    </author>
    <author>
      <name>Faiza Azam</name>
    </author>
    <author>
      <name>Alejandro Coca-Castro</name>
    </author>
    <author>
      <name>Veronika Kopackova</name>
    </author>
    <author>
      <name>Piotr Bilinski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appeared at the 32nd Conference on Neural Information Processing
  Systems (NeurlPS 2018) Machine Learning for the Developing World (ML4DW)
  Workshop</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">NeurlPS workshop on Machine Learning for the Developing World
  (ML4DW), 2018</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1812.00786v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.00786v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.6137v1</id>
    <updated>2014-02-05T20:05:34Z</updated>
    <published>2014-02-05T20:05:34Z</published>
    <title>An enhanced neural network based approach towards object extraction</title>
    <summary>  The improvements in spectral and spatial resolution of the satellite images
have facilitated the automatic extraction and identification of the features
from satellite images and aerial photographs. An automatic object extraction
method is presented for extracting and identifying the various objects from
satellite images and the accuracy of the system is verified with regard to IRS
satellite images. The system is based on neural network and simulates the
process of visual interpretation from remote sensing images and hence increases
the efficiency of image analysis. This approach obtains the basic
characteristics of the various features and the performance is enhanced by the
automatic learning approach, intelligent interpretation, and intelligent
interpolation. The major advantage of the method is its simplicity and that the
system identifies the features not only based on pixel value but also based on
the shape, haralick features etc of the objects. Further the system allows
flexibility for identifying the features within the same category based on size
and shape. The successful application of the system verified its effectiveness
and the accuracy of the system were assessed by ground truth verification.
</summary>
    <author>
      <name>S. K. Katiyar</name>
    </author>
    <author>
      <name>P. V. Arun</name>
    </author>
    <link href="http://arxiv.org/abs/1405.6137v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.6137v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.1009v1</id>
    <updated>2009-12-05T12:54:24Z</updated>
    <published>2009-12-05T12:54:24Z</published>
    <title>Biogeography based Satellite Image Classification</title>
    <summary>  Biogeography is the study of the geographical distribution of biological
organisms. The mindset of the engineer is that we can learn from nature.
Biogeography Based Optimization is a burgeoning nature inspired technique to
find the optimal solution of the problem. Satellite image classification is an
important task because it is the only way we can know about the land cover map
of inaccessible areas. Though satellite images have been classified in past by
using various techniques, the researchers are always finding alternative
strategies for satellite image classification so that they may be prepared to
select the most appropriate technique for the feature extraction task in hand.
This paper is focused on classification of the satellite image of a particular
land cover using the theory of Biogeography based Optimization. The original
BBO algorithm does not have the inbuilt property of clustering which is
required during image classification. Hence modifications have been proposed to
the original algorithm and the modified algorithm is used to classify the
satellite image of a given region. The results indicate that highly accurate
land cover features can be extracted effectively when the proposed algorithm is
used.
</summary>
    <author>
      <name>V. K. Panchal</name>
    </author>
    <author>
      <name>Parminder Singh</name>
    </author>
    <author>
      <name>Navdeep Kaur</name>
    </author>
    <author>
      <name>Harish Kundra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 269-274, November 2009, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0912.1009v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.1009v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.12563v1</id>
    <updated>2019-05-29T16:14:52Z</updated>
    <published>2019-05-29T16:14:52Z</published>
    <title>Application of Different Simulated Spectral Data and Machine Learning to
  Estimate the Chlorophyll $a$ Concentration of Several Inland Waters</title>
    <summary>  Water quality is of great importance for humans and for the environment and
has to be monitored continuously. It is determinable through proxies such as
the chlorophyll $a$ concentration, which can be monitored by remote sensing
techniques. This study focuses on the trade-off between the spatial and the
spectral resolution of six simulated satellite-based data sets when estimating
the chlorophyll $a$ concentration with supervised machine learning models. The
initial dataset for the spectral simulation of the satellite missions contains
spectrometer data and measured chlorophyll $a$ concentration of 13 different
inland waters. Focusing on the regression performance, it appears that the
machine learning models achieve almost as good results with the simulated
Sentinel data as with the simulated hyperspectral data. Regarding the
applicability, the Sentinel 2 mission is the best choice for small inland
waters due to its high spatial and temporal resolution in combination with a
suitable spectral resolution.
</summary>
    <author>
      <name>Philipp M. Maier</name>
    </author>
    <author>
      <name>Sina Keller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This contribution was submitted to the IEEE Whispers 2019 in
  Amsterdam</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.12563v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.12563v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.00144v1</id>
    <updated>2018-06-01T00:10:04Z</updated>
    <published>2018-06-01T00:10:04Z</published>
    <title>Sea surface temperature prediction and reconstruction using patch-level
  neural network representations</title>
    <summary>  The forecasting and reconstruction of ocean and atmosphere dynamics from
satellite observation time series are key challenges. While model-driven
representations remain the classic approaches, data-driven representations
become more and more appealing to benefit from available large-scale
observation and simulation datasets. In this work we investigate the relevance
of recently introduced bilinear residual neural network representations, which
mimic numerical integration schemes such as Runge-Kutta, for the forecasting
and assimilation of geophysical fields from satellite-derived remote sensing
data. As a case-study, we consider satellite-derived Sea Surface Temperature
time series off South Africa, which involves intense and complex upper ocean
dynamics. Our numerical experiments demonstrate that the proposed patch-level
neural-network-based representations outperform other data-driven models,
including analog schemes, both in terms of forecasting and missing data
interpolation performance with a relative gain up to 50\% for highly dynamic
areas.
</summary>
    <author>
      <name>Said Ouala</name>
    </author>
    <author>
      <name>Cedric Herzet</name>
    </author>
    <author>
      <name>Ronan Fablet</name>
    </author>
    <link href="http://arxiv.org/abs/1806.00144v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.00144v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1811.07896v1</id>
    <updated>2018-11-19T15:45:06Z</updated>
    <published>2018-11-19T15:45:06Z</published>
    <title>Slum Segmentation and Change Detection : A Deep Learning Approach</title>
    <summary>  More than one billion people live in slums around the world. In some
developing countries, slum residents make up for more than half of the
population and lack reliable sanitation services, clean water, electricity,
other basic services. Thus, slum rehabilitation and improvement is an important
global challenge, and a significant amount of effort and resources have been
put into this endeavor. These initiatives rely heavily on slum mapping and
monitoring, and it is essential to have robust and efficient methods for
mapping and monitoring existing slum settlements. In this work, we introduce an
approach to segment and map individual slums from satellite imagery, leveraging
regional convolutional neural networks for instance segmentation using transfer
learning. In addition, we also introduce a method to perform change detection
and monitor slum change over time. We show that our approach effectively learns
slum shape and appearance, and demonstrates strong quantitative results,
resulting in a maximum AP of 80.0.
</summary>
    <author>
      <name>Shishira R Maiya</name>
    </author>
    <author>
      <name>Sudharshan Chandra Babu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at NIPS 2018 Workshop on Machine Learning for the
  Developing World</arxiv:comment>
    <link href="http://arxiv.org/abs/1811.07896v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1811.07896v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.11019v2</id>
    <updated>2019-05-30T13:03:30Z</updated>
    <published>2018-06-28T14:56:39Z</published>
    <title>Integration of LiDAR and multispectral images for exposure and
  earthquake vulnerability estimation. Application in Lorca, Spain</title>
    <summary>  We present a procedure for assessing the urban exposure and seismic
vulnerability that integrates LiDAR data with aerial and satellite images. It
comprises three phases: first, we segment the satellite image to divide the
study area into different urban patterns. Second, we extract building
footprints and attributes that represent the type of building of each urban
pattern. Finally, we assign the seismic vulnerability to each building using
different machine-learning techniques: Decision trees, SVM, logistic regression
and Bayesian networks. We apply the procedure to 826 buildings in the city of
Lorca (SE Spain), where we count on a vulnerability database that we use as
ground truth for the validation of results. The outcomes show that the machine
learning techniques have similar performance, yielding vulnerability
classification results with an accuracy of 77% - 80% (F1-Score). The procedure
is scalable and can be replicated in different areas. It is especially
interesting as a complement to conventional data gathering approaches for
disaster risk applications in areas where field surveys need to be restricted
to certain areas, dates or budget. Keywords LiDAR, satellite image, orthophoto,
image segmentation, machine learning, earthquake vulnerability.
</summary>
    <author>
      <name>Yolanda Torres</name>
    </author>
    <author>
      <name>Jose Juan Arranz</name>
    </author>
    <author>
      <name>Jorge M. Gaspar-Escribano</name>
    </author>
    <author>
      <name>Azadeh Haghi</name>
    </author>
    <author>
      <name>Sandra Martinez-Cuevas</name>
    </author>
    <author>
      <name>Belen Benito</name>
    </author>
    <author>
      <name>Juan Carlos Ojeda</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jag.2019.05.015</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jag.2019.05.015" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">I.J. of Applied Earth Observation and Geoinformation, 81, 161-175
  (2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1806.11019v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.11019v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1803.00397v1</id>
    <updated>2018-02-19T08:04:25Z</updated>
    <published>2018-02-19T08:04:25Z</published>
    <title>Satellite imagery analysis for operational damage assessment in
  Emergency situations</title>
    <summary>  When major disaster occurs the questions are raised how to estimate the
damage in time to support the decision making process and relief efforts by
local authorities or humanitarian teams. In this paper we consider the use of
Machine Learning and Computer Vision on remote sensing imagery to improve time
efficiency of assessment of damaged buildings in disaster affected area. We
propose a general workflow that can be useful in various disaster management
applications, and demonstrate the use of the proposed workflow for the
assessment of the damage caused by the wildfires in California in 2017.
</summary>
    <author>
      <name>Alexey Trekin</name>
    </author>
    <author>
      <name>German Novikov</name>
    </author>
    <author>
      <name>Georgy Potapov</name>
    </author>
    <author>
      <name>Vladimir Ignatiev</name>
    </author>
    <author>
      <name>Evgeny Burnaev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1803.00397v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1803.00397v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.07376v2</id>
    <updated>2019-01-19T23:46:05Z</updated>
    <published>2018-05-18T18:20:52Z</published>
    <title>Algorithms for Estimating Trends in Global Temperature Volatility</title>
    <summary>  Trends in terrestrial temperature variability are perhaps more relevant for
species viability than trends in mean temperature. In this paper, we develop
methodology for estimating such trends using multi-resolution climate data from
polar orbiting weather satellites. We derive two novel algorithms for
computation that are tailored for dense, gridded observations over both space
and time. We evaluate our methods with a simulation that mimics these data's
features and on a large, publicly available, global temperature dataset with
the eventual goal of tracking trends in cloud reflectance temperature
variability.
</summary>
    <author>
      <name>Arash Khodadadi</name>
    </author>
    <author>
      <name>Daniel J McDonald</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in AAAI-19</arxiv:comment>
    <link href="http://arxiv.org/abs/1805.07376v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.07376v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.05359v2</id>
    <updated>2016-11-21T18:43:29Z</updated>
    <published>2016-10-17T21:12:01Z</published>
    <title>A Machine Learns to Predict the Stability of Tightly Packed Planetary
  Systems</title>
    <summary>  The requirement that planetary systems be dynamically stable is often used to
vet new discoveries or set limits on unconstrained masses or orbital elements.
This is typically carried out via computationally expensive N-body simulations.
We show that characterizing the complicated and multi-dimensional stability
boundary of tightly packed systems is amenable to machine learning methods. We
find that training an XGBoost machine learning algorithm on physically
motivated features yields an accurate classifier of stability in packed
systems. On the stability timescale investigated ($10^7$ orbits), it is 3
orders of magnitude faster than direct N-body simulations. Optimized machine
learning classifiers for dynamical stability may thus prove useful across the
discipline, e.g., to characterize the exoplanet sample discovered by the
upcoming Transiting Exoplanet Survey Satellite (TESS). This proof of concept
motivates investing computational resources to train algorithms capable of
predicting stability over longer timescales and over broader regions of phase
space.
</summary>
    <author>
      <name>Daniel Tamayo</name>
    </author>
    <author>
      <name>Ari Silburt</name>
    </author>
    <author>
      <name>Diana Valencia</name>
    </author>
    <author>
      <name>Kristen Menou</name>
    </author>
    <author>
      <name>Mohamad Ali-Dib</name>
    </author>
    <author>
      <name>Cristobal Petrovich</name>
    </author>
    <author>
      <name>Chelsea X. Huang</name>
    </author>
    <author>
      <name>Hanno Rein</name>
    </author>
    <author>
      <name>Christa van Laerhoven</name>
    </author>
    <author>
      <name>Adiv Paradise</name>
    </author>
    <author>
      <name>Alysa Obertas</name>
    </author>
    <author>
      <name>Norman Murray</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3847/2041-8205/832/2/L22</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3847/2041-8205/832/2/L22" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in ApJ letters. 7 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.05359v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.05359v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.04881v1</id>
    <updated>2018-10-11T08:05:29Z</updated>
    <published>2018-10-11T08:05:29Z</published>
    <title>Monitoring spatial sustainable development: Semi-automated analysis of
  satellite and aerial images for energy transition and sustainability
  indicators</title>
    <summary>  Solar panels are installed by a large and growing number of households due to
the convenience of having cheap and renewable energy to power house appliances.
In contrast to other energy sources solar installations are distributed very
decentralized and spread over hundred-thousands of locations. On a global level
more than 25% of solar photovoltaic (PV) installations were decentralized. The
effect of the quick energy transition from a carbon based economy to a green
economy is though still very difficult to quantify. As a matter of fact the
quick adoption of solar panels by households is difficult to track, with local
registries that miss a large number of the newly built solar panels. This makes
the task of assessing the impact of renewable energies an impossible task.
Although models of the output of a region exist, they are often black box
estimations. This project's aim is twofold: First automate the process to
extract the location of solar panels from aerial or satellite images and
second, produce a map of solar panels along with statistics on the number of
solar panels. Further, this project takes place in a wider framework which
investigates how official statistics can benefit from new digital data sources.
At project completion, a method for detecting solar panels from aerial images
via machine learning will be developed and the methodology initially developed
for BE, DE and NL will be standardized for application to other EU countries.
In practice, machine learning techniques are used to identify solar panels in
satellite and aerial images for the province of Limburg (NL), Flanders (BE) and
North Rhine-Westphalia (DE).
</summary>
    <author>
      <name>R. L. Curier</name>
    </author>
    <author>
      <name>T. J. A. De Jong</name>
    </author>
    <author>
      <name>Katharina Strauch</name>
    </author>
    <author>
      <name>Katharina Cramer</name>
    </author>
    <author>
      <name>Natalie Rosenski</name>
    </author>
    <author>
      <name>Clara Schartner</name>
    </author>
    <author>
      <name>M. Debusschere</name>
    </author>
    <author>
      <name>Hannah Ziemons</name>
    </author>
    <author>
      <name>Deniz Iren</name>
    </author>
    <author>
      <name>Stefano Bromuri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This document provides the reader with an overview of the various
  datasets which will be used throughout the project. The collection of
  satellite and aerial images as well as auxiliary information such as the
  location of buildings and roofs which is required to train, test and validate
  the machine learning algorithm that is being developed</arxiv:comment>
    <link href="http://arxiv.org/abs/1810.04881v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.04881v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="00-02" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.4077v2</id>
    <updated>2013-05-31T16:57:33Z</updated>
    <published>2013-04-15T12:54:52Z</published>
    <title>A new Bayesian ensemble of trees classifier for identifying multi-class
  labels in satellite images</title>
    <summary>  Classification of satellite images is a key component of many remote sensing
applications. One of the most important products of a raw satellite image is
the classified map which labels the image pixels into meaningful classes.
Though several parametric and non-parametric classifiers have been developed
thus far, accurate labeling of the pixels still remains a challenge. In this
paper, we propose a new reliable multiclass-classifier for identifying class
labels of a satellite image in remote sensing applications. The proposed
multiclass-classifier is a generalization of a binary classifier based on the
flexible ensemble of regression trees model called Bayesian Additive Regression
Trees (BART). We used three small areas from the LANDSAT 5 TM image, acquired
on August 15, 2009 (path/row: 08/29, L1T product, UTM map projection) over
Kings County, Nova Scotia, Canada to classify the land-use. Several prediction
accuracy and uncertainty measures have been used to compare the reliability of
the proposed classifier with the state-of-the-art classifiers in remote
sensing.
</summary>
    <author>
      <name>Reshu Agarwal</name>
    </author>
    <author>
      <name>Pritam Ranjan</name>
    </author>
    <author>
      <name>Hugh Chipman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages, 6 figures, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.4077v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.4077v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.00878v1</id>
    <updated>2018-08-02T16:00:32Z</updated>
    <published>2018-08-02T16:00:32Z</published>
    <title>Supervised classification for object identification in urban areas using
  satellite imagery</title>
    <summary>  This paper presents a useful method to achieve classification in satellite
imagery. The approach is based on pixel level study employing various features
such as correlation, homogeneity, energy and contrast. In this study gray-scale
images are used for training the classification model. For supervised
classification, two classification techniques are employed namely the Support
Vector Machine (SVM) and the Naive Bayes. With textural features used for
gray-scale images, Naive Bayes performs better with an overall accuracy of 76%
compared to 68% achieved by SVM. The computational time is evaluated while
performing the experiment with two different window sizes i.e., 50x50 and
70x70. The required computational time on a single image is found to be 27
seconds for a window size of 70x70 and 45 seconds for a window size of 50x50.
</summary>
    <author>
      <name>Hazrat Ali</name>
    </author>
    <author>
      <name>Adnan Ali Awan</name>
    </author>
    <author>
      <name>Sanaullah Khan</name>
    </author>
    <author>
      <name>Omer Shafique</name>
    </author>
    <author>
      <name>Atiq ur Rahman</name>
    </author>
    <author>
      <name>Shahid Khan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICOMET.2018.8346383</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICOMET.2018.8346383" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2018 International Conference on Computing, Mathematics and
  Engineering Technologies (iCoMET)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">H. Ali et al., 2018 International Conference on Computing,
  Mathematics and Engineering Technologies (iCoMET), Sukkur, 2018, pp. 1-4</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1808.00878v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.00878v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.00861v3</id>
    <updated>2019-05-30T11:11:39Z</updated>
    <published>2019-01-03T16:51:40Z</published>
    <title>Mapping Informal Settlements in Developing Countries using Machine
  Learning and Low Resolution Multi-spectral Data</title>
    <summary>  Informal settlements are home to the most socially and economically
vulnerable people on the planet. In order to deliver effective economic and
social aid, non-government organizations (NGOs), such as the United Nations
Children's Fund (UNICEF), require detailed maps of the locations of informal
settlements. However, data regarding informal and formal settlements is
primarily unavailable and if available is often incomplete. This is due, in
part, to the cost and complexity of gathering data on a large scale. To address
these challenges, we, in this work, provide three contributions. 1) A brand new
machine learning data-set, purposely developed for informal settlement
detection. 2) We show that it is possible to detect informal settlements using
freely available low-resolution (LR) data, in contrast to previous studies that
use very-high resolution (VHR) satellite and aerial imagery, something that is
cost-prohibitive for NGOs. 3) We demonstrate two effective classification
schemes on our curated data set, one that is cost-efficient for NGOs and
another that is cost-prohibitive for NGOs, but has additional utility. We
integrate these schemes into a semi-automated pipeline that converts either a
LR or VHR satellite image into a binary map that encodes the locations of
informal settlements.
</summary>
    <author>
      <name>Bradley Gram-Hansen</name>
    </author>
    <author>
      <name>Patrick Helber</name>
    </author>
    <author>
      <name>Indhu Varatharajan</name>
    </author>
    <author>
      <name>Faiza Azam</name>
    </author>
    <author>
      <name>Alejandro Coca-Castro</name>
    </author>
    <author>
      <name>Veronika Kopackova</name>
    </author>
    <author>
      <name>Piotr Bilinski</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3306618.3314253</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3306618.3314253" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at the AAAI/ACM Conference on AI, ethics and society.
  Extended results from our previous workshop: arXiv:1812.00812</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI/ACM Conference on AI, Ethics, and Society (AIES 2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1901.00861v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.00861v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.06151v1</id>
    <updated>2019-06-10T15:22:54Z</updated>
    <published>2019-06-10T15:22:54Z</published>
    <title>Landslide Geohazard Assessment With Convolutional Neural Networks Using
  Sentinel-2 Imagery Data</title>
    <summary>  In this paper, the authors aim to combine the latest state of the art models
in image recognition with the best publicly available satellite images to
create a system for landslide risk mitigation. We focus first on landslide
detection and further propose a similar system to be used for prediction. Such
models are valuable as they could easily be scaled up to provide data for
hazard evaluation, as satellite imagery becomes increasingly available. The
goal is to use satellite images and correlated data to enrich the public
repository of data and guide disaster relief efforts for locating precise areas
where landslides have occurred. Different image augmentation methods are used
to increase diversity in the chosen dataset and create more robust
classification. The resulting outputs are then fed into variants of 3-D
convolutional neural networks. A review of the current literature indicates
there is no research using CNNs (Convolutional Neural Networks) and freely
available satellite imagery for classifying landslide risk. The model has shown
to be ultimately able to achieve a significantly better than baseline accuracy.
</summary>
    <author>
      <name>Silvia L. Ullo</name>
    </author>
    <author>
      <name>Maximillian S. Langenkamp</name>
    </author>
    <author>
      <name>Tuomas P. Oikarinen</name>
    </author>
    <author>
      <name>Maria P. Del Rosso</name>
    </author>
    <author>
      <name>Alessandro Sebastianelli</name>
    </author>
    <author>
      <name>Federica Piccirillo</name>
    </author>
    <author>
      <name>Stefania Sica</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 3 figures, 1 table, accepted to 2019 IEEE IGARSS Conference
  that will be held in Japan next July</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.06151v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.06151v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1811.07769v1</id>
    <updated>2018-11-10T07:34:04Z</updated>
    <published>2018-11-10T07:34:04Z</published>
    <title>Addressing the Invisible: Street Address Generation for Developing
  Countries with Deep Learning</title>
    <summary>  More than half of the world's roads lack adequate street addressing systems.
Lack of addresses is even more visible in daily lives of people in developing
countries. We would like to object to the assumption that having an address is
a luxury, by proposing a generative address design that maps the world in
accordance with streets. The addressing scheme is designed considering several
traditional street addressing methodologies employed in the urban development
scenarios around the world. Our algorithm applies deep learning to extract
roads from satellite images, converts the road pixel confidences into a road
network, partitions the road network to find neighborhoods, and labels the
regions, roads, and address units using graph- and proximity-based algorithms.
We present our results on a sample US city, and several developing cities,
compare travel times of users using current ad hoc and new complete addresses,
and contrast our addressing solution to current industrial and open geocoding
alternatives.
</summary>
    <author>
      <name>Ilke Demir</name>
    </author>
    <author>
      <name>Ramesh Raskar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at NIPS 2018 Workshop on Machine Learning for the
  Developing World</arxiv:comment>
    <link href="http://arxiv.org/abs/1811.07769v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1811.07769v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.00141v1</id>
    <updated>2018-12-01T04:20:21Z</updated>
    <published>2018-12-01T04:20:21Z</published>
    <title>A Dynamic Network and Representation LearningApproach for Quantifying
  Economic Growth fromSatellite Imagery</title>
    <summary>  Quantifying the improvement in human living standard, as well as the city
growth in developing countries, is a challenging problem due to the lack of
reliable economic data. Therefore, there is a fundamental need for alternate,
largely unsupervised, computational methods that can estimate the economic
conditions in the developing regions. To this end, we propose a new network
science- and representation learning-based approach that can quantify economic
indicators and visualize the growth of various regions. More precisely, we
first create a dynamic network drawn out of high-resolution nightlight
satellite images. We then demonstrate that using representation learning to
mine the resulting network, our proposed approach can accurately predict
spatial gross economic expenditures over large regions. Our method, which
requires only nightlight images and limited survey data, can capture
city-growth, as well as how people's living standard is changing; this can
ultimately facilitate the decision makers' understanding of growth without
heavily relying on expensive and time-consuming surveys.
</summary>
    <author>
      <name>Jiqian Dong</name>
    </author>
    <author>
      <name>Gopaljee Atulya</name>
    </author>
    <author>
      <name>Kartikeya Bhardwaj</name>
    </author>
    <author>
      <name>Radu Marculescu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at NIPS 2018 Workshop on Machine Learning for the
  Developing World</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.00141v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.00141v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.02052v1</id>
    <updated>2019-04-03T15:16:36Z</updated>
    <published>2019-04-03T15:16:36Z</published>
    <title>Estimating Chlorophyll a Concentrations of Several Inland Waters with
  Hyperspectral Data and Machine Learning Models</title>
    <summary>  Water is a key component of life, the natural environment and human health.
For monitoring the conditions of a water body, the chlorophyll a concentration
can serve as a proxy for nutrients and oxygen supply. In situ measurements of
water quality parameters are often time-consuming, expensive and limited in
areal validity. Therefore, we apply remote sensing techniques. During field
campaigns, we collected hyperspectral data with a spectrometer and in situ
measured chlorophyll a concentrations of 13 inland water bodies with different
spectral characteristics. One objective of this study is to estimate
chlorophyll a concentrations of these inland waters by applying three machine
learning regression models: Random Forest, Support Vector Machine and an
Artificial Neural Network. Additionally, we simulate four different
hyperspectral resolutions of the spectrometer data to investigate the effects
on the estimation performance. Furthermore, the application of first order
derivatives of the spectra is evaluated in turn to the regression performance.
This study reveals the potential of combining machine learning approaches and
remote sensing data for inland waters. Each machine learning model achieves an
R2-score between 80 % to 90 % for the regression on chlorophyll a
concentrations. The random forest model benefits clearly from the applied
derivatives of the spectra. In further studies, we will focus on the
application of machine learning models on spectral satellite data to enhance
the area-wide estimation of chlorophyll a concentration for inland waters.
</summary>
    <author>
      <name>Philipp M. Maier</name>
    </author>
    <author>
      <name>Sina Keller</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5194/isprs-annals-IV-2-W5-609-2019</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5194/isprs-annals-IV-2-W5-609-2019" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at ISPRS Geospatial Week 2019 in Enschede</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.02052v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.02052v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.00029v2</id>
    <updated>2019-02-01T09:51:18Z</updated>
    <published>2017-08-31T18:19:10Z</published>
    <title>EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and
  Land Cover Classification</title>
    <summary>  In this paper, we address the challenge of land use and land cover
classification using Sentinel-2 satellite images. The Sentinel-2 satellite
images are openly and freely accessible provided in the Earth observation
program Copernicus. We present a novel dataset based on Sentinel-2 satellite
images covering 13 spectral bands and consisting out of 10 classes with in
total 27,000 labeled and geo-referenced images. We provide benchmarks for this
novel dataset with its spectral bands using state-of-the-art deep Convolutional
Neural Network (CNNs). With the proposed novel dataset, we achieved an overall
classification accuracy of 98.57%. The resulting classification system opens a
gate towards a number of Earth observation applications. We demonstrate how
this classification system can be used for detecting land use and land cover
changes and how it can assist in improving geographical maps. The
geo-referenced dataset EuroSAT is made publicly available at
https://github.com/phelber/eurosat.
</summary>
    <author>
      <name>Patrick Helber</name>
    </author>
    <author>
      <name>Benjamin Bischke</name>
    </author>
    <author>
      <name>Andreas Dengel</name>
    </author>
    <author>
      <name>Damian Borth</name>
    </author>
    <link href="http://arxiv.org/abs/1709.00029v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.00029v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.07367v1</id>
    <updated>2018-12-09T16:32:40Z</updated>
    <published>2018-12-09T16:32:40Z</published>
    <title>Deep Learning Approach in Automatic Iceberg - Ship Detection with SAR
  Remote Sensing Data</title>
    <summary>  Deep Learning is gaining traction with geophysics community to understand
subsurface structures, such as fault detection or salt body in seismic data.
This study describes using deep learning method for iceberg or ship recognition
with synthetic aperture radar (SAR) data. Drifting icebergs pose a potential
threat to activities offshore around the Arctic, including for both ship
navigation and oil rigs. Advancement of satellite imagery using
weather-independent cross-polarized radar has enabled us to monitor and
delineate icebergs and ships, however a human component is needed to classify
the images. Here we present Transfer Learning, a convolutional neural network
(CNN) designed to work with a limited training data and features, while
demonstrating its effectiveness in this problem. Key aspect of the approach is
data augmentation and stacking of multiple outputs, resulted in a significant
boost in accuracy (logarithmic score of 0.1463). This algorithm has been tested
through participation at the Statoil/C-Core Kaggle competition.
</summary>
    <author>
      <name>Cheng Zhan</name>
    </author>
    <author>
      <name>Licheng Zhang</name>
    </author>
    <author>
      <name>Zhenzhen Zhong</name>
    </author>
    <author>
      <name>Sher Didi-Ooi</name>
    </author>
    <author>
      <name>Youzuo Lin</name>
    </author>
    <author>
      <name>Yunxi Zhang</name>
    </author>
    <author>
      <name>Shujiao Huang</name>
    </author>
    <author>
      <name>Changchun Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1812.07367v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.07367v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.04856v1</id>
    <updated>2018-01-15T15:56:36Z</updated>
    <published>2018-01-15T15:56:36Z</published>
    <title>Improving Orbit Prediction Accuracy through Supervised Machine Learning</title>
    <summary>  Due to the lack of information such as the space environment condition and
resident space objects' (RSOs') body characteristics, current orbit predictions
that are solely grounded on physics-based models may fail to achieve required
accuracy for collision avoidance and have led to satellite collisions already.
This paper presents a methodology to predict RSOs' trajectories with higher
accuracy than that of the current methods. Inspired by the machine learning
(ML) theory through which the models are learned based on large amounts of
observed data and the prediction is conducted without explicitly modeling space
objects and space environment, the proposed ML approach integrates
physics-based orbit prediction algorithms with a learning-based process that
focuses on reducing the prediction errors. Using a simulation-based space
catalog environment as the test bed, the paper demonstrates three types of
generalization capability for the proposed ML approach: 1) the ML model can be
used to improve the same RSO's orbit information that is not available during
the learning process but shares the same time interval as the training data; 2)
the ML model can be used to improve predictions of the same RSO at future
epochs; and 3) the ML model based on a RSO can be applied to other RSOs that
share some common features.
</summary>
    <author>
      <name>Hao Peng</name>
    </author>
    <author>
      <name>Xiaoli Bai</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.asr.2018.03.001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.asr.2018.03.001" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, 21 figures, 4 tables, Preprint submitted to Advances in
  Space Research, on December 14, 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1801.04856v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.04856v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.13196v1</id>
    <updated>2019-04-30T12:44:22Z</updated>
    <published>2019-04-30T12:44:22Z</published>
    <title>Semantic Referee: A Neural-Symbolic Framework for Enhancing Geospatial
  Semantic Segmentation</title>
    <summary>  Understanding why machine learning algorithms may fail is usually the task of
the human expert that uses domain knowledge and contextual information to
discover systematic shortcomings in either the data or the algorithm. In this
paper, we propose a semantic referee, which is able to extract qualitative
features of the errors emerging from deep machine learning frameworks and
suggest corrections. The semantic referee relies on ontological reasoning about
spatial knowledge in order to characterize errors in terms of their spatial
relations with the environment. Using semantics, the reasoner interacts with
the learning algorithm as a supervisor. In this paper, the proposed method of
the interaction between a neural network classifier and a semantic referee
shows how to improve the performance of semantic segmentation for satellite
imagery data.
</summary>
    <author>
      <name>Marjan Alirezaie</name>
    </author>
    <author>
      <name>Martin Längkvist</name>
    </author>
    <author>
      <name>Michael Sioutis</name>
    </author>
    <author>
      <name>Amy Loutfi</name>
    </author>
    <link href="http://arxiv.org/abs/1904.13196v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.13196v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.01791v1</id>
    <updated>2016-11-06T15:09:50Z</updated>
    <published>2016-11-06T15:09:50Z</published>
    <title>Solar Flare Prediction Model with Three Machine-Learning Algorithms
  Using Ultraviolet Brightening and Vector Magnetogram</title>
    <summary>  We developed a flare prediction model using machine learning, which is
optimized to predict the maximum class of flares occurring in the following 24
h. Machine learning is used to devise algorithms that can learn from and make
decisions on a huge amount of data. We used solar observation data during the
period 2010-2015, such as vector magnetogram, ultraviolet (UV) emission, and
soft X-ray emission taken by the Solar Dynamics Observatory and the
Geostationary Operational Environmental Satellite. We detected active regions
from the full-disk magnetogram, from which 60 features were extracted with
their time differentials, including magnetic neutral lines, the current
helicity, the UV brightening, and the flare history. After standardizing the
feature database, we fully shuffled and randomly separated it into two for
training and testing. To investigate which algorithm is best for flare
prediction, we compared three machine learning algorithms: the support vector
machine (SVM), k-nearest neighbors (k-NN), and extremely randomized trees
(ERT). The prediction score, the true skill statistic (TSS), was higher than
0.9 with a fully shuffled dataset, which is higher than that for human
forecasts. It was found that k-NN has the highest performance among the three
algorithms. The ranking of the feature importance showed that the previous
flare activity is most effective, followed by the length of magnetic neutral
lines, the unsigned magnetic flux, the area of UV brightening, and the time
differentials of features over 24 h, all of which are strongly correlated with
the flux emergence dynamics in an active region.
</summary>
    <author>
      <name>N. Nishizuka</name>
    </author>
    <author>
      <name>K. Sugiura</name>
    </author>
    <author>
      <name>Y. Kubo</name>
    </author>
    <author>
      <name>M. Den</name>
    </author>
    <author>
      <name>S. Watari</name>
    </author>
    <author>
      <name>M. Ishii</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3847/1538-4357/835/2/156</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3847/1538-4357/835/2/156" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.01791v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.01791v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.07888v2</id>
    <updated>2017-12-14T17:42:18Z</updated>
    <published>2017-06-24T01:25:12Z</published>
    <title>Evolving Spatially Aggregated Features from Satellite Imagery for
  Regional Modeling</title>
    <summary>  Satellite imagery and remote sensing provide explanatory variables at
relatively high resolutions for modeling geospatial phenomena, yet regional
summaries are often desirable for analysis and actionable insight. In this
paper, we propose a novel method of inducing spatial aggregations as a
component of the machine learning process, yielding regional model features
whose construction is driven by model prediction performance rather than prior
assumptions. Our results demonstrate that Genetic Programming is particularly
well suited to this type of feature construction because it can automatically
synthesize appropriate aggregations, as well as better incorporate them into
predictive models compared to other regression methods we tested. In our
experiments we consider a specific problem instance and real-world dataset
relevant to predicting snow properties in high-mountain Asia.
</summary>
    <author>
      <name>Sam Kriegman</name>
    </author>
    <author>
      <name>Marcin Szubert</name>
    </author>
    <author>
      <name>Josh C. Bongard</name>
    </author>
    <author>
      <name>Christian Skalka</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-45823-6_66</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-45823-6_66" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Parallel Problem Solving from Nature - PPSN XIV. PPSN 2016.
  Lecture Notes in Computer Science, vol 9921. Springer, Cham</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1706.07888v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.07888v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.01232v3</id>
    <updated>2019-07-15T02:40:55Z</updated>
    <published>2018-07-03T15:12:59Z</published>
    <title>SpaceNet: A Remote Sensing Dataset and Challenge Series</title>
    <summary>  Foundational mapping remains a challenge in many parts of the world,
particularly in dynamic scenarios such as natural disasters when timely updates
are critical. Updating maps is currently a highly manual process requiring a
large number of human labelers to either create features or rigorously validate
automated outputs. We propose that the frequent revisits of earth imaging
satellite constellations may accelerate existing efforts to quickly update
foundational maps when combined with advanced machine learning techniques.
Accordingly, the SpaceNet partners (CosmiQ Works, Radiant Solutions, and
NVIDIA), released a large corpus of labeled satellite imagery on Amazon Web
Services (AWS) called SpaceNet. The SpaceNet partners also launched a series of
public prize competitions to encourage improvement of remote sensing machine
learning algorithms. The first two of these competitions focused on automated
building footprint extraction, and the most recent challenge focused on road
network extraction. In this paper we discuss the SpaceNet imagery, labels,
evaluation metrics, prize challenge results to date, and future plans for the
SpaceNet challenge series.
</summary>
    <author>
      <name>Adam Van Etten</name>
    </author>
    <author>
      <name>Dave Lindenbaum</name>
    </author>
    <author>
      <name>Todd M. Bacastow</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 5 figures, 2 tables, 5 appendices</arxiv:comment>
    <link href="http://arxiv.org/abs/1807.01232v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.01232v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.11766v1</id>
    <updated>2018-07-31T11:28:52Z</updated>
    <published>2018-07-31T11:28:52Z</published>
    <title>Remote sensing image regression for heterogeneous change detection</title>
    <summary>  Change detection in heterogeneous multitemporal satellite images is an
emerging topic in remote sensing. In this paper we propose a framework, based
on image regression, to perform change detection in heterogeneous multitemporal
satellite images, which has become a main topic in remote sensing. Our method
learns a transformation to map the first image to the domain of the other
image, and vice versa. Four regression methods are selected to carry out the
transformation: Gaussian processes, support vector machines, random forests,
and a recently proposed kernel regression method called homogeneous pixel
transformation. To evaluate not only potentials and limitations of our
framework, but also the pros and cons of each regression method, we perform
experiments on two data sets. The results indicates that random forests achieve
good performance, are fast and robust to hyperparameters, whereas the
homogeneous pixel transformation method can achieve better accuracy at the cost
of a higher complexity.
</summary>
    <author>
      <name>Luigi T. Luppino</name>
    </author>
    <author>
      <name>Filippo M. Bianchi</name>
    </author>
    <author>
      <name>Gabriele Moser</name>
    </author>
    <author>
      <name>Stian N. Anfinsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to Machine Learning for Signal Processing 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1807.11766v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.11766v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.08315v2</id>
    <updated>2018-10-31T19:02:57Z</updated>
    <published>2018-08-24T21:28:36Z</published>
    <title>A Deterministic Self-Organizing Map Approach and its Application on
  Satellite Data based Cloud Type Classification</title>
    <summary>  A self-organizing map (SOM) is a type of competitive artificial neural
network, which projects the high-dimensional input space of the training
samples into a low-dimensional space with the topology relations preserved.
This makes SOMs supportive of organizing and visualizing complex data sets and
have been pervasively used among numerous disciplines with different
applications. Notwithstanding its wide applications, the self-organizing map is
perplexed by its inherent randomness, which produces dissimilar SOM patterns
even when being trained on identical training samples with the same parameters
every time, and thus causes usability concerns for other domain practitioners
and precludes more potential users from exploring SOM based applications in a
broader spectrum. Motivated by this practical concern, we propose a
deterministic approach as a supplement to the standard self-organizing map. In
accordance with the theoretical design, the experimental results with satellite
cloud data demonstrate the effective and efficient organization as well as
simplification capabilities of the proposed approach.
</summary>
    <author>
      <name>Wenbin Zhang</name>
    </author>
    <author>
      <name>Jianwu Wang</name>
    </author>
    <author>
      <name>Daeho Jin</name>
    </author>
    <author>
      <name>Lazaros Oreopoulos</name>
    </author>
    <author>
      <name>Zhibo Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to IEEE Big Data 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1808.08315v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.08315v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.09860v2</id>
    <updated>2018-11-13T03:31:56Z</updated>
    <published>2018-09-26T09:17:06Z</published>
    <title>Geographically and temporally weighted neural networks for
  satellite-based mapping of ground-level PM2.5</title>
    <summary>  The integration of satellite-derived aerosol optical depth (AOD) and
station-measured PM2.5 provides a promising approach for obtaining spatial
PM2.5 data. Several spatiotemporal models, which considered spatial and
temporal heterogeneities of AOD-PM2.5 relationship, have been widely adopted
for PM2.5 estimation. However, they generally described the complex AOD-PM2.5
relationship based on a linear hypothesis. Previous machine learning models
yielded great superiorities for fitting the nonlinear AOD-PM2.5 relationship,
but seldom allowed for its spatiotemporal variations. To simultaneously
consider the nonlinearity and spatiotemporal heterogeneities of AOD-PM2.5
relationship, geographically and temporally weighted neural networks (GTWNNs)
were developed for satellite-based estimation of ground-level PM2.5 in this
study. Using satellite AOD products, NDVI data, and meteorological factors over
China as input, GTWNNs were set up with station PM2.5 measurements. Then the
spatial PM2.5 data of those locations with no ground stations could be
obtained. The proposed GTWNNs have achieved a better performance compared with
previous spatiotemporal models, i.e., daily geographically weighted regression
and geographically and temporally weighted regression. The sample-based and
site-based cross-validation R2 values of GTWNNs are 0.80 and 0.79,
respectively. On this basis, the spatial PM2.5 data with a resolution of 0.1
degree were generated in China. This study implemented the combination of
geographical law and neural networks, and improved the accuracy of
satellite-based PM2.5 estimation.
</summary>
    <author>
      <name>Tongwen Li</name>
    </author>
    <author>
      <name>Huanfeng Shen</name>
    </author>
    <author>
      <name>Qiangqiang Yuan</name>
    </author>
    <author>
      <name>Liangpei Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1809.09860v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.09860v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.01756v1</id>
    <updated>2018-12-05T00:05:01Z</updated>
    <published>2018-12-05T00:05:01Z</published>
    <title>Multi$^{\mathbf{3}}$Net: Segmenting Flooded Buildings via Fusion of
  Multiresolution, Multisensor, and Multitemporal Satellite Imagery</title>
    <summary>  We propose a novel approach for rapid segmentation of flooded buildings by
fusing multiresolution, multisensor, and multitemporal satellite imagery in a
convolutional neural network. Our model significantly expedites the generation
of satellite imagery-based flood maps, crucial for first responders and local
authorities in the early stages of flood events. By incorporating multitemporal
satellite imagery, our model allows for rapid and accurate post-disaster damage
assessment and can be used by governments to better coordinate medium- and
long-term financial assistance programs for affected areas. The network
consists of multiple streams of encoder-decoder architectures that extract
spatiotemporal information from medium-resolution images and spatial
information from high-resolution images before fusing the resulting
representations into a single medium-resolution segmentation map of flooded
buildings. We compare our model to state-of-the-art methods for building
footprint segmentation as well as to alternative fusion approaches for the
segmentation of flooded buildings and find that our model performs best on both
tasks. We also demonstrate that our model produces highly accurate segmentation
maps of flooded buildings using only publicly available medium-resolution data
instead of significantly more detailed but sparsely available very
high-resolution data. We release the first open-source dataset of fully
preprocessed and labeled multiresolution, multispectral, and multitemporal
satellite images of disaster sites along with our source code.
</summary>
    <author>
      <name>Tim G. J. Rudner</name>
    </author>
    <author>
      <name>Marc Rußwurm</name>
    </author>
    <author>
      <name>Jakub Fil</name>
    </author>
    <author>
      <name>Ramona Pelich</name>
    </author>
    <author>
      <name>Benjamin Bischke</name>
    </author>
    <author>
      <name>Veronika Kopackova</name>
    </author>
    <author>
      <name>Piotr Bilinski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Proceedings of the Thirty-Third AAAI Conference on
  Artificial Intelligence (AAAI-19)</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.01756v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.01756v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.10; I.4.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.05612v1</id>
    <updated>2017-09-17T06:21:40Z</updated>
    <published>2017-09-17T06:21:40Z</published>
    <title>Multi-Entity Dependence Learning with Rich Context via Conditional
  Variational Auto-encoder</title>
    <summary>  Multi-Entity Dependence Learning (MEDL) explores conditional correlations
among multiple entities. The availability of rich contextual information
requires a nimble learning scheme that tightly integrates with deep neural
networks and has the ability to capture correlation structures among
exponentially many outcomes. We propose MEDL_CVAE, which encodes a conditional
multivariate distribution as a generating process. As a result, the variational
lower bound of the joint likelihood can be optimized via a conditional
variational auto-encoder and trained end-to-end on GPUs. Our MEDL_CVAE was
motivated by two real-world applications in computational sustainability: one
studies the spatial correlation among multiple bird species using the eBird
data and the other models multi-dimensional landscape composition and human
footprint in the Amazon rainforest with satellite images. We show that
MEDL_CVAE captures rich dependency structures, scales better than previous
methods, and further improves on the joint likelihood taking advantage of very
large datasets that are beyond the capacity of previous methods.
</summary>
    <author>
      <name>Luming Tang</name>
    </author>
    <author>
      <name>Yexiang Xue</name>
    </author>
    <author>
      <name>Di Chen</name>
    </author>
    <author>
      <name>Carla P. Gomes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The first two authors contribute equally</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.05612v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.05612v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.03975v1</id>
    <updated>2019-06-01T18:56:33Z</updated>
    <published>2019-06-01T18:56:33Z</published>
    <title>Predicting Global Variations in Outdoor PM2.5 Concentrations using
  Satellite Images and Deep Convolutional Neural Networks</title>
    <summary>  Here we present a new method of estimating global variations in outdoor
PM$_{2.5}$ concentrations using satellite images combined with ground-level
measurements and deep convolutional neural networks. Specifically, new deep
learning models were trained over the global PM$_{2.5}$ concentration range
($&lt;$1-436 $\mu$g/m$^3$) using a large database of satellite images paired with
ground level PM$_{2.5}$ measurements available from the World Health
Organization. Final model selection was based on a systematic evaluation of
well-known architectures for the convolutional base including InceptionV3,
Xception, and VGG16. The Xception architecture performed best and the final
global model had a root mean square error (RMSE) value of 13.01 $\mu$g/m$^3$
(R$^2$=0.75) in the disjoint test set. The predictive performance of our new
global model (called IMAGE-PM$_{2.5}$) is similar to the current
state-of-the-art model used in the Global Burden of Disease study but relies
only on satellite images as input. As a result, the IMAGE-PM$_{2.5}$ model
offers a fast, cost-effective means of estimating global variations in
long-term average PM$_{2.5}$ concentrations and may be particularly useful for
regions without ground monitoring data or detailed emissions inventories. The
IMAGE-PM$_{2.5}$ model can be used as a stand-alone method of global exposure
estimation or incorporated into more complex hierarchical model structures.
</summary>
    <author>
      <name>Kris Y. Hong</name>
    </author>
    <author>
      <name>Pedro O. Pinheiro</name>
    </author>
    <author>
      <name>Scott Weichenthal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 6 figures, Submitted to Scientific Reports</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.03975v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.03975v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.04055v1</id>
    <updated>2017-04-13T09:47:12Z</updated>
    <published>2017-04-13T09:47:12Z</published>
    <title>Land Cover Classification via Multi-temporal Spatial Data by Recurrent
  Neural Networks</title>
    <summary>  Nowadays, modern earth observation programs produce huge volumes of satellite
images time series (SITS) that can be useful to monitor geographical areas
through time. How to efficiently analyze such kind of information is still an
open question in the remote sensing field. Recently, deep learning methods
proved suitable to deal with remote sensing data mainly for scene
classification (i.e. Convolutional Neural Networks - CNNs - on single images)
while only very few studies exist involving temporal deep learning approaches
(i.e Recurrent Neural Networks - RNNs) to deal with remote sensing time series.
In this letter we evaluate the ability of Recurrent Neural Networks, in
particular the Long-Short Term Memory (LSTM) model, to perform land cover
classification considering multi-temporal spatial data derived from a time
series of satellite images. We carried out experiments on two different
datasets considering both pixel-based and object-based classification. The
obtained results show that Recurrent Neural Networks are competitive compared
to state-of-the-art classifiers, and may outperform classical approaches in
presence of low represented and/or highly mixed classes. We also show that
using the alternative feature representation generated by LSTM can improve the
performances of standard classifiers.
</summary>
    <author>
      <name>Dino Ienco</name>
    </author>
    <author>
      <name>Raffaele Gaetano</name>
    </author>
    <author>
      <name>Claire Dupaquier</name>
    </author>
    <author>
      <name>Pierre Maurel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/LGRS.2017.2728698</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/LGRS.2017.2728698" rel="related"/>
    <link href="http://arxiv.org/abs/1704.04055v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.04055v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1803.00650v1</id>
    <updated>2018-03-01T22:47:35Z</updated>
    <published>2018-03-01T22:47:35Z</published>
    <title>Kernel Embedding Approaches to Orbit Determination of Spacecraft
  Clusters</title>
    <summary>  This paper presents a novel formulation and solution of orbit determination
over finite time horizons as a learning problem. We present an approach to
orbit determination under very broad conditions that are satisfied for n-body
problems. These weak conditions allow us to perform orbit determination with
noisy and highly non-linear observations such as those presented by range-rate
only (Doppler only) observations. We show that domain generalization and
distribution regression techniques can learn to estimate orbits of a group of
satellites and identify individual satellites especially with prior
understanding of correlations between orbits and provide asymptotic convergence
conditions. The approach presented requires only visibility and observability
of the underlying state from observations and is particularly useful for
autonomous spacecraft operations using low-cost ground stations or sensors. We
validate the orbit determination approach using observations of two spacecraft
(GRIFEX and MCubed-2) along with synthetic datasets of multiple spacecraft
deployments and lunar orbits. We also provide a comparison with the standard
techniques (EKF) under highly noisy conditions.
</summary>
    <author>
      <name>Srinagesh Sharma</name>
    </author>
    <author>
      <name>James W. Cutler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to JMLR</arxiv:comment>
    <link href="http://arxiv.org/abs/1803.00650v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1803.00650v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.03012v1</id>
    <updated>2019-06-07T11:16:02Z</updated>
    <published>2019-06-07T11:16:02Z</published>
    <title>Deep Learning For Experimental Hybrid Terrestrial and Satellite
  Interference Management</title>
    <summary>  Interference Management is a vast topic present in many disciplines. The
majority of wireless standards suffer the drawback of interference intrusion
and the network efficiency drop due to that. Traditionally, interference
management has been addressed by proposing signal processing techniques that
minimize their effects locally. However, the fast evolution of future
communications makes difficult to adapt to new era. In this paper we propose
the use of Deep Learning techniques to present a compact system for
interference management. In particular, we describe two subsystems capable to
detect the presence of interference, even in high Signal to Interference Ratio
(SIR), and interference classification in several radio standards. Finally, we
present results based on real signals captured from terrestrial and satellite
networks and the conclusions unveil the courageous future of AI and wireless
communications.
</summary>
    <author>
      <name>Pol Henarejos</name>
    </author>
    <author>
      <name>Miguel Ángel Vázquez</name>
    </author>
    <author>
      <name>Ana Isabel Pérez-Neira</name>
    </author>
    <link href="http://arxiv.org/abs/1906.03012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.03012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.2194v4</id>
    <updated>2016-02-03T22:59:26Z</updated>
    <published>2012-02-10T06:35:20Z</published>
    <title>Efficient statistical classification of satellite measurements</title>
    <summary>  Supervised statistical classification is a vital tool for satellite image
processing. It is useful not only when a discrete result, such as feature
extraction or surface type, is required, but also for continuum retrievals by
dividing the quantity of interest into discrete ranges. Because of the high
resolution of modern satellite instruments and because of the requirement for
real-time processing, any algorithm has to be fast to be useful. Here we
describe an algorithm based on kernel estimation called Adaptive Gaussian
Filtering that incorporates several innovations to produce superior efficiency
as compared to three other popular methods: k-nearest-neighbour (KNN), Learning
Vector Quantization (LVQ) and Support Vector Machines (SVM). This efficiency is
gained with no compromises: accuracy is maintained, while estimates of the
conditional probabilities are returned. These are useful not only to gauge the
accuracy of an estimate in the absence of its true value, but also to
re-calibrate a retrieved image and as a proxy for a discretized continuum
variable. The algorithm is demonstrated and compared with the other three on a
pair of synthetic test classes and to map the waterways of the Netherlands.
Software may be found at: http://libagf.sourceforge.net.
</summary>
    <author>
      <name>Peter Mills</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/01431161.2010.507795</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/01431161.2010.507795" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Corrected formatting errors, corrected equation in appendix</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Remote Sensing, 2011, 32(21): 6109-6132</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.2194v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.2194v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.05283v1</id>
    <updated>2019-07-08T17:03:12Z</updated>
    <published>2019-07-08T17:03:12Z</published>
    <title>A Comparison of Super-Resolution and Nearest Neighbors Interpolation
  Applied to Object Detection on Satellite Data</title>
    <summary>  As Super-Resolution (SR) has matured as a research topic, it has been applied
to additional topics beyond image reconstruction. In particular, combining
classification or object detection tasks with a super-resolution preprocessing
stage has yielded improvements in accuracy especially with objects that are
small relative to the scene. While SR has shown promise, a study comparing SR
and naive upscaling methods such as Nearest Neighbors (NN) interpolation when
applied as a preprocessing step for object detection has not been performed. We
apply the topic to satellite data and compare the Multi-scale Deep
Super-Resolution (MDSR) system to NN on the xView challenge dataset. To do so,
we propose a pipeline for processing satellite data that combines multi-stage
image tiling and upscaling, the YOLOv2 object detection architecture, and label
stitching. We compare the effects of training models using an upscaling factor
of 4, upscaling images from 30cm Ground Sample Distance (GSD) to an effective
GSD of 7.5cm. Upscaling by this factor significantly improves detection
results, increasing Average Precision (AP) of a generalized vehicle class by 23
percent. We demonstrate that while SR produces upscaled images that are more
visually pleasing than their NN counterparts, object detection networks see
little difference in accuracy with images upsampled using NN obtaining nearly
identical results to the MDSRx4 enhanced images with a difference of 0.0002 AP
between the two methods.
</summary>
    <author>
      <name>Evan Koester</name>
    </author>
    <author>
      <name>Cem Safak Sahin</name>
    </author>
    <link href="http://arxiv.org/abs/1907.05283v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.05283v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1811.09496v2</id>
    <updated>2019-02-01T12:42:40Z</updated>
    <published>2018-11-23T14:36:23Z</published>
    <title>The Error is the Feature: how to Forecast Lightning using a Model
  Prediction Error</title>
    <summary>  Despite the progress within the last decades, weather forecasting is still a
challenging and computationally expensive task. Current satellite-based
approaches to predict thunderstorms are usually based on the analysis of the
observed brightness temperatures in different spectral channels and emit a
warning if a critical threshold is reached. Recent progress in data science
however demonstrates that machine learning can be successfully applied to many
research fields in science, especially in areas dealing with large datasets. We
therefore present a new approach to the problem of predicting thunderstorms
based on machine learning. The core idea of our work is to use the error of
two-dimensional optical flow algorithms applied to images of meteorological
satellites as a feature for machine learning models. We interpret that optical
flow error as an indication of convection potentially leading to thunderstorms
and lightning. To factor in spatial proximity we use various manual convolution
steps. We also consider effects such as the time of day or the geographic
location. We train different tree classifier models as well as a neural network
to predict lightning within the next few hours (called nowcasting in
meteorology) based on these features. In our evaluation section we compare the
predictive power of the different models and the impact of different features
on the classification result. Our results show a high accuracy of 96% for
predictions over the next 15 minutes which slightly decreases with increasing
forecast period but still remains above 83% for forecasts of up to five hours.
The high false positive rate of nearly 6% however needs further investigation
to allow for an operational use of our approach.
</summary>
    <author>
      <name>Christian Schön</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Saarland Informatics Campus</arxiv:affiliation>
    </author>
    <author>
      <name>Jens Dittrich</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Saarland Informatics Campus</arxiv:affiliation>
    </author>
    <author>
      <name>Richard Müller</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Deutscher Wetterdienst</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1811.09496v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1811.09496v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.02811v1</id>
    <updated>2016-06-09T03:33:11Z</updated>
    <published>2016-06-09T03:33:11Z</published>
    <title>Machine Learning Techniques and Applications For Ground-based Image
  Analysis</title>
    <summary>  Ground-based whole sky cameras have opened up new opportunities for
monitoring the earth's atmosphere. These cameras are an important complement to
satellite images by providing geoscientists with cheaper, faster, and more
localized data. The images captured by whole sky imagers can have high spatial
and temporal resolution, which is an important pre-requisite for applications
such as solar energy modeling, cloud attenuation analysis, local weather
prediction, etc.
  Extracting valuable information from the huge amount of image data by
detecting and analyzing the various entities in these images is challenging.
However, powerful machine learning techniques have become available to aid with
the image analysis. This article provides a detailed walk-through of recent
developments in these techniques and their applications in ground-based
imaging. We aim to bridge the gap between computer vision and remote sensing
with the help of illustrative examples. We demonstrate the advantages of using
machine learning techniques in ground-based image analysis via three primary
applications -- segmentation, classification, and denoising.
</summary>
    <author>
      <name>Soumyabrata Dev</name>
    </author>
    <author>
      <name>Bihan Wen</name>
    </author>
    <author>
      <name>Yee Hui Lee</name>
    </author>
    <author>
      <name>Stefan Winkler</name>
    </author>
    <link href="http://arxiv.org/abs/1606.02811v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.02811v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.05347v1</id>
    <updated>2016-08-18T17:47:53Z</updated>
    <published>2016-08-18T17:47:53Z</published>
    <title>Probabilistic Data Analysis with Probabilistic Programming</title>
    <summary>  Probabilistic techniques are central to data analysis, but different
approaches can be difficult to apply, combine, and compare. This paper
introduces composable generative population models (CGPMs), a computational
abstraction that extends directed graphical models and can be used to describe
and compose a broad class of probabilistic data analysis techniques. Examples
include hierarchical Bayesian models, multivariate kernel methods,
discriminative machine learning, clustering algorithms, dimensionality
reduction, and arbitrary probabilistic programs. We also demonstrate the
integration of CGPMs into BayesDB, a probabilistic programming platform that
can express data analysis tasks using a modeling language and a structured
query language. The practical value is illustrated in two ways. First, CGPMs
are used in an analysis that identifies satellite data records which probably
violate Kepler's Third Law, by composing causal probabilistic programs with
non-parametric Bayes in under 50 lines of probabilistic code. Second, for
several representative data analysis tasks, we report on lines of code and
accuracy measurements of various CGPMs, plus comparisons with standard baseline
solutions from Python and MATLAB libraries.
</summary>
    <author>
      <name>Feras Saad</name>
    </author>
    <author>
      <name>Vikash Mansinghka</name>
    </author>
    <link href="http://arxiv.org/abs/1608.05347v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.05347v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.05611v2</id>
    <updated>2019-04-25T18:54:53Z</updated>
    <published>2019-02-14T21:41:18Z</published>
    <title>GeoGAN: A Conditional GAN with Reconstruction and Style Loss to Generate
  Standard Layer of Maps from Satellite Images</title>
    <summary>  Automatically generating maps from satellite images is an important task.
There is a body of literature which tries to address this challenge. We created
a more expansive survey of the task by experimenting with different models and
adding new loss functions to improve results. We created a database of pairs of
satellite images and the corresponding map of the area. Our model translates
the satellite image to the corresponding standard layer map image using three
main model architectures: (i) a conditional Generative Adversarial Network
(GAN) which compresses the images down to a learned embedding, (ii) a generator
which is trained as a normalizing flow (RealNVP) model, and (iii) a conditional
GAN where the generator translates via a series of convolutions to the standard
layer of a map and the discriminator input is the concatenation of the
real/generated map and the satellite image. Model (iii) was by far the most
promising of three models. To improve the results we also added a
reconstruction loss and style transfer loss in addition to the GAN losses. The
third model architecture produced the best quality of sampled images. In
contrast to the other generative model where evaluation of the model is a
challenging problem. since we have access to the real map for a given satellite
image, we are able to assign a quantitative metric to the quality of the
generated images in addition to inspecting them visually. While we are
continuing to work on increasing the accuracy of the model, one challenge has
been the coarse resolution of the data which upper-bounds the quality of the
results of our model. Nevertheless, as will be seen in the results, the
generated map is more accurate in the features it produces since the generator
architecture demands a pixel-wise image translation/pixel-wise coloring. A
video presentation summarizing this paper is available at:
https://youtu.be/Ur0flOX-Ji0
</summary>
    <author>
      <name>Swetava Ganguli</name>
    </author>
    <author>
      <name>Pedro Garzon</name>
    </author>
    <author>
      <name>Noa Glaser</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Version 2 of paper submitted incorporating minor revisions. Corrected
  typographical errors and added some additional references</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.05611v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.05611v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.03915v1</id>
    <updated>2016-04-13T19:13:17Z</updated>
    <published>2016-04-13T19:13:17Z</published>
    <title>Removing Clouds and Recovering Ground Observations in Satellite Image
  Sequences via Temporally Contiguous Robust Matrix Completion</title>
    <summary>  We consider the problem of removing and replacing clouds in satellite image
sequences, which has a wide range of applications in remote sensing. Our
approach first detects and removes the cloud-contaminated part of the image
sequences. It then recovers the missing scenes from the clean parts using the
proposed "TECROMAC" (TEmporally Contiguous RObust MAtrix Completion) objective.
The objective function balances temporal smoothness with a low rank solution
while staying close to the original observations. The matrix whose the rows are
pixels and columnsare days corresponding to the image, has low-rank because the
pixels reflect land-types such as vegetation, roads and lakes and there are
relatively few variations as a result. We provide efficient optimization
algorithms for TECROMAC, so we can exploit images containing millions of
pixels. Empirical results on real satellite image sequences, as well as
simulated data, demonstrate that our approach is able to recover underlying
images from heavily cloud-contaminated observations.
</summary>
    <author>
      <name>Jialei Wang</name>
    </author>
    <author>
      <name>Peder A. Olsen</name>
    </author>
    <author>
      <name>Andrew R. Conn</name>
    </author>
    <author>
      <name>Aurelie C. Lozano</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To Appear In Conference on Computer Vision and Pattern Recognition
  (CVPR 2016)</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.03915v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.03915v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.06878v3</id>
    <updated>2018-02-22T12:47:37Z</updated>
    <published>2017-06-21T13:06:57Z</published>
    <title>An Unsupervised Method for Estimating the Global Horizontal Irradiance
  from Photovoltaic Power Measurements</title>
    <summary>  In this paper, we present a method to determine the global horizontal
irradiance (GHI) from the power measurements of one or more PV systems, located
in the same neighborhood. The method is completely unsupervised and is based on
a physical model of a PV plant. The precise assessment of solar irradiance is
pivotal for the forecast of the electric power generated by photovoltaic (PV)
plants. However, on-ground measurements are expensive and are generally not
performed for small and medium-sized PV plants. Satellite-based services
represent a valid alternative to on site measurements, but their space-time
resolution is limited. Results from two case studies located in Switzerland are
presented. The performance of the proposed method at assessing GHI is compared
with that of free and commercial satellite services. Our results show that the
presented method is generally better than satellite-based services, especially
at high temporal resolutions.
</summary>
    <author>
      <name>Lorenzo Nespoli</name>
    </author>
    <author>
      <name>Vasco Medici</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Solar Energy Volume 158, December 2017, Pages 701-710</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1706.06878v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.06878v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1712.02282v3</id>
    <updated>2018-06-25T14:04:52Z</updated>
    <published>2017-12-06T16:53:14Z</published>
    <title>On monitoring development indicators using high resolution satellite
  images</title>
    <summary>  We develop a machine learning based tool for accurate prediction of
socio-economic indicators from daytime satellite imagery. The diverse set of
indicators are often not intuitively related to observable features in
satellite images, and are not even always well correlated with each other. Our
predictive tool is more accurate than using night light as a proxy, and can be
used to predict missing data, smooth out noise in surveys, monitor development
progress of a region, and flag potential anomalies. Finally, we use predicted
variables to do robustness analysis of a regression study of high rate of
stunting in India.
</summary>
    <author>
      <name>Potnuru Kishen Suraj</name>
    </author>
    <author>
      <name>Ankesh Gupta</name>
    </author>
    <author>
      <name>Makkunda Sharma</name>
    </author>
    <author>
      <name>Sourabh Bikas Paul</name>
    </author>
    <author>
      <name>Subhashis Banerjee</name>
    </author>
    <link href="http://arxiv.org/abs/1712.02282v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1712.02282v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="econ.EM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="econ.EM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.08528v1</id>
    <updated>2018-08-26T10:32:40Z</updated>
    <published>2018-08-26T10:32:40Z</published>
    <title>A MapReduce based Big-data Framework for Object Extraction from Mosaic
  Satellite Images</title>
    <summary>  We propose a framework stitching of vector representations of large scale
raster mosaic images in distributed computing model. In this way, the negative
effect of the lack of resources of the central system and scalability problem
can be eliminated. The product obtained by this study can be used in
applications requiring spatial and temporal analysis on big satellite map
images. This study also shows that big data frameworks are not only used in
applications of text-based data mining and machine learning algorithms, but
also used in applications of algorithms in image processing. The effectiveness
of the product realized with this project is also going to be proven by
scalability and performance tests performed on real world LandSat-8 satellite
images.
</summary>
    <author>
      <name>Suleyman Eken</name>
    </author>
    <author>
      <name>Ahmet Sayar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of Doctoral Consortium on Internet of Things At Roma,
  Italy 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1808.08528v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.08528v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.07033v1</id>
    <updated>2018-12-17T20:08:23Z</updated>
    <published>2018-12-17T20:08:23Z</published>
    <title>From Satellite Imagery to Disaster Insights</title>
    <summary>  The use of satellite imagery has become increasingly popular for disaster
monitoring and response. After a disaster, it is important to prioritize rescue
operations, disaster response and coordinate relief efforts. These have to be
carried out in a fast and efficient manner since resources are often limited in
disaster-affected areas and it's extremely important to identify the areas of
maximum damage. However, most of the existing disaster mapping efforts are
manual which is time-consuming and often leads to erroneous results. In order
to address these issues, we propose a framework for change detection using
Convolutional Neural Networks (CNN) on satellite images which can then be
thresholded and clustered together into grids to find areas which have been
most severely affected by a disaster. We also present a novel metric called
Disaster Impact Index (DII) and use it to quantify the impact of two natural
disasters - the Hurricane Harvey flood and the Santa Rosa fire. Our framework
achieves a top F1 score of 81.2% on the gridded flood dataset and 83.5% on the
gridded fire dataset.
</summary>
    <author>
      <name>Jigar Doshi</name>
    </author>
    <author>
      <name>Saikat Basu</name>
    </author>
    <author>
      <name>Guan Pang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS 2018 Camera-Ready version; AI for Social Good Workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.07033v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.07033v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.00098v2</id>
    <updated>2016-02-27T23:21:48Z</updated>
    <published>2015-10-01T03:04:29Z</published>
    <title>Transfer Learning from Deep Features for Remote Sensing and Poverty
  Mapping</title>
    <summary>  The lack of reliable data in developing countries is a major obstacle to
sustainable development, food security, and disaster relief. Poverty data, for
example, is typically scarce, sparse in coverage, and labor-intensive to
obtain. Remote sensing data such as high-resolution satellite imagery, on the
other hand, is becoming increasingly available and inexpensive. Unfortunately,
such data is highly unstructured and currently no techniques exist to
automatically extract useful insights to inform policy decisions and help
direct humanitarian efforts. We propose a novel machine learning approach to
extract large-scale socioeconomic indicators from high-resolution satellite
imagery. The main challenge is that training data is very scarce, making it
difficult to apply modern techniques such as Convolutional Neural Networks
(CNN). We therefore propose a transfer learning approach where nighttime light
intensities are used as a data-rich proxy. We train a fully convolutional CNN
model to predict nighttime lights from daytime imagery, simultaneously learning
features that are useful for poverty prediction. The model learns filters
identifying different terrains and man-made structures, including roads,
buildings, and farmlands, without any supervision beyond nighttime lights. We
demonstrate that these learned features are highly informative for poverty
mapping, even approaching the predictive performance of survey data collected
in the field.
</summary>
    <author>
      <name>Michael Xie</name>
    </author>
    <author>
      <name>Neal Jean</name>
    </author>
    <author>
      <name>Marshall Burke</name>
    </author>
    <author>
      <name>David Lobell</name>
    </author>
    <author>
      <name>Stefano Ermon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proc. 30th AAAI Conference on Artificial Intelligence</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.00098v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.00098v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.4204v1</id>
    <updated>2013-05-17T22:40:14Z</updated>
    <published>2013-05-17T22:40:14Z</published>
    <title>Machine learning on images using a string-distance</title>
    <summary>  We present a new method for image feature-extraction which is based on
representing an image by a finite-dimensional vector of distances that measure
how different the image is from a set of image prototypes. We use the recently
introduced Universal Image Distance (UID) \cite{RatsabyChesterIEEE2012} to
compare the similarity between an image and a prototype image. The advantage in
using the UID is the fact that no domain knowledge nor any image analysis need
to be done. Each image is represented by a finite dimensional feature vector
whose components are the UID values between the image and a finite set of image
prototypes from each of the feature categories. The method is automatic since
once the user selects the prototype images, the feature vectors are
automatically calculated without the need to do any image analysis. The
prototype images can be of different size, in particular, different than the
image size. Based on a collection of such cases any supervised or unsupervised
learning algorithm can be used to train and produce an image classifier or
image cluster analysis. In this paper we present the image feature-extraction
method and use it on several supervised and unsupervised learning experiments
for satellite image data.
</summary>
    <author>
      <name>Uzi Chester</name>
    </author>
    <author>
      <name>Joel Ratsaby</name>
    </author>
    <link href="http://arxiv.org/abs/1305.4204v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.4204v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.09086v1</id>
    <updated>2017-08-30T02:05:16Z</updated>
    <published>2017-08-30T02:05:16Z</published>
    <title>A Deep Learning Approach for Population Estimation from Satellite
  Imagery</title>
    <summary>  Knowing where people live is a fundamental component of many decision making
processes such as urban development, infectious disease containment, evacuation
planning, risk management, conservation planning, and more. While bottom-up,
survey driven censuses can provide a comprehensive view into the population
landscape of a country, they are expensive to realize, are infrequently
performed, and only provide population counts over broad areas. Population
disaggregation techniques and population projection methods individually
address these shortcomings, but also have shortcomings of their own. To jointly
answer the questions of "where do people live" and "how many people live
there," we propose a deep learning model for creating high-resolution
population estimations from satellite imagery. Specifically, we train
convolutional neural networks to predict population in the USA at a
$0.01^{\circ} \times 0.01^{\circ}$ resolution grid from 1-year composite
Landsat imagery. We validate these models in two ways: quantitatively, by
comparing our model's grid cell estimates aggregated at a county-level to
several US Census county-level population projections, and qualitatively, by
directly interpreting the model's predictions in terms of the satellite image
inputs. We find that aggregating our model's estimates gives comparable results
to the Census county-level population projections and that the predictions made
by our model can be directly interpreted, which give it advantages over
traditional population disaggregation methods. In general, our model is an
example of how machine learning techniques can be an effective tool for
extracting information from inherently unstructured, remotely sensed data to
provide effective solutions to social problems.
</summary>
    <author>
      <name>Caleb Robinson</name>
    </author>
    <author>
      <name>Fred Hohman</name>
    </author>
    <author>
      <name>Bistra Dilkina</name>
    </author>
    <link href="http://arxiv.org/abs/1708.09086v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.09086v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.11110v2</id>
    <updated>2019-04-25T19:27:01Z</updated>
    <published>2019-02-13T21:52:17Z</published>
    <title>Semi-Supervised Multitask Learning on Multispectral Satellite Images
  Using Wasserstein Generative Adversarial Networks (GANs) for Predicting
  Poverty</title>
    <summary>  Obtaining reliable data describing local poverty metrics at a granularity
that is informative to policy-makers requires expensive and logistically
difficult surveys, particularly in the developing world. Not surprisingly, the
poverty stricken regions are also the ones which have a high probability of
being a war zone, have poor infrastructure and sometimes have governments that
do not cooperate with internationally funded development efforts. We train a
CNN on free and publicly available daytime satellite images of the African
continent from Landsat 7 to build a model for predicting local economic
livelihoods. Only 5% of the satellite images can be associated with labels
(which are obtained from DHS Surveys) and thus a semi-supervised approach using
a GAN (similar to the approach of Salimans, et al. (2016)), albeit with a more
stable-to-train flavor of GANs called the Wasserstein GAN regularized with
gradient penalty(Gulrajani, et al. (2017)) is used. The method of multitask
learning is employed to regularize the network and also create an end-to-end
model for the prediction of multiple poverty metrics.
</summary>
    <author>
      <name>Anthony Perez</name>
    </author>
    <author>
      <name>Swetava Ganguli</name>
    </author>
    <author>
      <name>Stefano Ermon</name>
    </author>
    <author>
      <name>George Azzari</name>
    </author>
    <author>
      <name>Marshall Burke</name>
    </author>
    <author>
      <name>David Lobell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This project was recognized as the best two-person project during the
  Spring 2017 offering of CS 231N Convolutional Neural Networks for Visual
  Recognition. Second revised version corrects typographical errors and adds a
  few additional references</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.11110v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.11110v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.08117v1</id>
    <updated>2016-12-24T00:06:02Z</updated>
    <published>2016-12-24T00:06:02Z</published>
    <title>Improving Human-Machine Cooperative Visual Search With Soft Highlighting</title>
    <summary>  Advances in machine learning have produced systems that attain human-level
performance on certain visual tasks, e.g., object identification. Nonetheless,
other tasks requiring visual expertise are unlikely to be entrusted to machines
for some time, e.g., satellite and medical imagery analysis. We describe a
human-machine cooperative approach to visual search, the aim of which is to
outperform either human or machine acting alone. The traditional route to
augmenting human performance with automatic classifiers is to draw boxes around
regions of an image deemed likely to contain a target. Human experts typically
reject this type of hard highlighting. We propose instead a soft highlighting
technique in which the saliency of regions of the visual field is modulated in
a graded fashion based on classifier confidence level. We report on experiments
with both synthetic and natural images showing that soft highlighting achieves
a performance synergy surpassing that attained by hard highlighting.
</summary>
    <author>
      <name>Ronald T. Kneusel</name>
    </author>
    <author>
      <name>Michael C. Mozer</name>
    </author>
    <link href="http://arxiv.org/abs/1612.08117v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.08117v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.08937v3</id>
    <updated>2018-12-13T18:27:28Z</updated>
    <published>2018-02-25T01:15:47Z</published>
    <title>Detecting Comma-shaped Clouds for Severe Weather Forecasting using Shape
  and Motion</title>
    <summary>  Meteorologists use shapes and movements of clouds in satellite images as
indicators of several major types of severe storms. Satellite imaginary data
are in increasingly higher resolution, both spatially and temporally, making it
impossible for humans to fully leverage the data in their forecast. Automatic
satellite imagery analysis methods that can find storm-related cloud patterns
as soon as they are detectable are in demand. We propose a machine learning and
pattern recognition based approach to detect "comma-shaped" clouds in satellite
images, which are specific cloud distribution patterns strongly associated with
the cyclone formulation. In order to detect regions with the targeted movement
patterns, our method is trained on manually annotated cloud examples
represented by both shape and motion-sensitive features. Sliding windows in
different scales are used to ensure that dense clouds will be captured, and we
implement effective selection rules to shrink the region of interest among
these sliding windows. Finally, we evaluate the method on a hold-out annotated
comma-shaped cloud dataset and cross-match the results with recorded storm
events in the severe weather database. The validated utility and accuracy of
our method suggest a high potential for assisting meteorologists in weather
forecasting.
</summary>
    <author>
      <name>Xinye Zheng</name>
    </author>
    <author>
      <name>Jianbo Ye</name>
    </author>
    <author>
      <name>Yukun Chen</name>
    </author>
    <author>
      <name>Stephen Wistar</name>
    </author>
    <author>
      <name>Jia Li</name>
    </author>
    <author>
      <name>Jose A. Piedra-Fernández</name>
    </author>
    <author>
      <name>Michael A. Steinberg</name>
    </author>
    <author>
      <name>James Z. Wang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TGRS.2018.2887206</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TGRS.2018.2887206" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Under submission</arxiv:comment>
    <link href="http://arxiv.org/abs/1802.08937v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.08937v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.05405v1</id>
    <updated>2016-11-16T18:48:18Z</updated>
    <published>2016-11-16T18:48:18Z</published>
    <title>Correcting biased observation model error in data assimilation</title>
    <summary>  While the formulation of most data assimilation schemes assumes an unbiased
observation model error, in real applications, model error with nontrivial
biases is unavoidable. A practical example is the error in the radiative
transfer model (which is used to assimilate satellite measurements) in the
presence of clouds. As a consequence, many (in fact 99\%) of the cloudy
observed measurements are not being used although they may contain useful
information. This paper presents a novel nonparametric Bayesian scheme which is
able to learn the observation model error distribution and correct the bias in
incoming observations. This scheme can be used in tandem with any data
assimilation forecasting system. The proposed model error estimator uses
nonparametric likelihood functions constructed with data-driven basis functions
based on the theory of kernel embeddings of conditional distributions developed
in the machine learning community. Numerically, we show positive results with
two examples. The first example is designed to produce a bimodality in the
observation model error (typical of "cloudy" observations) by introducing
obstructions to the observations which occur randomly in space and time. The
second example, which is physically more realistic, is to assimilate cloudy
satellite brightness temperature-like quantities, generated from a stochastic
cloud model for tropical convection and a simple radiative transfer model.
</summary>
    <author>
      <name>John Harlim</name>
    </author>
    <author>
      <name>Tyrus Berry</name>
    </author>
    <link href="http://arxiv.org/abs/1611.05405v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.05405v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.02095v1</id>
    <updated>2019-02-06T10:23:01Z</updated>
    <published>2019-02-06T10:23:01Z</published>
    <title>Space Navigator: a Tool for the Optimization of Collision Avoidance
  Maneuvers</title>
    <summary>  The number of space objects will grow several times in a few years due to the
planned launches of constellations of thousands microsatellites. It leads to a
significant increase in the threat of satellite collisions. Spacecraft must
undertake collision avoidance maneuvers to mitigate the risk. According to
publicly available information, conjunction events are now manually handled by
operators on the Earth. The manual maneuver planning requires qualified
personnel and will be impractical for constellations of thousands satellites.
In this paper we propose a new modular autonomous collision avoidance system
called "Space Navigator". It is based on a novel maneuver optimization approach
that combines domain knowledge with Reinforcement Learning methods.
</summary>
    <author>
      <name>Leonid Gremyachikh</name>
    </author>
    <author>
      <name>Dmitrii Dubov</name>
    </author>
    <author>
      <name>Nikita Kazeev</name>
    </author>
    <author>
      <name>Andrey Kulibaba</name>
    </author>
    <author>
      <name>Andrey Skuratov</name>
    </author>
    <author>
      <name>Anton Tereshkin</name>
    </author>
    <author>
      <name>Andrey Ustyuzhanin</name>
    </author>
    <author>
      <name>Lubov Shiryaeva</name>
    </author>
    <author>
      <name>Sergej Shishkin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to AAS Advances in the Astronautical Sciences, presented at
  IAA SciTech Forum 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.02095v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.02095v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.06818v2</id>
    <updated>2016-03-07T16:03:39Z</updated>
    <published>2016-02-22T15:31:19Z</published>
    <title>Graph Regularized Low Rank Representation for Aerosol Optical Depth
  Retrieval</title>
    <summary>  In this paper, we propose a novel data-driven regression model for aerosol
optical depth (AOD) retrieval. First, we adopt a low rank representation (LRR)
model to learn a powerful representation of the spectral response. Then, graph
regularization is incorporated into the LRR model to capture the local
structure information and the nonlinear property of the remote-sensing data.
Since it is easy to acquire the rich satellite-retrieval results, we use them
as a baseline to construct the graph. Finally, the learned feature
representation is feeded into support vector machine (SVM) to retrieve AOD.
Experiments are conducted on two widely used data sets acquired by different
sensors, and the experimental results show that the proposed method can achieve
superior performance compared to the physical models and other state-of-the-art
empirical models.
</summary>
    <author>
      <name>Yubao Sun</name>
    </author>
    <author>
      <name>Renlong Hang</name>
    </author>
    <author>
      <name>Qingshan Liu</name>
    </author>
    <author>
      <name>Fuping Zhu</name>
    </author>
    <author>
      <name>Hucheng Pei</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/01431161.2016.1249302</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/01431161.2016.1249302" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.06818v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.06818v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.04431v3</id>
    <updated>2018-06-06T20:39:29Z</updated>
    <published>2018-02-13T02:09:32Z</published>
    <title>Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic
  Thresholding</title>
    <summary>  As spacecraft send back increasing amounts of telemetry data, improved
anomaly detection systems are needed to lessen the monitoring burden placed on
operations engineers and reduce operational risk. Current spacecraft monitoring
systems only target a subset of anomaly types and often require costly expert
knowledge to develop and maintain due to challenges involving scale and
complexity. We demonstrate the effectiveness of Long Short-Term Memory (LSTMs)
networks, a type of Recurrent Neural Network (RNN), in overcoming these issues
using expert-labeled telemetry anomaly data from the Soil Moisture Active
Passive (SMAP) satellite and the Mars Science Laboratory (MSL) rover,
Curiosity. We also propose a complementary unsupervised and nonparametric
anomaly thresholding approach developed during a pilot implementation of an
anomaly detection system for SMAP, and offer false positive mitigation
strategies along with other key improvements and lessons learned during
development.
</summary>
    <author>
      <name>Kyle Hundman</name>
    </author>
    <author>
      <name>Valentino Constantinou</name>
    </author>
    <author>
      <name>Christopher Laporte</name>
    </author>
    <author>
      <name>Ian Colwell</name>
    </author>
    <author>
      <name>Tom Soderstrom</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3219819.3219845</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3219819.3219845" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">KDD 2018 camera-ready version</arxiv:comment>
    <link href="http://arxiv.org/abs/1802.04431v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.04431v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1803.04899v3</id>
    <updated>2019-03-14T15:38:56Z</updated>
    <published>2018-03-13T15:55:35Z</published>
    <title>Optimal Transport for Multi-source Domain Adaptation under Target Shift</title>
    <summary>  In this paper, we propose to tackle the problem of reducing discrepancies
between multiple domains referred to as multi-source domain adaptation and
consider it under the target shift assumption: in all domains we aim to solve a
classification problem with the same output classes, but with labels'
proportions differing across them. This problem, generally ignored in the vast
majority papers on domain adaptation papers, is nevertheless critical in
real-world applications, and we theoretically show its impact on the adaptation
success. To address this issue, we design a method based on optimal transport,
a theory that has been successfully used to tackle adaptation problems in
machine learning. Our method performs multi-source adaptation and target shift
correction simultaneously by learning the class probabilities of the unlabeled
target sample and the coupling allowing to align two (or more) probability
distributions. Experiments on both synthetic and real-world data related to
satellite image segmentation task show the superiority of the proposed method
over the state-of-the-art.
</summary>
    <author>
      <name>Ievgen Redko</name>
    </author>
    <author>
      <name>Nicolas Courty</name>
    </author>
    <author>
      <name>Rémi Flamary</name>
    </author>
    <author>
      <name>Devis Tuia</name>
    </author>
    <link href="http://arxiv.org/abs/1803.04899v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1803.04899v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1811.02471v2</id>
    <updated>2018-12-02T11:30:38Z</updated>
    <published>2018-10-28T17:58:22Z</published>
    <title>Convolutional LSTMs for Cloud-Robust Segmentation of Remote Sensing
  Imagery</title>
    <summary>  Clouds frequently cover the Earth's surface and pose an omnipresent challenge
to optical Earth observation methods. The vast majority of remote sensing
approaches either selectively choose single cloud-free observations or employ a
pre-classification strategy to identify and mask cloudy pixels. We follow a
different strategy and treat cloud coverage as noise that is inherent to the
observed satellite data. In prior work, we directly employed a straightforward
\emph{convolutional long short-term memory} network for vegetation
classification without explicit cloud filtering and achieved state-of-the-art
classification accuracies. In this work, we investigate this cloud-robustness
further by visualizing internal cell activations and performing an ablation
experiment on datasets of different cloud coverage. In the visualizations of
network states, we identified some cells in which modulation and input gates
closed on cloudy pixels. This indicates that the network has internalized a
cloud-filtering mechanism without being specifically trained on cloud labels.
Overall, our results question the necessity of sophisticated pre-processing
pipelines for multi-temporal deep learning approaches.
</summary>
    <author>
      <name>Marc Rußwurm</name>
    </author>
    <author>
      <name>Marco Körner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Cameraready version to NeurIPS 2018 Spatiotemporal Workshop.
  Openreview: https://openreview.net/forum?id=Sye7df9CK7</arxiv:comment>
    <link href="http://arxiv.org/abs/1811.02471v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1811.02471v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.04595v1</id>
    <updated>2019-06-10T01:18:35Z</updated>
    <published>2019-06-10T01:18:35Z</published>
    <title>Evaluating aleatoric and epistemic uncertainties of time series deep
  learning models for soil moisture predictions</title>
    <summary>  Soil moisture is an important variable that determines floods, vegetation
health, agriculture productivity, and land surface feedbacks to the atmosphere,
etc. Accurately modeling soil moisture has important implications in both
weather and climate models. The recently available satellite-based observations
give us a unique opportunity to build data-driven models to predict soil
moisture instead of using land surface models, but previously there was no
uncertainty estimate. We tested Monte Carlo dropout (MCD) with an aleatoric
term for our long short-term memory models for this problem, and asked if the
uncertainty terms behave as they were argued to. We show that the method
successfully captures the predictive error after tuning a hyperparameter on a
representative training dataset. We show the MCD uncertainty estimate, as
previously argued, does detect dissimilarity.
</summary>
    <author>
      <name>Kuai Fang</name>
    </author>
    <author>
      <name>Chaopeng Shen</name>
    </author>
    <author>
      <name>Daniel Kifer</name>
    </author>
    <link href="http://arxiv.org/abs/1906.04595v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.04595v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.01933v1</id>
    <updated>2019-01-31T16:28:16Z</updated>
    <published>2019-01-31T16:28:16Z</published>
    <title>Combining Physically-Based Modeling and Deep Learning for Fusing GRACE
  Satellite Data: Can We Learn from Mismatch?</title>
    <summary>  Global hydrological and land surface models are increasingly used for
tracking terrestrial total water storage (TWS) dynamics, but the utility of
existing models is hampered by conceptual and/or data uncertainties related to
various underrepresented and unrepresented processes, such as groundwater
storage. The gravity recovery and climate experiment (GRACE) satellite mission
provided a valuable independent data source for tracking TWS at regional and
continental scales. Strong interests exist in fusing GRACE data into global
hydrological models to improve their predictive performance. Here we develop
and apply deep convolutional neural network (CNN) models to learn the
spatiotemporal patterns of mismatch between TWS anomalies (TWSA) derived from
GRACE and those simulated by NOAH, a widely used land surface model. Once
trained, our CNN models can be used to correct the NOAH simulated TWSA without
requiring GRACE data, potentially filling the data gap between GRACE and its
follow-on mission, GRACE-FO. Our methodology is demonstrated over India, which
has experienced significant groundwater depletion in recent decades that is
nevertheless not being captured by the NOAH model. Results show that the CNN
models significantly improve the match with GRACE TWSA, achieving a
country-average correlation coefficient of 0.94 and Nash-Sutcliff efficient of
0.87, or 14\% and 52\% improvement respectively over the original NOAH TWSA. At
the local scale, the learned mismatch pattern correlates well with the observed
in situ groundwater storage anomaly data for most parts of India, suggesting
that deep learning models effectively compensate for the missing groundwater
component in NOAH for this study region.
</summary>
    <author>
      <name>Alexander Y. Sun</name>
    </author>
    <author>
      <name>Bridget R. Scanlon</name>
    </author>
    <author>
      <name>Zizhan Zhang</name>
    </author>
    <author>
      <name>David Walling</name>
    </author>
    <author>
      <name>Soumendra N. Bhanja</name>
    </author>
    <author>
      <name>Abhijit Mukherjee</name>
    </author>
    <author>
      <name>Zhi Zhong</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1029/2018WR023333</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1029/2018WR023333" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Water Resources Research, 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1902.01933v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.01933v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.06323v1</id>
    <updated>2017-11-16T21:27:33Z</updated>
    <published>2017-11-16T21:27:33Z</published>
    <title>Poverty Mapping Using Convolutional Neural Networks Trained on High and
  Medium Resolution Satellite Images, With an Application in Mexico</title>
    <summary>  Mapping the spatial distribution of poverty in developing countries remains
an important and costly challenge. These "poverty maps" are key inputs for
poverty targeting, public goods provision, political accountability, and impact
evaluation, that are all the more important given the geographic dispersion of
the remaining bottom billion severely poor individuals. In this paper we train
Convolutional Neural Networks (CNNs) to estimate poverty directly from high and
medium resolution satellite images. We use both Planet and Digital Globe
imagery with spatial resolutions of 3-5 sq. m. and 50 sq. cm. respectively,
covering all 2 million sq. km. of Mexico. Benchmark poverty estimates come from
the 2014 MCS-ENIGH combined with the 2015 Intercensus and are used to estimate
poverty rates for 2,456 Mexican municipalities. CNNs are trained using the 896
municipalities in the 2014 MCS-ENIGH. We experiment with several architectures
(GoogleNet, VGG) and use GoogleNet as a final architecture where weights are
fine-tuned from ImageNet. We find that 1) the best models, which incorporate
satellite-estimated land use as a predictor, explain approximately 57% of the
variation in poverty in a validation sample of 10 percent of MCS-ENIGH
municipalities; 2) Across all MCS-ENIGH municipalities explanatory power
reduces to 44% in a CNN prediction and landcover model; 3) Predicted poverty
from the CNN predictions alone explains 47% of the variation in poverty in the
validation sample, and 37% over all MCS-ENIGH municipalities; 4) In urban areas
we see slight improvements from using Digital Globe versus Planet imagery,
which explain 61% and 54% of poverty variation respectively. We conclude that
CNNs can be trained end-to-end on satellite imagery to estimate poverty,
although there is much work to be done to understand how the training process
influences out of sample validation.
</summary>
    <author>
      <name>Boris Babenko</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Orbital Insight</arxiv:affiliation>
    </author>
    <author>
      <name>Jonathan Hersh</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Chapman University</arxiv:affiliation>
    </author>
    <author>
      <name>David Newhouse</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">World Bank</arxiv:affiliation>
    </author>
    <author>
      <name>Anusha Ramakrishnan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">World Bank</arxiv:affiliation>
    </author>
    <author>
      <name>Tom Swartz</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Orbital Insight</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 2 figures, Presented at NIPS 2017 Workshop on Machine
  Learning for the Developing World</arxiv:comment>
    <link href="http://arxiv.org/abs/1711.06323v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.06323v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.03063v1</id>
    <updated>2019-04-05T13:39:42Z</updated>
    <published>2019-04-05T13:39:42Z</published>
    <title>Bayesian Heatmaps: Probabilistic Classification with Multiple Unreliable
  Information Sources</title>
    <summary>  Unstructured data from diverse sources, such as social media and aerial
imagery, can provide valuable up-to-date information for intelligent situation
assessment. Mining these different information sources could bring major
benefits to applications such as situation awareness in disaster zones and
mapping the spread of diseases. Such applications depend on classifying the
situation across a region of interest, which can be depicted as a spatial
"heatmap". Annotating unstructured data using crowdsourcing or automated
classifiers produces individual classifications at sparse locations that
typically contain many errors. We propose a novel Bayesian approach that models
the relevance, error rates and bias of each information source, enabling us to
learn a spatial Gaussian Process classifier by aggregating data from multiple
sources with varying reliability and relevance. Our method does not require
gold-labelled data and can make predictions at any location in an area of
interest given only sparse observations. We show empirically that our approach
can handle noisy and biased data sources, and that simultaneously inferring
reliability and transferring information between neighbouring reports leads to
more accurate predictions. We demonstrate our method on two real-world problems
from disaster response, showing how our approach reduces the amount of
crowdsourced data required and can be used to generate valuable heatmap
visualisations from SMS messages and satellite images.
</summary>
    <author>
      <name>Edwin Simpson</name>
    </author>
    <author>
      <name>Steven Reece</name>
    </author>
    <author>
      <name>Stephen J. Roberts</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases (2017), pp. 109-125, Springer, Cham</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1904.03063v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.03063v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.08560v1</id>
    <updated>2018-06-22T08:56:29Z</updated>
    <published>2018-06-22T08:56:29Z</published>
    <title>FLARECAST: an I4.0 technology for space weather using satellite data</title>
    <summary>  'Flare Likelihood and Region Eruption Forecasting (FLARECAST)' is a Horizon
2020 project, which realized a technological platform for machine learning
algorithms, with the objective of providing the space weather community with a
prediction service for solar flares. This paper describes the FLARECAST service
and shows how the methods implemented in the platform allow both flare
prediction and a quantitative assessment of how the information contained in
the space data utilized in the analysis may impact the forecasting process.
</summary>
    <author>
      <name>Michele Piana</name>
    </author>
    <author>
      <name>Anna Maria Massone</name>
    </author>
    <author>
      <name>Federico Benvenuto</name>
    </author>
    <author>
      <name>Cristina Campi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Italy Session - 4th International Forum on Research and
  Technologies for Society and Industry</arxiv:comment>
    <link href="http://arxiv.org/abs/1806.08560v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.08560v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.space-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="85-08, 68T05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1811.03707v1</id>
    <updated>2018-11-08T22:59:40Z</updated>
    <published>2018-11-08T22:59:40Z</published>
    <title>Validating Hyperspectral Image Segmentation</title>
    <summary>  Hyperspectral satellite imaging attracts enormous research attention in the
remote sensing community, hence automated approaches for precise segmentation
of such imagery are being rapidly developed. In this letter, we share our
observations on the strategy for validating hyperspectral image segmentation
algorithms currently followed in the literature, and show that it can lead to
over-optimistic experimental insights. We introduce a new routine for
generating segmentation benchmarks, and use it to elaborate ready-to-use
hyperspectral training-test data partitions. They can be utilized for fair
validation of new and existing algorithms without any training-test data
leakage.
</summary>
    <author>
      <name>Jakub Nalepa</name>
    </author>
    <author>
      <name>Michal Myller</name>
    </author>
    <author>
      <name>Michal Kawulok</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/LGRS.2019.2895697</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/LGRS.2019.2895697" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to IEEE Geoscience and Remote Sensing Letters</arxiv:comment>
    <link href="http://arxiv.org/abs/1811.03707v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1811.03707v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.02766v1</id>
    <updated>2016-12-08T18:46:39Z</updated>
    <published>2016-12-08T18:46:39Z</published>
    <title>Feedback Neural Network for Weakly Supervised Geo-Semantic Segmentation</title>
    <summary>  Learning from weakly-supervised data is one of the main challenges in machine
learning and computer vision, especially for tasks such as image semantic
segmentation where labeling is extremely expensive and subjective. In this
paper, we propose a novel neural network architecture to perform
weakly-supervised learning by suppressing irrelevant neuron activations. It
localizes objects of interest by learning from image-level categorical labels
in an end-to-end manner. We apply this algorithm to a practical challenge of
transforming satellite images into a map of settlements and individual
buildings. Experimental results show that the proposed algorithm achieves
superior performance and efficiency when compared with various baseline models.
</summary>
    <author>
      <name>Xianming Liu</name>
    </author>
    <author>
      <name>Amy Zhang</name>
    </author>
    <author>
      <name>Tobias Tiecke</name>
    </author>
    <author>
      <name>Andreas Gros</name>
    </author>
    <author>
      <name>Thomas S. Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.02766v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.02766v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.10503v1</id>
    <updated>2019-01-29T19:25:52Z</updated>
    <published>2019-01-29T19:25:52Z</published>
    <title>Time-Space tradeoff in deep learning models for crop classification on
  satellite multi-spectral image time series</title>
    <summary>  In this article, we investigate several structured deep learning models for
crop type classification on multi-spectral time series. In particular, our aim
is to assess the respective importance of spatial and temporal structures in
such data. With this objective, we consider several designs of convolutional,
recurrent, and hybrid neural networks, and assess their performance on a large
dataset of freely available Sentinel-2 imagery. We find that the
best-performing approaches are hybrid configurations for which most of the
parameters (up to 90%) are allocated to modeling the temporal structure of the
data. Our results thus constitute a set of guidelines for the design of bespoke
deep learning models for crop type classification.
</summary>
    <author>
      <name>Vivien Sainte Fare Garnot</name>
    </author>
    <author>
      <name>Loic Landrieu</name>
    </author>
    <author>
      <name>Sebastien Giordano</name>
    </author>
    <author>
      <name>Nesrine Chehata</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Currently under review</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.10503v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.10503v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.05552v1</id>
    <updated>2019-07-12T07:43:42Z</updated>
    <published>2019-07-12T07:43:42Z</published>
    <title>Tiny-Inception-ResNet-v2: Using Deep Learning for Eliminating Bonded
  Labors of Brick Kilns in South Asia</title>
    <summary>  This paper proposes to employ a Inception-ResNet inspired deep learning
architecture called Tiny-Inception-ResNet-v2 to eliminate bonded labor by
identifying brick kilns within "Brick-Kiln-Belt" of South Asia. The framework
is developed by training a network on the satellite imagery consisting of 11
different classes of South Asian region. The dataset developed during the
process includes the geo-referenced images of brick kilns, houses, roads,
tennis courts, farms, sparse trees, dense trees, orchards, parking lots, parks
and barren lands. The dataset is made publicly available for further research.
Our proposed network architecture with very fewer learning parameters
outperforms all state-of-the-art architectures employed for recognition of
brick kilns. Our proposed solution would enable regional monitoring and
evaluation mechanisms for the Sustainable Development Goals.
</summary>
    <author>
      <name>Usman Nazir</name>
    </author>
    <author>
      <name>Numan Khurshid</name>
    </author>
    <author>
      <name>Muhammad Ahmed Bhimra</name>
    </author>
    <author>
      <name>Murtaza Taj</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">CVPR 2019 workshop</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1907.05552v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.05552v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.12305v1</id>
    <updated>2019-05-29T10:07:14Z</updated>
    <published>2019-05-29T10:07:14Z</published>
    <title>Fusion of Heterogeneous Earth Observation Data for the Classification of
  Local Climate Zones</title>
    <summary>  This paper proposes a novel framework for fusing multi-temporal,
multispectral satellite images and OpenStreetMap (OSM) data for the
classification of local climate zones (LCZs). Feature stacking is the most
commonly-used method of data fusion but does not consider the heterogeneity of
multimodal optical images and OSM data, which becomes its main drawback. The
proposed framework processes two data sources separately and then combines them
at the model level through two fusion models (the landuse fusion model and
building fusion model), which aim to fuse optical images with landuse and
buildings layers of OSM data, respectively. In addition, a new approach to
detecting building incompleteness of OSM data is proposed. The proposed
framework was trained and tested using data from the 2017 IEEE GRSS Data Fusion
Contest, and further validated on one additional test set containing test
samples which are manually labeled in Munich and New York. Experimental results
have indicated that compared to the feature stacking-based baseline framework
the proposed framework is effective in fusing optical images with OSM data for
the classification of LCZs with high generalization capability on a large
scale. The classification accuracy of the proposed framework outperforms the
baseline framework by more than 6% and 2%, while testing on the test set of
2017 IEEE GRSS Data Fusion Contest and the additional test set, respectively.
In addition, the proposed framework is less sensitive to spectral diversities
of optical satellite images and thus achieves more stable classification
performance than state-of-the art frameworks.
</summary>
    <author>
      <name>Guichen Zhang</name>
    </author>
    <author>
      <name>Pedram Ghamisi</name>
    </author>
    <author>
      <name>Xiao Xiang Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted by TGRS</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.12305v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.12305v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.06470v1</id>
    <updated>2018-08-14T09:34:16Z</updated>
    <published>2018-08-14T09:34:16Z</published>
    <title>predictSLUMS: A new model for identifying and predicting informal
  settlements and slums in cities from street intersections using machine
  learning</title>
    <summary>  Identifying current and future informal regions within cities remains a
crucial issue for policymakers and governments in developing countries. The
delineation process of identifying such regions in cities requires a lot of
resources. While there are various studies that identify informal settlements
based on satellite image classification, relying on both supervised or
unsupervised machine learning approaches, these models either require multiple
input data to function or need further development with regards to precision.
In this paper, we introduce a novel method for identifying and predicting
informal settlements using only street intersections data, regardless of the
variation of urban form, number of floors, materials used for construction or
street width. With such minimal input data, we attempt to provide planners and
policy-makers with a pragmatic tool that can aid in identifying informal zones
in cities. The algorithm of the model is based on spatial statistics and a
machine learning approach, using Multinomial Logistic Regression (MNL) and
Artificial Neural Networks (ANN). The proposed model relies on defining
informal settlements based on two ubiquitous characteristics that these regions
tend to be filled in with smaller subdivided lots of housing relative to the
formal areas within the local context, and the paucity of services and
infrastructure within the boundary of these settlements that require relatively
bigger lots. We applied the model in five major cities in Egypt and India that
have spatial structures in which informality is present. These cities are
Greater Cairo, Alexandria, Hurghada and Minya in Egypt, and Mumbai in India.
The predictSLUMS model shows high validity and accuracy for identifying and
predicting informality within the same city the model was trained on or in
different ones of a similar context.
</summary>
    <author>
      <name>Mohamed R. Ibrahim</name>
    </author>
    <author>
      <name>Helena Titheridge</name>
    </author>
    <author>
      <name>Tao Cheng</name>
    </author>
    <author>
      <name>James Haworth</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1808.06470v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.06470v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.3251v2</id>
    <updated>2012-06-28T09:36:27Z</updated>
    <published>2012-04-15T10:21:57Z</published>
    <title>Plug-in martingales for testing exchangeability on-line</title>
    <summary>  A standard assumption in machine learning is the exchangeability of data,
which is equivalent to assuming that the examples are generated from the same
probability distribution independently. This paper is devoted to testing the
assumption of exchangeability on-line: the examples arrive one by one, and
after receiving each example we would like to have a valid measure of the
degree to which the assumption of exchangeability has been falsified. Such
measures are provided by exchangeability martingales. We extend known
techniques for constructing exchangeability martingales and show that our new
method is competitive with the martingales introduced before. Finally we
investigate the performance of our testing method on two benchmark datasets,
USPS and Statlog Satellite data; for the former, the known techniques give
satisfactory results, but for the latter our new more flexible method becomes
necessary.
</summary>
    <author>
      <name>Valentina Fedorova</name>
    </author>
    <author>
      <name>Alex Gammerman</name>
    </author>
    <author>
      <name>Ilia Nouretdinov</name>
    </author>
    <author>
      <name>Vladimir Vovk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 7 figures; ICML 2012 Conference Proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.3251v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.3251v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62G10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.2969v1</id>
    <updated>2013-02-13T02:11:37Z</updated>
    <published>2013-02-13T02:11:37Z</published>
    <title>Towards Identification of Relevant Variables in the observed Aerosol
  Optical Depth Bias between MODIS and AERONET observations</title>
    <summary>  Measurements made by satellite remote sensing, Moderate Resolution Imaging
Spectroradiometer (MODIS), and globally distributed Aerosol Robotic Network
(AERONET) are compared. Comparison of the two datasets measurements for aerosol
optical depth values show that there are biases between the two data products.
In this paper, we present a general framework towards identifying relevant set
of variables responsible for the observed bias. We present a general framework
to identify the possible factors influencing the bias, which might be
associated with the measurement conditions such as the solar and sensor zenith
angles, the solar and sensor azimuth, scattering angles, and surface
reflectivity at the various measured wavelengths, etc. Specifically, we
performed analysis for remote sensing Aqua-Land data set, and used machine
learning technique, neural network in this case, to perform multivariate
regression between the ground-truth and the training data sets. Finally, we
used mutual information between the observed and the predicted values as the
measure of similarity to identify the most relevant set of variables. The
search is brute force method as we have to consider all possible combinations.
The computations involves a huge number crunching exercise, and we implemented
it by writing a job-parallel program.
</summary>
    <author>
      <name>N. K. Malakar</name>
    </author>
    <author>
      <name>D. J. Lary</name>
    </author>
    <author>
      <name>D. Gencaga</name>
    </author>
    <author>
      <name>A. Albayrak</name>
    </author>
    <author>
      <name>J. Wei</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1063/1.4819985</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1063/1.4819985" rel="related"/>
    <link href="http://arxiv.org/abs/1302.2969v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.2969v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.05381v3</id>
    <updated>2018-03-20T14:08:25Z</updated>
    <published>2017-09-15T20:00:01Z</published>
    <title>Heterogeneous Quantum Computing for Satellite Constellation
  Optimization: Solving the Weighted K-Clique Problem</title>
    <summary>  NP-hard optimization problems scale very rapidly with problem size, becoming
unsolvable with brute force methods, even with supercomputing resources.
Typically, such problems have been approximated with heuristics. However, these
methods still take a long time and are not guaranteed to find an optimal
solution. Quantum computing offers the possibility of producing significant
speed-up and improved solution quality. Current quantum annealing (QA) devices
are designed to solve difficult optimization problems, but they are limited by
hardware size and qubit connectivity restrictions. We present a novel
heterogeneous computing stack that combines QA and classical machine learning,
allowing the use of QA on problems larger than the hardware limits of the
quantum device. These results represent experiments on a real-world problem
represented by the weighted k-clique problem. Through this experiment, we
provide insight into the state of quantum machine learning.
</summary>
    <author>
      <name>Gideon Bass</name>
    </author>
    <author>
      <name>Casey Tomlin</name>
    </author>
    <author>
      <name>Vaibhaw Kumar</name>
    </author>
    <author>
      <name>Pete Rihaczek</name>
    </author>
    <author>
      <name>Joseph Dulny III</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/2058-9565/aaadc2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/2058-9565/aaadc2" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Gideon Bass et al 2018 Quantum Sci. Technol. 3 024010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1709.05381v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.05381v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.02290v1</id>
    <updated>2018-02-07T02:23:47Z</updated>
    <published>2018-02-07T02:23:47Z</published>
    <title>Spectral Image Visualization Using Generative Adversarial Networks</title>
    <summary>  Spectral images captured by satellites and radio-telescopes are analyzed to
obtain information about geological compositions distributions, distant asters
as well as undersea terrain. Spectral images usually contain tens to hundreds
of continuous narrow spectral bands and are widely used in various fields. But
the vast majority of those image signals are beyond the visible range, which
calls for special visualization technique. The visualizations of spectral
images shall convey as much information as possible from the original signal
and facilitate image interpretation. However, most of the existing visualizatio
methods display spectral images in false colors, which contradict with human's
experience and expectation. In this paper, we present a novel visualization
generative adversarial network (GAN) to display spectral images in natural
colors. To achieve our goal, we propose a loss function which consists of an
adversarial loss and a structure loss. The adversarial loss pushes our solution
to the natural image distribution using a discriminator network that is trained
to differentiate between false-color images and natural-color images. We also
use a cycle loss as the structure constraint to guarantee structure
consistency. Experimental results show that our method is able to generate
structure-preserved and natural-looking visualizations.
</summary>
    <author>
      <name>Siyu Chen</name>
    </author>
    <author>
      <name>Danping Liao</name>
    </author>
    <author>
      <name>Yuntao Qian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1802.02290v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.02290v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.11219v1</id>
    <updated>2019-05-27T13:52:16Z</updated>
    <published>2019-05-27T13:52:16Z</published>
    <title>Automated Ground Truth Estimation of Vulnerable Road Users in Automotive
  Radar Data Using GNSS</title>
    <summary>  Annotating automotive radar data is a difficult task. This article presents
an automated way of acquiring data labels which uses a highly accurate and
portable global navigation satellite system (GNSS). The proposed system is
discussed besides a revision of other label acquisitions techniques and a
problem description of manual data annotation. The article concludes with a
systematic comparison of conventional hand labeling and automatic data
acquisition. The results show clear advantages of the proposed method without a
relevant loss in labeling accuracy. Minor changes can be observed in the
measured radar data, but the so introduced bias of the GNSS reference is
clearly outweighed by the indisputable time savings. Beside data annotation,
the proposed system can also provide a ground truth for validating object
tracking or other automated driving system applications.
</summary>
    <author>
      <name>Nicolas Scheiner</name>
    </author>
    <author>
      <name>Nils Appenrodt</name>
    </author>
    <author>
      <name>Jürgen Dickmann</name>
    </author>
    <author>
      <name>Bernhard Sick</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICMIM.2019.8726801</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICMIM.2019.8726801" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Published in Proceedings of IEEE MTT-S International Conference on
  Microwaves for Intelligent Mobility (ICMIM), Detroit, MI, USA, April 2019,
  pp. 5-9, ISBN: 978-1-7281-0775-2</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1905.11219v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.11219v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.09611v1</id>
    <updated>2019-06-23T17:11:40Z</updated>
    <published>2019-06-23T17:11:40Z</published>
    <title>Automatic classification of K2 pulsating stars using machine learning
  techniques</title>
    <summary>  The second mission of the NASA Kepler satellite, K2, has collected hundreds
of thousands of lightcurves for stars close to the ecliptic plane. This new
sample could increase the number of known pulsating stars and then improve our
understanding of those stars. For the moment only a few stars have been
properly classified and published. In this work, we present a method to
automaticly classify K2 pulsating stars using a Machine Learning technique
called Random Forest. The objective is to sort out the stars in four classes:
red giant (RG), main-sequence Solar-like stars (SL), classical pulsators (PULS)
and Other. To do this we use the effective temperatures and the luminosities of
the stars as well as the FliPer features, that measures the amount of power
contained in the power spectral density. The classifier now retrieves the right
classification for more than 80% of the stars.
</summary>
    <author>
      <name>A. Le Saux</name>
    </author>
    <author>
      <name>L. Bugnet</name>
    </author>
    <author>
      <name>S. Mathur</name>
    </author>
    <author>
      <name>S. N. Breton</name>
    </author>
    <author>
      <name>R. A. Garcia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 2019 SF2A meeting. 4 pages and 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.09611v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.09611v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4670v1</id>
    <updated>2012-06-18T15:34:23Z</updated>
    <published>2012-06-18T15:34:23Z</published>
    <title>State-Space Inference for Non-Linear Latent Force Models with
  Application to Satellite Orbit Prediction</title>
    <summary>  Latent force models (LFMs) are flexible models that combine mechanistic
modelling principles (i.e., physical models) with non-parametric data-driven
components. Several key applications of LFMs need non-linearities, which
results in analytically intractable inference. In this work we show how
non-linear LFMs can be represented as non-linear white noise driven state-space
models and present an efficient non-linear Kalman filtering and smoothing based
method for approximate state and parameter inference. We illustrate the
performance of the proposed methodology via two simulated examples, and apply
it to a real-world problem of long-term prediction of GPS satellite orbits.
</summary>
    <author>
      <name>Jouni Hartikainen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Aalto University</arxiv:affiliation>
    </author>
    <author>
      <name>Mari Seppanen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Tampere University of Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Simo Sarkka</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Aalto University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4670v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4670v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.10190v1</id>
    <updated>2018-09-26T18:58:24Z</updated>
    <published>2018-09-26T18:58:24Z</published>
    <title>Content Based Image Retrieval from AWiFS Images Repository of IRS
  Resourcesat-2 Satellite Based on Water Bodies and Burnt Areas</title>
    <summary>  Satellite Remote Sensing Technology is becoming a major milestone in the
prediction of weather anomalies, natural disasters as well as finding
alternative resources in proximity using multiple multi-spectral sensors
emitting electromagnetic waves at distinct wavelengths. Hence, it is imperative
to extract water bodies and burnt areas from orthorectified tiles and
correspondingly rank them using similarity measures. Different objects in all
the spheres of the earth have the inherent capability of absorbing
electromagnetic waves of distant wavelengths. This creates various unique masks
in terms of reflectance on the receptor. We propose Dynamic Semantic
Segmentation (DSS) algorithms that utilized the mentioned capability to extract
and rank Advanced Wide Field Sensor (AWiFS) images according to various
features. This system stores data intelligently in the form of a sparse feature
vector which drastically mitigates the computational and spatial costs incurred
for further analysis. The compressed source image is divided into chunks and
stored in the database for quicker retrieval. This work is intended to utilize
readily available and cost effective resources like AWiFS dataset instead of
depending on advanced technologies like Moderate Resolution Imaging
Spectroradiometer (MODIS) for data which is scarce.
</summary>
    <author>
      <name>Suraj Kothawade</name>
    </author>
    <author>
      <name>Kunjan Mhaske</name>
    </author>
    <author>
      <name>Sahil Sharma</name>
    </author>
    <author>
      <name>Furkhan Shaikh</name>
    </author>
    <link href="http://arxiv.org/abs/1809.10190v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.10190v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.13273v2</id>
    <updated>2018-11-06T12:14:15Z</updated>
    <published>2018-10-31T13:25:17Z</published>
    <title>Ionospheric activity prediction using convolutional recurrent neural
  networks</title>
    <summary>  The ionosphere electromagnetic activity is a major factor of the quality of
satellite telecommunications, Global Navigation Satellite Systems (GNSS) and
other vital space applications. Being able to forecast globally the Total
Electron Content (TEC) would enable a better anticipation of potential
performance degradations. A few studies have proposed models able to predict
the TEC locally, but not worldwide for most of them. Thanks to a large record
of past TEC maps publicly available, we propose a method based on Deep Neural
Networks (DNN) to forecast a sequence of global TEC maps consecutive to an
input sequence of TEC maps, without introducing any prior knowledge other than
Earth rotation periodicity. By combining several state-of-the-art
architectures, the proposed approach is competitive with previous works on TEC
forecasting while predicting the TEC globally.
</summary>
    <author>
      <name>Alexandre Boulch</name>
    </author>
    <author>
      <name>Noëlie Cherrier</name>
    </author>
    <author>
      <name>Thibaut Castaings</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Under submission at IEEE Transactions on Big Data</arxiv:comment>
    <link href="http://arxiv.org/abs/1810.13273v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.13273v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.04604v1</id>
    <updated>2019-02-12T19:39:07Z</updated>
    <published>2019-02-12T19:39:07Z</published>
    <title>Progressively Growing Generative Adversarial Networks for High
  Resolution Semantic Segmentation of Satellite Images</title>
    <summary>  Machine learning has proven to be useful in classification and segmentation
of images. In this paper, we evaluate a training methodology for pixel-wise
segmentation on high resolution satellite images using progressive growing of
generative adversarial networks. We apply our model to segmenting building
rooftops and compare these results to conventional methods for rooftop
segmentation. We present our findings using the SpaceNet version 2 dataset.
Progressive GAN training achieved a test accuracy of 93% compared to 89% for
traditional GAN training.
</summary>
    <author>
      <name>Edward Collier</name>
    </author>
    <author>
      <name>Kate Duffy</name>
    </author>
    <author>
      <name>Sangram Ganguly</name>
    </author>
    <author>
      <name>Geri Madanguit</name>
    </author>
    <author>
      <name>Subodh Kalia</name>
    </author>
    <author>
      <name>Gayaka Shreekant</name>
    </author>
    <author>
      <name>Ramakrishna Nemani</name>
    </author>
    <author>
      <name>Andrew Michaelis</name>
    </author>
    <author>
      <name>Shuang Li</name>
    </author>
    <author>
      <name>Auroop Ganguly</name>
    </author>
    <author>
      <name>Supratik Mukhopadhyay</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted too and presented at DMESS 2018 as part of IEEE ICDM 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.04604v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.04604v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.09901v1</id>
    <updated>2019-04-22T14:36:57Z</updated>
    <published>2019-04-22T14:36:57Z</published>
    <title>City-scale Road Extraction from Satellite Imagery</title>
    <summary>  Automated road network extraction from remote sensing imagery remains a
significant challenge despite its importance in a broad array of applications.
To this end, we leverage recent open source advances and the high quality
SpaceNet dataset to explore road network extraction at scale, and approach we
call City-scale Road Extraction from Satellite Imagery (CRESI). Specifically,
we create an algorithm to extract road networks directly from imagery over
city-scale regions, which can subsequently be used for routing purposes. We
quantify the performance of our algorithm with the APLS and TOPO
graph-theoretic metrics over a diverse 608 square kilometer test area covering
four cities. We find an aggregate score of APLS = 0.73, and a TOPO score of
0.58 (a significant improvement over existing methods). Inference speed is 160
square kilometers per hour on modest hardware.
</summary>
    <author>
      <name>Adam Van Etten</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 11 figures, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.09901v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.09901v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.09244v2</id>
    <updated>2018-10-15T22:27:53Z</updated>
    <published>2018-06-25T01:05:19Z</published>
    <title>A Scalable Machine Learning System for Pre-Season Agriculture Yield
  Forecast</title>
    <summary>  Yield forecast is essential to agriculture stakeholders and can be obtained
with the use of machine learning models and data coming from multiple sources.
Most solutions for yield forecast rely on NDVI (Normalized Difference
Vegetation Index) data, which is time-consuming to be acquired and processed.
To bring scalability for yield forecast, in the present paper we describe a
system that incorporates satellite-derived precipitation and soil properties
datasets, seasonal climate forecasting data from physical models and other
sources to produce a pre-season prediction of soybean/maize yield---with no
need of NDVI data. This system provides significantly useful results by the
exempting the need for high-resolution remote-sensing data and allowing farmers
to prepare for adverse climate influence on the crop cycle. In our studies, we
forecast the soybean and maize yields for Brazil and USA, which corresponded to
44% of the world's grain production in 2016. Results show the error metrics for
soybean and maize yield forecasts are comparable to similar systems that only
provide yield forecast information in the first weeks to months of the crop
cycle.
</summary>
    <author>
      <name>Igor Oliveira</name>
    </author>
    <author>
      <name>Renato L. F. Cunha</name>
    </author>
    <author>
      <name>Bruno Silva</name>
    </author>
    <author>
      <name>Marco A. S. Netto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures, Submitted to 14th IEEE eScience</arxiv:comment>
    <link href="http://arxiv.org/abs/1806.09244v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.09244v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
