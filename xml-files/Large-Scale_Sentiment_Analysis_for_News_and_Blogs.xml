<?xml version="1.0" encoding="UTF-8"?>
<article xmlns:xlink="http://www.w3.org/1999/xlink">
  <front>
    <journal-meta />
    <article-meta>
      <title-group>
        <article-title>Large-Scale Sentiment Analysis for News and Blogs</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <string-name>?Google Inc.</string-name>
          <xref ref-type="aff" rid="aff0">0</xref>
          <xref ref-type="aff" rid="aff1">1</xref>
          <xref ref-type="aff" rid="aff2">2</xref>
        </contrib>
        <contrib contrib-type="author">
          <string-name>New York NY</string-name>
          <xref ref-type="aff" rid="aff0">0</xref>
          <xref ref-type="aff" rid="aff1">1</xref>
          <xref ref-type="aff" rid="aff2">2</xref>
        </contrib>
        <aff id="aff0">
          <label>0</label>
          <institution>Manjunath Srinivasaiah</institution>
        </aff>
        <aff id="aff1">
          <label>1</label>
          <institution>Namrata Godbole</institution>
        </aff>
        <aff id="aff2">
          <label>2</label>
          <institution>Steven Skiena</institution>
        </aff>
      </contrib-group>
      <pub-date>
        <year>2007</year>
      </pub-date>
      <abstract>
        <p>Newspapers and blogs express opinion of news entities (people, places, things) while reporting on recent events. We present a system that assigns scores indicating positive or negative opinion to each distinct entity in the text corpus. Our system consists of a sentiment identi cation phase, which associates expressed opinions with each relevant entity, and a sentiment aggregation and scoring phase, which scores each entity relative to others in the same class. Finally, we evaluate the signi cance of our scoring techniques over large corpus of news and blogs.</p>
      </abstract>
    </article-meta>
  </front>
  <body>
    <sec id="sec-1">
      <title>1. Introduction</title>
      <p>News can be good or bad, but it is seldom neutral. Although
full comprehension of natural language text remains well
beyond the power of machines, the statistical analysis of
relatively simple sentiment cues can provide a surprisingly
meaningful sense of how the latest news impacts important entities.</p>
      <p>
        In this paper, we report on our development of a large-scale
sentiment analysis system for news and blog entities built on
top of the Lydia text analysis system [
        <xref ref-type="bibr" rid="ref1 ref2 ref3 ref4 ref5">1, 2, 3, 4, 5</xref>
        ]. We
determine the public sentiment on each of the hundreds of
thousands of entities that we track, and how this sentiment
varies with time. We encourage the reader to study our
historical sentiment analysis for your favorite news entities at
http://www.textmap.com and view our daily sentiment
analysis report at http://www.textmap.com/sentiment. We give
several examples of our analysis in the demonstration paper
of our system, which appears in this volume [
        <xref ref-type="bibr" rid="ref6">6</xref>
        ].
      </p>
      <p>In this paper, we discuss several aspects of our sentiment
analysis system, including:</p>
      <p>Algorithmic Construction of Sentiment Dictionaries {
Our sentiment index relies critically on tracking the
reference frequencies of adjectives with positive and
negative connotations. We present a method for expanding
small candidate seed lists of positive and negative words
into full sentiment lexicons using path-based analysis
of synonym and antonym sets in WordNet. We use
sentiment-alternation hop counts to determine the
polarity strength of the candidate terms and eliminate the
ambiguous terms. We present the detailed algorithm
and performance results.</p>
      <p>Sentiment Index Formulation { There is considerable
subtlety in constructing a statistical index which
meaningfully re ects the signi cance of sentiment term
juxtaposition. We present our technique of using
juxtaposition of sentiment terms and entities and a
frequencyweighted interpolation with world happiness levels to
score entity sentiment.</p>
      <p>
        Evaluation of Signi cance { We provide statistical
evidence of the validity of our sentiment evaluation by
correlating our index with several classes of real-world
events, including (1) results of professional baseball and
basketball games, (2) performance of stock-market
indices, and (3) seasonal e ects [
        <xref ref-type="bibr" rid="ref6">6</xref>
        ]. Positive correlations
prove that our sentiment analyzer can accurately
measure public sentiment. We also present additional
anecdotal evidence corroborating our analysis.
      </p>
      <p>Finally, we discuss possible applications and implications of
our work.</p>
    </sec>
    <sec id="sec-2">
      <title>2. Related work</title>
      <p>Sentiment analysis of natural language texts is a large and
growing eld. Previous work particularly relevant to our task
falls naturally in two groups. The rst relates to techniques
to automatically generate sentiment lexicons. The second
relates to systems that analyze sentiment (on a global or local
basis) for entire documents.</p>
    </sec>
    <sec id="sec-3">
      <title>2.1 Determining semantic orientation of words</title>
      <p>
        Hatzivassiloglou and McKeown[
        <xref ref-type="bibr" rid="ref7">7</xref>
        ] hypothesize that adjectives
separated by \and" have the same polarity, while those
separated by \but" have opposite polarity. Starting with small
seed lists, this information is used to group adjectives into
two clusters such that maximum constraints are satis ed.
      </p>
      <p>
        Wiebe [
        <xref ref-type="bibr" rid="ref8">8</xref>
        ] evaluates adjectives for polarity as well as
gradation classi cation. A statistical model groups adjectives into
clusters, corresponding to their tone/orientation. The use of
such gradable adjectives is an important factor in
determining subjectivity. Statistical models are used to predict the
gradability of adjectives.
      </p>
      <p>
        Kim and Hovy[
        <xref ref-type="bibr" rid="ref9">9</xref>
        ] evaluate the sentiment of an opinion holder
(entity) using WordNet to generate lists of positive and
negative words by expanding seed lists. They assume that
synonyms (antonyms) of a word have the same (opposite)
polarity. The percentage of a word's synonyms belonging to
lists of either polarity was used as a measure of its polarity
strength, while those below a threshold were deemed neutral
or ambiguous. Their best results were achieved when the
topic neighborhood consisted of words between the topic up
to the end of the sentence.
      </p>
    </sec>
    <sec id="sec-4">
      <title>2.2 Sentiment analysis systems</title>
      <p>
        Several systems have been built which attempt to quantify
opinion from product reviews. Pang, Lee and Vaithyanathan[
        <xref ref-type="bibr" rid="ref10">10</xref>
        ]
perform sentiment analysis of movie reviews. Their results
show that the machine learning techniques perform better
than simple counting methods. They achieve an accuracy of
polarity classi cation of roughly 83%. In [
        <xref ref-type="bibr" rid="ref11">11</xref>
        ], they identify
which sentences in a review are of subjective character to
improve sentiment analysis. We do not make this distinction in
our system, because we feel that that both fact and opinion
contribute to the public sentiment about news entities.
      </p>
      <p>
        Nasukawa and Yi[
        <xref ref-type="bibr" rid="ref12">12</xref>
        ] identify local sentiment as being more
reliable than global document sentiment, since human
evaluators often fail to agree on the global sentiment of a document.
They focus on identifying the orientation of sentiment
expressions and determining the target of these sentiments.
Shallow parsing identi es the target and the sentiment expression;
the latter is evaluated and associated with the target. Our
system also analyzes local sentiments but aims to be quicker
and cruder: we charge sentiment to all entities juxtaposed
in the same sentence as instead of a speci c target. In [
        <xref ref-type="bibr" rid="ref13">13</xref>
        ],
they follow up by employing a feature-term extractor. For a
given item, the feature extractor identi es parts or attributes
of that item. e.g., battery and lens are features of a camera.
      </p>
    </sec>
    <sec id="sec-5">
      <title>3. Sentiment lexicon generation</title>
      <p>Sentiment analysis depends on our ability to identify the
sentimental terms in a corpus and their orientation. We de ned
separate lexicons for each of seven sentiment dimensions
(general, health, crime, sports, business, politics, media). We
selected these dimensions based on our identi cation of distinct
news spheres with distinct standards of opinion and
sentiment. Enlarging the number of sentiment lexicons permits
greater focus in analyzing topic-speci c phenomena, but
potentially at a substantial cost in human curation. To avoid
this, we developed an algorithm for expanding small
dimension sets of seed sentiment words into full lexicons.</p>
    </sec>
    <sec id="sec-6">
      <title>3.1 Lexicon expansion through path analysis</title>
      <p>
        Previous systems detailed in Section 2 have expanded seed
lists into lexicons by recursively querying for synonyms using
the computer dictionary WordNet [
        <xref ref-type="bibr" rid="ref14">14</xref>
        ]. The pitfall of such
methods that that synonym set coherence weakens with
distance. Figure 1 shows four separate ways to get from good to
bad using chains of WordNet synonyms.
      </p>
      <p>To counteract such problems, our sentiment word
generation algorithm expands a set of seed words using synonym
and antonym queries as follows:</p>
      <p>
        We associate a polarity (positive or negative) to each
word and query both the synonyms and antonyms, akin
to [
        <xref ref-type="bibr" rid="ref15 ref16">15, 16</xref>
        ] Synonyms inherit the polarity from the
parent, whereas antonyms get the opposite polarity.
      </p>
      <p>
        The signi cance of a path decreases as a function of
its length or depth from a seed word, akin to [
        <xref ref-type="bibr" rid="ref17 ref18 ref9">9, 17,
18</xref>
        ]. The signi cance of a word W at depth d decreases
exponentially as score(W ) = 1=cd for some constant
c &gt; 1. The nal score of each word is the summation of
the scores received over all paths.
      </p>
      <p>Great</p>
      <p>Keen
Big</p>
      <p>Hard</p>
      <p>Severe</p>
      <p>Intense
Good
Serious</p>
      <p>Bad
Paths which alternate between positive and negative
terms are likely spurious. Thus our algorithm runs in
two iterations. The rst iteration calculates a
preliminary score estimate for each word as described above.
The second iteration re-enumerates the paths while
calculating the number of apparent sentiment alternations,
or ips. The fewer the ips, the more trustworthy the
path is. The nal score is calculated taking into
account only those paths whose ip value is within our
threshold.</p>
      <p>
        WordNet [
        <xref ref-type="bibr" rid="ref14">14</xref>
        ] orders the synonyms/antonyms by sense,
with the more common senses listed rst. We improve
accuracy by limiting our notion of synonym/antonym
to only the top senses returned for a given word.
      </p>
      <p>This algorithm generates more than 18,000 words as
being within ve hops from our small set of seed words.
Since the assigned scores followed a normal distribution,
they are naturally converted to z-scores. Most words
lying in the middle of this distribution are ambiguous,
meaning they cannot be consistently classi ed as
positive or negative. Such ambiguous words are discarded
by taking only the top X% words from either extremes
of the curve.</p>
      <p>Table 1 presents the composition of our algorithmically-generated
and curated sentiment dictionaries for each class of adjectives.</p>
    </sec>
    <sec id="sec-7">
      <title>3.2 Performance evaluation</title>
      <p>We evaluated our sentiment lexicon generation in two di
erent ways. The rst we call the un-test. The pre xes un- and
im- generally negate the sentiment of a term. Thus the terms
of form X and unX should appear on di erent ends of the
sentiment spectrum, such as competent and incompetent. Table
2 reports the fraction of (term, negated term) pairs with same
polarity. Thus the lower this ratio, the better. Our results
show that precision increases at the expense of recall as we
(1) restrict the number of path sentiment alternations and
(2) prune increasing fractions of less polar terms.</p>
      <p>
        We also compared our sentiment lexicons against those
obtained by Wiebe [
        <xref ref-type="bibr" rid="ref19">19</xref>
        ], as reported in Table 3. There is a high
degree of agreement between our algorithmically-generated
lexicon and the manually curated lexicons. Further, we nd
our algorithmically-generated polarity is often sound even
when it di ers from [
        <xref ref-type="bibr" rid="ref19">19</xref>
        ]. For example, the negative lexicon
PolMauto contained such clearly positive words like bullish,
agile, and compassionate, while the positive lexicon PolPman
contained words like strenuous, uneventful, and adamant.
      </p>
    </sec>
    <sec id="sec-8">
      <title>4. Interpretation and scoring of sentiment data</title>
      <p>We use our sentiment lexicons to mark up all sentiment words
and associated entities in our corpus. We reverse the polarity
of a sentiment word whenever it is preceded by a negation.
We increase/decrease the polarity strength when a word is
preceded by a modi er. Thus not good = -1; good = +1;
very good = +2.</p>
      <p>
        Our sentiment analyzer ignores articles which are detected
as being a duplicate of another [
        <xref ref-type="bibr" rid="ref1">1</xref>
        ]. This prevents news
syndicate articles from having a larger impact on the sentiment
than other articles. Since our system processes vast
quantities of text on a daily basis, speed considerations prevent us
from doing careful parsing. Instead, we use co-occurrence of
an entity and a sentiment word in the same sentence to mean
that the sentiment is associated with that entity. This is not
always accurate, particularly in complex sentences. Still the
volume of text we process enables us to generate accurate
sentiment scores.
      </p>
      <p>
        We take several steps to aggregate entity references under
di erent names. By employing techniques for pronoun
resolution, we can identify more entity/sentiment co-occurrences
than occur in the original news text. Further, Lydia's system
for identifying co-reference sets [
        <xref ref-type="bibr" rid="ref4">4</xref>
        ] associates alternate
references such as George W. Bush and George Bush under the
single synonym set header George W. Bush. This consolidates
sentiment pertaining to a single entity.
      </p>
    </sec>
    <sec id="sec-9">
      <title>4.1 Polarity scores</title>
      <p>DIMENSION
BUSINESS</p>
      <p>CRIME
GENERAL
HEALTH</p>
      <p>MEDIA
POLITICS
SPORTS</p>
    </sec>
    <sec id="sec-10">
      <title>4.2 Subjectivity scores</title>
      <p>The subjectivity time series re ects the amount of sentiment
an entity is associated with, regardless of whether the
sentiment is positive or negative. Reading all news text over a
period of time and counting sentiment in it gives a measure
of the average subjectivity levels of the world. We evaluate
world subjectivity using sentiment data for all entities for the
entire time period:
world subjectivity =
total sentiment ref erences
total ref erences
We evaluate entity subjectivityi using sentiment data for
that day (dayi) only:
entity subjectivityi =
total sentiment ref erencesi
total ref erencesi</p>
    </sec>
    <sec id="sec-11">
      <title>5. News vs. blogs</title>
      <p>
        The issues and the people discussed in blogs varies
considerably from newspapers [
        <xref ref-type="bibr" rid="ref2">2</xref>
        ]. Table 5 lists the people that
were the most positive in newspapers and blogs, respectively,
as of July 2006. American investor Warren Bu et and F-1
driver Fernando Alonso, driver are regarded positively both
in blogs and newspapers. Other sportsmen (Rafael Nadal,
Maria Sharapova) are also among the top positive people in
blogs. Because the percentile ratings of news and blogs are
not directly comparable, we report our results here in terms
of net positive and negative sentiment.
      </p>
      <p>Table 6 lists the most negative people appearing in
newspapers and blogs. International (Slobodan Milosevic, Zacarias
Moussaoui) and domestic criminal gures (John A. Muhammed,
Lionel Tate, George Ryan) are regarded as losers in both blogs
and newspapers. The blogs of angry fans reveal their extreme
displeasure at certain sports gures (Sammy Sosa, Esteban
Loaiza, Ricky Williams).</p>
      <p>Most interesting are the distinct fates of certain
controversial American political gures. Some (e.g. Harriet Miers, Al
Sharpton) are regarded negatively in newspapers but
positively in blogs, while others (e.g. Charles Schumer, Edward
Kennedy) are thought of negatively only by bloggers. These
clearly re ect political biases among bloggers, and perhaps
the mainstream press.</p>
    </sec>
    <sec id="sec-12">
      <title>6. Conclusion</title>
      <p>
        There are many interesting directions that can be explored.
We are interested in how sentiment can vary by demographic
group, news source or geographic location. By expanding our
spatial analysis of news entities [
        <xref ref-type="bibr" rid="ref1">1</xref>
        ] to sentiment maps, we can
identify geographical regions of favorable or adverse opinions
for given entities. We are also studying in analyzing the
degree to which our sentiment indices predict future changes in
popularity or market behavior.
      </p>
    </sec>
  </body>
  <back>
    <ref-list>
      <ref id="ref1">
        <mixed-citation>
          [1]
          <string-name>
            <surname>Mehler</surname>
            ,
            <given-names>A.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Bao</surname>
            ,
            <given-names>Y.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Li</surname>
            ,
            <given-names>X.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Wang</surname>
            ,
            <given-names>Y.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Skiena</surname>
            ,
            <given-names>S.</given-names>
          </string-name>
          :
          <article-title>Spatial analysis of news sources</article-title>
          .
          <source>IEEE Trans. Visualization and Computer Graphics</source>
          <volume>12</volume>
          (
          <year>2006</year>
          )
          <volume>765</volume>
          {
          <fpage>772</fpage>
        </mixed-citation>
      </ref>
      <ref id="ref2">
        <mixed-citation>
          [2]
          <string-name>
            <surname>Lloyd</surname>
            ,
            <given-names>L.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Kaulgud</surname>
            ,
            <given-names>P.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Skiena</surname>
            ,
            <given-names>S.</given-names>
          </string-name>
          :
          <article-title>Newspapers vs. blogs: Who gets the scoop? In: Computational Approaches to Analyzing Weblogs (AAAI-CAAW</article-title>
          <year>2006</year>
          ). Volume AAAI Press,
          <source>Technical Report SS-06-03</source>
          . (
          <year>2006</year>
          )
          <volume>117</volume>
          {
          <fpage>124</fpage>
        </mixed-citation>
      </ref>
      <ref id="ref3">
        <mixed-citation>
          [3]
          <string-name>
            <surname>Lloyd</surname>
            ,
            <given-names>L.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Kechagias</surname>
            ,
            <given-names>D.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Skiena</surname>
            ,
            <given-names>S.</given-names>
          </string-name>
          :
          <article-title>Lydia: A system for large-scale news analysis</article-title>
          .
          <source>In: String Processing and Information Retrieval (SPIRE</source>
          <year>2005</year>
          ).
          <source>Volume Lecture Notes in Computer Science</source>
          ,
          <volume>3772</volume>
          . (
          <year>2005</year>
          )
          <volume>161</volume>
          {
          <fpage>166</fpage>
        </mixed-citation>
      </ref>
      <ref id="ref4">
        <mixed-citation>
          [4]
          <string-name>
            <surname>Lloyd</surname>
            ,
            <given-names>L.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Mehler</surname>
            ,
            <given-names>A.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Skiena</surname>
            .,
            <given-names>S.</given-names>
          </string-name>
          :
          <article-title>Identifying co-referential names across large corpra</article-title>
          .
          <source>In: Proc. Combinatorial Pattern Matching (CPM 2006). Volume Lecture Notes in Computer Science</source>
          ,
          <volume>4009</volume>
          . (
          <year>2006</year>
          )
          <volume>12</volume>
          {
          <fpage>23</fpage>
        </mixed-citation>
      </ref>
      <ref id="ref5">
        <mixed-citation>
          [5]
          <string-name>
            <surname>Kil</surname>
            ,
            <given-names>J.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Lloyd</surname>
            ,
            <given-names>L.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Skiena</surname>
            ,
            <given-names>S.</given-names>
          </string-name>
          :
          <article-title>Question answering with lydia</article-title>
          .
          <source>Proc. 14th Text Retrieval Conference (TREC</source>
          <year>2005</year>
          )
          <article-title>(</article-title>
          <year>2005</year>
          )
        </mixed-citation>
      </ref>
      <ref id="ref6">
        <mixed-citation>
          [6]
          <string-name>
            <surname>Godbole</surname>
            ,
            <given-names>N.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Srinivasaiah</surname>
            ,
            <given-names>M.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Skiena</surname>
            ,
            <given-names>S.</given-names>
          </string-name>
          :
          <article-title>Large-scale sentiment analysis for news and blogs (demonstration)</article-title>
          .
          <source>In: Proc. Int. Conf. Weblogs and Social Media (ICWSM 07)</source>
          . (
          <year>2007</year>
          )
        </mixed-citation>
      </ref>
      <ref id="ref7">
        <mixed-citation>
          [7]
          <string-name>
            <surname>Hatzivassiloglou</surname>
            ,
            <given-names>V.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>McKeown</surname>
            ,
            <given-names>K.R.</given-names>
          </string-name>
          :
          <article-title>Predicting the semantic orientation of adjectives</article-title>
          .
          <source>In: Proc. 8th Conf</source>
          .
          <article-title>on European chapter of the Association for Computational Linguistics</article-title>
          , Morristown, NJ, USA, Association for Computational Linguistics (
          <year>1997</year>
          )
          <volume>174</volume>
          {
          <fpage>181</fpage>
        </mixed-citation>
      </ref>
      <ref id="ref8">
        <mixed-citation>
          [8]
          <string-name>
            <surname>Wiebe</surname>
            ,
            <given-names>J.</given-names>
          </string-name>
          :
          <article-title>Learning subjective adjectives from corpora</article-title>
          .
          <source>In: Proc. 17th Nat. Conf. on Arti cial Intelligence and 12th Conf. on Innovative Applications of Arti cial Intelligence</source>
          , AAAI Press / The MIT Press (
          <year>2000</year>
          )
          <volume>735</volume>
          {
          <fpage>740</fpage>
        </mixed-citation>
      </ref>
      <ref id="ref9">
        <mixed-citation>
          [9]
          <string-name>
            <surname>Kim</surname>
            ,
            <given-names>S.M.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Hovy</surname>
          </string-name>
          , E.:
          <article-title>Determining the sentiment of opinions</article-title>
          .
          <source>In: Proceedings of the Coling Conference</source>
          . (
          <year>2004</year>
          )
        </mixed-citation>
      </ref>
      <ref id="ref10">
        <mixed-citation>
          [10]
          <string-name>
            <surname>Pang</surname>
            ,
            <given-names>B.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Lee</surname>
            ,
            <given-names>L.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Vaithyanathan</surname>
            ,
            <given-names>S.</given-names>
          </string-name>
          :
          <article-title>Thumbs up? Sentiment classi cation using machine learning techniques</article-title>
          .
          <source>In: Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing (EMNLP)</source>
          .
          <article-title>(</article-title>
          <year>2002</year>
          )
          <volume>79</volume>
          {
          <fpage>86</fpage>
        </mixed-citation>
      </ref>
      <ref id="ref11">
        <mixed-citation>
          [11]
          <string-name>
            <surname>Pang</surname>
            ,
            <given-names>B.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Lee</surname>
            ,
            <given-names>L.</given-names>
          </string-name>
          :
          <article-title>A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts</article-title>
          .
          <source>In: Proceedings of the ACL</source>
          . (
          <year>2004</year>
          )
          <volume>271</volume>
          {
          <fpage>278</fpage>
        </mixed-citation>
      </ref>
      <ref id="ref12">
        <mixed-citation>
          [12]
          <string-name>
            <surname>Nasukawa</surname>
            ,
            <given-names>T.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Yi</surname>
          </string-name>
          , J.:
          <article-title>Sentiment analysis: Capturing favorability using natural language processing</article-title>
          .
          <source>In: The Second International Conferences on Knowledge Capture</source>
          . (
          <year>2003</year>
          )
          <volume>70</volume>
          {
          <fpage>77</fpage>
        </mixed-citation>
      </ref>
      <ref id="ref13">
        <mixed-citation>
          [13]
          <string-name>
            <given-names>J.</given-names>
            <surname>Yi</surname>
          </string-name>
          ,
          <string-name>
            <given-names>T.</given-names>
            <surname>Nasukawa</surname>
          </string-name>
          ,
          <string-name>
            <given-names>R.B.</given-names>
            ,
            <surname>Niblack</surname>
          </string-name>
          ,
          <string-name>
            <surname>W.</surname>
          </string-name>
          :
          <article-title>Sentiment analyzer: Extracting sentiments about a given topic using natural language processing techniques</article-title>
          .
          <source>In: 3rd IEEE Conf. on Data Mining (ICDM'03)</source>
          . (
          <year>2003</year>
          )
          <volume>423</volume>
          {
          <fpage>434</fpage>
        </mixed-citation>
      </ref>
      <ref id="ref14">
        <mixed-citation>
          [14]
          <string-name>
            <surname>Miller</surname>
            ,
            <given-names>G.A.</given-names>
          </string-name>
          :
          <article-title>Wordnet: A lexical database</article-title>
          .
          <source>Communications of the ACM</source>
          <volume>38</volume>
          (
          <issue>11</issue>
          ) (
          <year>1995</year>
          )
          <volume>39</volume>
          {
          <fpage>41</fpage>
        </mixed-citation>
      </ref>
      <ref id="ref15">
        <mixed-citation>
          [15]
          <string-name>
            <surname>Andreevskaia</surname>
            ,
            <given-names>A.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Bergler</surname>
            ,
            <given-names>S.</given-names>
          </string-name>
          :
          <article-title>Mining wordnet for a fuzzy sentiment: Sentiment tag extraction from wordnet glosses</article-title>
          .
          <source>In: EACL</source>
          . (
          <year>2006</year>
          )
        </mixed-citation>
      </ref>
      <ref id="ref16">
        <mixed-citation>
          [16]
          <string-name>
            <surname>Esuli</surname>
            ,
            <given-names>A.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Sabastiani</surname>
            ,
            <given-names>F.</given-names>
          </string-name>
          :
          <article-title>Determining term subjectivity and term orientation for opinion mining</article-title>
          .
          <source>In: EACL</source>
          . (
          <year>2006</year>
          )
        </mixed-citation>
      </ref>
      <ref id="ref17">
        <mixed-citation>
          [17]
          <string-name>
            <surname>Ide</surname>
            ,
            <given-names>N.</given-names>
          </string-name>
          :
          <article-title>Making senses: Bootstrapping sense-tagged lists of semantically-related words</article-title>
          .
          <source>In: CICLING</source>
          . (
          <year>2006</year>
          )
        </mixed-citation>
      </ref>
      <ref id="ref18">
        <mixed-citation>
          [18]
          <string-name>
            <surname>Wiebe</surname>
            ,
            <given-names>J.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Mihalcea</surname>
          </string-name>
          , R.:
          <article-title>Word sense and subjectivity</article-title>
          . In: ACL. (
          <year>2006</year>
          )
        </mixed-citation>
      </ref>
      <ref id="ref19">
        <mixed-citation>
          [19]
          <string-name>
            <surname>Wiebe</surname>
            ,
            <given-names>J.</given-names>
          </string-name>
          :
          <article-title>Learning subjective adjectives from corpora</article-title>
          .
          <source>In: AAAI/IAAI</source>
          . (
          <year>2000</year>
          )
          <volume>735</volume>
          {
          <fpage>740</fpage>
        </mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>

